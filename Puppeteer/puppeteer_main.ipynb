{"cells":[{"cell_type":"markdown","metadata":{"_uuid":"65670791be0f9dbdabacec767b7aa930f88f57cb"},"source":["#### Imports"]},{"cell_type":"code","execution_count":186,"metadata":{"_uuid":"8b92df54d984e6e40ada9af22e0212e435dbf783","trusted":true},"outputs":[],"source":["#pytorch utility imports\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader, TensorDataset\n","from torchvision.utils import make_grid\n","\n","#neural net imports\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.autograd import Variable\n","\n","#import external libraries\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import os\n","import math\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"_uuid":"a37121ac5ef70c0cb0899b0d8d996c40b450c826"},"source":["Check for CUDA"]},{"cell_type":"code","execution_count":187,"metadata":{"_uuid":"cc31bfe822c48ef3a7911eb3a3f62e4116f6befc","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["False\n","True\n","mps\n"]}],"source":["print(torch.cuda.is_available())\n","print(torch.backends.cudnn.enabled)\n","\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","elif torch.backends.mps.is_available():\n","    device = torch.device(\"mps\")  # Use Metal backend for Apple GPUs\n","else:\n","    device = torch.device(\"cpu\")  # Fallback to CPU\n","print(device)"]},{"cell_type":"code","execution_count":188,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["sample_submission.csv test.csv              train.csv\n"]}],"source":["! ls ../Data/\n","Data_folder_path = \"../Data/\"\n","train_df = pd.read_csv(Data_folder_path+\"train.csv\")\n","test_df = pd.read_csv(Data_folder_path+\"test.csv\")"]},{"cell_type":"markdown","metadata":{"_uuid":"d9dd9d5effcb7f16090ce11cfcd748ea7fc651e5"},"source":["#### Separate into labels and training images and reshape the images"]},{"cell_type":"code","execution_count":189,"metadata":{"_uuid":"ceb1cc8b91f268b7864b4ce8a135ee0f36863b4d","trusted":true},"outputs":[],"source":["train_labels = train_df['label'].values\n","train_images = (train_df.iloc[:,1:].values).astype('float32')\n","test_images = (test_df.iloc[:,:].values).astype('float32')\n","\n","#Training and Validation Split\n","train_images, val_images, train_labels, val_labels = train_test_split(train_images, train_labels,\n","                                                                     stratify=train_labels, random_state=123,\n","                                                                     test_size=0.20)"]},{"cell_type":"code","execution_count":190,"metadata":{"_uuid":"a0467a07f79074cb03dfafcf70a989a1de654e8e","trusted":true},"outputs":[],"source":["train_images = train_images.reshape(train_images.shape[0], 28, 28)\n","val_images = val_images.reshape(val_images.shape[0], 28, 28)\n","test_images = test_images.reshape(test_images.shape[0], 28, 28)"]},{"cell_type":"markdown","metadata":{"_uuid":"f5cc49c6ced3bbacfc4f2dbdfab19471ec4ddb04"},"source":["#### Plot some images to see samples"]},{"cell_type":"code","execution_count":191,"metadata":{"_uuid":"1de567ffcf179220917f3344066454f32a6127bb","trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x200 with 3 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#train samples\n","for i in range(6, 9):\n","    plt.subplot(330 + (i+1))\n","    plt.imshow(train_images[i].squeeze(), cmap=plt.get_cmap('gray'))\n","    plt.title(train_labels[i])"]},{"cell_type":"code","execution_count":192,"metadata":{"_uuid":"1ebccd63893509f0bddea4d0d6f783206796edf5","trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x200 with 3 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["#test samples\n","for i in range(6, 9):\n","    plt.subplot(330 + (i+1))\n","    plt.imshow(test_images[i].squeeze(), cmap=plt.get_cmap('gray'))\n","    plt.title(train_labels[i])"]},{"cell_type":"markdown","metadata":{"_uuid":"fa81fe0a91f7894e144d09b9268d67a6773c51b6"},"source":["#### Convert images to tensors\n","Normalize the images too"]},{"cell_type":"code","execution_count":193,"metadata":{"_uuid":"d39d3fb5b0613fabf72d4a17ddf638bf4ad28700","trusted":true},"outputs":[],"source":["#train\n","train_images_tensor = torch.tensor(train_images)/255.0\n","train_labels_tensor = torch.tensor(train_labels)\n","train_tensor = TensorDataset(train_images_tensor, train_labels_tensor)\n","\n","#val\n","val_images_tensor = torch.tensor(val_images)/255.0\n","val_labels_tensor = torch.tensor(val_labels)\n","val_tensor = TensorDataset(val_images_tensor, val_labels_tensor)\n","\n","#test\n","test_images_tensor = torch.tensor(test_images)/255.0"]},{"cell_type":"markdown","metadata":{"_uuid":"eea027734384efcc2ff337c0211d2685d95989b0"},"source":["#### Load images into the data generator"]},{"cell_type":"code","execution_count":194,"metadata":{"_uuid":"62de8a26a44cafbf5274ee914142fb56a58b25d4","trusted":true},"outputs":[],"source":["train_loader = DataLoader(train_tensor, batch_size=8, num_workers=0, shuffle=True)\n","val_loader = DataLoader(val_tensor, batch_size=16, num_workers=0, shuffle=True)\n","test_loader = DataLoader(test_images_tensor, batch_size=16, num_workers=0, shuffle=False)"]},{"cell_type":"markdown","metadata":{"_uuid":"7b72d3e520cb453ffa0ebc65d4809ccf7bb1aadd"},"source":["#### Plot some sample images using the data generator"]},{"cell_type":"code","execution_count":195,"metadata":{"_uuid":"ff324b9c832ff8959aa84902ccf9403f9483a879","trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x200 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["for batch_idx, (data, target) in enumerate(train_loader):\n","    img_grid = make_grid(data[0:8,].unsqueeze(1), nrow=8)\n","    img_target_labels = target[0:8,].numpy()\n","    break\n","    \n","plt.imshow(img_grid.numpy().transpose((1,2,0)))\n","plt.rcParams['figure.figsize'] = (10, 2)\n","plt.title(img_target_labels, size=16)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_uuid":"f99f8c9b1bfe0474f27b72005e7708b6d9fd091a","trusted":true},"source":["#### Define the CNN Model"]},{"cell_type":"code","execution_count":196,"metadata":{"_uuid":"16954f2ed80f6ecceff5b48e7566415857432a76","trusted":true},"outputs":[{"data":{"text/plain":["Net(\n","  (conv_block): Sequential(\n","    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace=True)\n","    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (linear_block): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=6272, out_features=128, bias=True)\n","    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): ReLU(inplace=True)\n","    (4): Dropout(p=0.5, inplace=False)\n","    (5): Linear(in_features=128, out_features=64, bias=True)\n","    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): ReLU(inplace=True)\n","    (8): Dropout(p=0.5, inplace=False)\n","    (9): Linear(in_features=64, out_features=10, bias=True)\n","  )\n",")"]},"execution_count":196,"metadata":{},"output_type":"execute_result"}],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        \n","        self.conv_block = nn.Sequential(\n","            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2) \n","        )\n","        \n","        self.linear_block = nn.Sequential(\n","            nn.Dropout(p=0.5),\n","            nn.Linear(128*7*7, 128),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.5),\n","            nn.Linear(128, 64),\n","            nn.BatchNorm1d(64),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.5),\n","            nn.Linear(64, 10)\n","        )\n","        \n","    def forward(self, x):\n","        x = self.conv_block(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.linear_block(x)\n","        \n","        return x\n","conv_model = Net()\n","conv_model"]},{"cell_type":"markdown","metadata":{"_uuid":"8c78e04e0466bb60c949f78e0ebb68e1bf5f34a5","trusted":true},"source":["#### Define the optimizer and loss functions"]},{"cell_type":"code","execution_count":197,"metadata":{"_uuid":"1ea02395180c3997298a4bae8f21f8a26aafb5c4","trusted":true},"outputs":[],"source":["optimizer = optim.Adam(params=conv_model.parameters(), lr=0.003)\n","criterion = nn.CrossEntropyLoss()\n","\n","exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n","\n","if torch.cuda.is_available():\n","    conv_model = conv_model.cuda()\n","    criterion = criterion.cuda()"]},{"cell_type":"markdown","metadata":{"_uuid":"ead9edefdda79f314421cefe8b174eb22f3502a5","trusted":true},"source":["#### Training the Model"]},{"cell_type":"code","execution_count":198,"metadata":{"_uuid":"7a6d0608892e522c76c7616dcd67c740b792f528","trusted":true},"outputs":[],"source":["training_losses = np.array([])\n","validation_losses = np.array([])\n","training_accuracies = np.array([])\n","validation_accuracies = np.array([])\n","\n","def train_model(num_epoch):\n","    conv_model.train()\n","    exp_lr_scheduler.step()\n","    \n","    total_loss = 0\n","    correct_predictions = 0\n","    total_samples = 0\n","\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data = data.unsqueeze(1)\n","        if torch.cuda.is_available():\n","            data = data.cuda()\n","            target = target.cuda()\n","            \n","        optimizer.zero_grad()\n","        output = conv_model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # Accumulate loss\n","        total_loss += loss.item()\n","        \n","        # Calculate accuracy for the batch\n","        _, predicted = output.max(1)\n","        correct_predictions += (predicted == target).sum().item()\n","        total_samples += target.size(0)\n","        \n","        if (batch_idx + 1) % 100 == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                num_epoch, (batch_idx + 1) * len(data), len(train_loader.dataset),\n","                100. * (batch_idx + 1) / len(train_loader), loss.item()))\n","    \n","    # Calculate average loss and accuracy for the epoch\n","    average_loss = total_loss / len(train_loader)\n","    accuracy = correct_predictions / total_samples\n","    \n","    # Record training metrics\n","    np.append(training_losses, average_loss)\n","    np.append(training_accuracies, accuracy)\n","\n","def evaluate(data_loader):\n","    conv_model.eval()\n","    total_loss = 0\n","    correct_predictions = 0\n","    total_samples = 0\n","    \n","    with torch.no_grad():\n","        for data, target in data_loader:\n","            data = data.unsqueeze(1)\n","            if torch.cuda.is_available():\n","                data = data.cuda()\n","                target = target.cuda()\n","\n","            output = conv_model(data)\n","            loss = criterion(output, target)\n","            total_loss += loss.item()\n","\n","            # Calculate accuracy\n","            _, predicted = output.max(1)\n","            correct_predictions += (predicted == target).sum().item()\n","            total_samples += target.size(0)\n","        \n","    average_loss = total_loss / len(data_loader)\n","    accuracy = correct_predictions / total_samples\n","\n","    # Record validation metrics\n","    np.append(validation_losses, average_loss)\n","    np.append(validation_accuracies, accuracy)\n","    \n","    print('\\nValidation - Average Loss: {:.4f}, Accuracy: {:.3f}%\\n'.format(\n","        average_loss, 100. * accuracy))\n","\n","# After training, plot the metrics\n","def plot_metrics():\n","    epochs = list(range(1, len(training_losses) + 1))\n","    \n","    # Plot losses\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(epochs, training_losses, linestyle='-', label='Training Loss')\n","    plt.plot(epochs, validation_losses, linestyle='-', label='Validation Loss')\n","    plt.title('Training and Validation Loss Over Epochs')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.grid(True)\n","    plt.legend()\n","    plt.savefig(\"MNIST_CNN_loss.jpg\", dpi = 1000)\n","    plt.show()\n","    \n","    # Plot accuracies\n","    plt.figure(figsize=(10, 6))\n","    plt.plot(epochs, training_accuracies * 100., linestyle='-', label='Training Accuracy')\n","    plt.plot(epochs, validation_accuracies * 100., linestyle='-', label='Validation Accuracy')\n","    plt.title('Training and Validation Accuracy Over Epochs')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.grid(True)\n","    plt.legend()\n","    plt.savefig(\"MNIST_CNN_accuracy.jpg\", dpi = 1000)\n","    plt.show()"]},{"cell_type":"code","execution_count":199,"metadata":{"_uuid":"aa9e16954b11b99d018779f3322285a6c6ddfaf2","scrolled":true,"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/ginta/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"]},{"name":"stdout","output_type":"stream","text":["Train Epoch: 0 [200/33600 (1%)]\tLoss: 2.343941\n","Train Epoch: 0 [400/33600 (1%)]\tLoss: 1.247292\n","Train Epoch: 0 [600/33600 (2%)]\tLoss: 2.452507\n","Train Epoch: 0 [800/33600 (2%)]\tLoss: 2.518236\n","Train Epoch: 0 [1000/33600 (3%)]\tLoss: 2.256964\n","Train Epoch: 0 [1200/33600 (4%)]\tLoss: 2.128230\n","Train Epoch: 0 [1400/33600 (4%)]\tLoss: 1.907578\n","Train Epoch: 0 [1600/33600 (5%)]\tLoss: 3.196615\n","Train Epoch: 0 [1800/33600 (5%)]\tLoss: 2.858004\n","Train Epoch: 0 [2000/33600 (6%)]\tLoss: 2.948783\n","Train Epoch: 0 [2200/33600 (7%)]\tLoss: 2.374839\n","Train Epoch: 0 [2400/33600 (7%)]\tLoss: 2.747944\n","Train Epoch: 0 [2600/33600 (8%)]\tLoss: 1.660208\n","Train Epoch: 0 [2800/33600 (8%)]\tLoss: 2.236449\n","Train Epoch: 0 [3000/33600 (9%)]\tLoss: 2.735335\n","Train Epoch: 0 [3200/33600 (10%)]\tLoss: 2.288576\n","Train Epoch: 0 [3400/33600 (10%)]\tLoss: 2.399826\n","Train Epoch: 0 [3600/33600 (11%)]\tLoss: 2.222115\n","Train Epoch: 0 [3800/33600 (11%)]\tLoss: 2.045804\n","Train Epoch: 0 [4000/33600 (12%)]\tLoss: 2.387335\n","Train Epoch: 0 [4200/33600 (12%)]\tLoss: 1.554192\n","Train Epoch: 0 [4400/33600 (13%)]\tLoss: 1.540205\n","Train Epoch: 0 [4600/33600 (14%)]\tLoss: 2.324587\n","Train Epoch: 0 [4800/33600 (14%)]\tLoss: 1.927323\n","Train Epoch: 0 [5000/33600 (15%)]\tLoss: 1.954179\n","Train Epoch: 0 [5200/33600 (15%)]\tLoss: 1.892342\n","Train Epoch: 0 [5400/33600 (16%)]\tLoss: 1.712698\n","Train Epoch: 0 [5600/33600 (17%)]\tLoss: 2.016048\n","Train Epoch: 0 [5800/33600 (17%)]\tLoss: 2.619582\n","Train Epoch: 0 [6000/33600 (18%)]\tLoss: 1.432972\n","Train Epoch: 0 [6200/33600 (18%)]\tLoss: 1.686173\n","Train Epoch: 0 [6400/33600 (19%)]\tLoss: 1.417569\n","Train Epoch: 0 [6600/33600 (20%)]\tLoss: 2.334857\n","Train Epoch: 0 [6800/33600 (20%)]\tLoss: 1.891165\n","Train Epoch: 0 [7000/33600 (21%)]\tLoss: 2.218612\n","Train Epoch: 0 [7200/33600 (21%)]\tLoss: 2.228352\n","Train Epoch: 0 [7400/33600 (22%)]\tLoss: 1.779883\n","Train Epoch: 0 [7600/33600 (23%)]\tLoss: 2.204660\n","Train Epoch: 0 [7800/33600 (23%)]\tLoss: 3.245970\n","Train Epoch: 0 [8000/33600 (24%)]\tLoss: 1.660009\n","Train Epoch: 0 [8200/33600 (24%)]\tLoss: 1.367844\n","Train Epoch: 0 [8400/33600 (25%)]\tLoss: 1.939986\n","Train Epoch: 0 [8600/33600 (26%)]\tLoss: 2.772937\n","Train Epoch: 0 [8800/33600 (26%)]\tLoss: 2.696362\n","Train Epoch: 0 [9000/33600 (27%)]\tLoss: 2.145094\n","Train Epoch: 0 [9200/33600 (27%)]\tLoss: 2.003518\n","Train Epoch: 0 [9400/33600 (28%)]\tLoss: 1.899113\n","Train Epoch: 0 [9600/33600 (29%)]\tLoss: 2.794654\n","Train Epoch: 0 [9800/33600 (29%)]\tLoss: 1.652925\n","Train Epoch: 0 [10000/33600 (30%)]\tLoss: 1.614022\n","Train Epoch: 0 [10200/33600 (30%)]\tLoss: 2.206955\n","Train Epoch: 0 [10400/33600 (31%)]\tLoss: 1.817563\n","Train Epoch: 0 [10600/33600 (32%)]\tLoss: 1.802340\n","Train Epoch: 0 [10800/33600 (32%)]\tLoss: 2.431999\n","Train Epoch: 0 [11000/33600 (33%)]\tLoss: 2.412130\n","Train Epoch: 0 [11200/33600 (33%)]\tLoss: 2.017992\n","Train Epoch: 0 [11400/33600 (34%)]\tLoss: 1.914740\n","Train Epoch: 0 [11600/33600 (35%)]\tLoss: 2.162992\n","Train Epoch: 0 [11800/33600 (35%)]\tLoss: 1.254469\n","Train Epoch: 0 [12000/33600 (36%)]\tLoss: 2.150729\n","Train Epoch: 0 [12200/33600 (36%)]\tLoss: 1.666131\n","Train Epoch: 0 [12400/33600 (37%)]\tLoss: 1.763480\n","Train Epoch: 0 [12600/33600 (38%)]\tLoss: 1.771685\n","Train Epoch: 0 [12800/33600 (38%)]\tLoss: 2.481525\n","Train Epoch: 0 [13000/33600 (39%)]\tLoss: 2.547372\n","Train Epoch: 0 [13200/33600 (39%)]\tLoss: 2.730414\n","Train Epoch: 0 [13400/33600 (40%)]\tLoss: 1.891451\n","Train Epoch: 0 [13600/33600 (40%)]\tLoss: 1.622046\n","Train Epoch: 0 [13800/33600 (41%)]\tLoss: 1.971087\n","Train Epoch: 0 [14000/33600 (42%)]\tLoss: 2.627054\n","Train Epoch: 0 [14200/33600 (42%)]\tLoss: 2.274132\n","Train Epoch: 0 [14400/33600 (43%)]\tLoss: 2.611538\n","Train Epoch: 0 [14600/33600 (43%)]\tLoss: 1.636288\n","Train Epoch: 0 [14800/33600 (44%)]\tLoss: 1.493363\n","Train Epoch: 0 [15000/33600 (45%)]\tLoss: 1.750787\n","Train Epoch: 0 [15200/33600 (45%)]\tLoss: 2.227537\n","Train Epoch: 0 [15400/33600 (46%)]\tLoss: 2.424150\n","Train Epoch: 0 [15600/33600 (46%)]\tLoss: 2.158819\n","Train Epoch: 0 [15800/33600 (47%)]\tLoss: 3.126985\n","Train Epoch: 0 [16000/33600 (48%)]\tLoss: 1.784256\n","Train Epoch: 0 [16200/33600 (48%)]\tLoss: 2.820184\n","Train Epoch: 0 [16400/33600 (49%)]\tLoss: 1.743138\n","Train Epoch: 0 [16600/33600 (49%)]\tLoss: 2.025139\n","Train Epoch: 0 [16800/33600 (50%)]\tLoss: 1.673282\n","Train Epoch: 0 [17000/33600 (51%)]\tLoss: 1.459465\n","Train Epoch: 0 [17200/33600 (51%)]\tLoss: 2.930960\n","Train Epoch: 0 [17400/33600 (52%)]\tLoss: 1.604325\n","Train Epoch: 0 [17600/33600 (52%)]\tLoss: 2.475168\n","Train Epoch: 0 [17800/33600 (53%)]\tLoss: 1.543118\n","Train Epoch: 0 [18000/33600 (54%)]\tLoss: 2.493138\n","Train Epoch: 0 [18200/33600 (54%)]\tLoss: 1.798794\n","Train Epoch: 0 [18400/33600 (55%)]\tLoss: 2.387943\n","Train Epoch: 0 [18600/33600 (55%)]\tLoss: 3.041802\n","Train Epoch: 0 [18800/33600 (56%)]\tLoss: 2.295439\n","Train Epoch: 0 [19000/33600 (57%)]\tLoss: 1.941341\n","Train Epoch: 0 [19200/33600 (57%)]\tLoss: 2.374544\n","Train Epoch: 0 [19400/33600 (58%)]\tLoss: 1.837734\n","Train Epoch: 0 [19600/33600 (58%)]\tLoss: 1.442844\n","Train Epoch: 0 [19800/33600 (59%)]\tLoss: 3.049620\n","Train Epoch: 0 [20000/33600 (60%)]\tLoss: 2.047092\n","Train Epoch: 0 [20200/33600 (60%)]\tLoss: 1.190685\n","Train Epoch: 0 [20400/33600 (61%)]\tLoss: 1.628713\n","Train Epoch: 0 [20600/33600 (61%)]\tLoss: 2.560030\n","Train Epoch: 0 [20800/33600 (62%)]\tLoss: 2.335368\n","Train Epoch: 0 [21000/33600 (62%)]\tLoss: 2.260171\n","Train Epoch: 0 [21200/33600 (63%)]\tLoss: 2.559270\n","Train Epoch: 0 [21400/33600 (64%)]\tLoss: 1.840953\n","Train Epoch: 0 [21600/33600 (64%)]\tLoss: 1.657422\n","Train Epoch: 0 [21800/33600 (65%)]\tLoss: 2.158180\n","Train Epoch: 0 [22000/33600 (65%)]\tLoss: 1.517437\n","Train Epoch: 0 [22200/33600 (66%)]\tLoss: 2.109973\n","Train Epoch: 0 [22400/33600 (67%)]\tLoss: 1.587691\n","Train Epoch: 0 [22600/33600 (67%)]\tLoss: 1.915972\n","Train Epoch: 0 [22800/33600 (68%)]\tLoss: 2.673469\n","Train Epoch: 0 [23000/33600 (68%)]\tLoss: 1.322951\n","Train Epoch: 0 [23200/33600 (69%)]\tLoss: 2.479196\n","Train Epoch: 0 [23400/33600 (70%)]\tLoss: 1.997489\n","Train Epoch: 0 [23600/33600 (70%)]\tLoss: 2.500388\n","Train Epoch: 0 [23800/33600 (71%)]\tLoss: 1.583658\n","Train Epoch: 0 [24000/33600 (71%)]\tLoss: 1.741670\n","Train Epoch: 0 [24200/33600 (72%)]\tLoss: 1.308172\n","Train Epoch: 0 [24400/33600 (73%)]\tLoss: 2.199715\n","Train Epoch: 0 [24600/33600 (73%)]\tLoss: 1.659501\n","Train Epoch: 0 [24800/33600 (74%)]\tLoss: 1.479569\n","Train Epoch: 0 [25000/33600 (74%)]\tLoss: 1.811014\n","Train Epoch: 0 [25200/33600 (75%)]\tLoss: 1.801811\n","Train Epoch: 0 [25400/33600 (76%)]\tLoss: 1.813423\n","Train Epoch: 0 [25600/33600 (76%)]\tLoss: 2.000460\n","Train Epoch: 0 [25800/33600 (77%)]\tLoss: 1.156656\n","Train Epoch: 0 [26000/33600 (77%)]\tLoss: 2.488703\n","Train Epoch: 0 [26200/33600 (78%)]\tLoss: 1.434250\n","Train Epoch: 0 [26400/33600 (79%)]\tLoss: 2.605992\n","Train Epoch: 0 [26600/33600 (79%)]\tLoss: 1.579067\n","Train Epoch: 0 [26800/33600 (80%)]\tLoss: 1.596741\n","Train Epoch: 0 [27000/33600 (80%)]\tLoss: 2.203188\n","Train Epoch: 0 [27200/33600 (81%)]\tLoss: 1.931772\n","Train Epoch: 0 [27400/33600 (82%)]\tLoss: 2.175390\n","Train Epoch: 0 [27600/33600 (82%)]\tLoss: 3.831858\n","Train Epoch: 0 [27800/33600 (83%)]\tLoss: 2.435647\n","Train Epoch: 0 [28000/33600 (83%)]\tLoss: 2.952475\n","Train Epoch: 0 [28200/33600 (84%)]\tLoss: 1.656856\n","Train Epoch: 0 [28400/33600 (85%)]\tLoss: 1.931127\n","Train Epoch: 0 [28600/33600 (85%)]\tLoss: 2.111628\n","Train Epoch: 0 [28800/33600 (86%)]\tLoss: 1.805265\n","Train Epoch: 0 [29000/33600 (86%)]\tLoss: 2.363561\n","Train Epoch: 0 [29200/33600 (87%)]\tLoss: 2.257100\n","Train Epoch: 0 [29400/33600 (88%)]\tLoss: 1.916549\n","Train Epoch: 0 [29600/33600 (88%)]\tLoss: 2.771544\n","Train Epoch: 0 [29800/33600 (89%)]\tLoss: 2.750777\n","Train Epoch: 0 [30000/33600 (89%)]\tLoss: 2.161417\n","Train Epoch: 0 [30200/33600 (90%)]\tLoss: 2.507923\n","Train Epoch: 0 [30400/33600 (90%)]\tLoss: 2.270202\n","Train Epoch: 0 [30600/33600 (91%)]\tLoss: 1.425776\n","Train Epoch: 0 [30800/33600 (92%)]\tLoss: 2.430472\n","Train Epoch: 0 [31000/33600 (92%)]\tLoss: 2.243745\n","Train Epoch: 0 [31200/33600 (93%)]\tLoss: 2.679969\n","Train Epoch: 0 [31400/33600 (93%)]\tLoss: 2.764701\n","Train Epoch: 0 [31600/33600 (94%)]\tLoss: 2.264332\n","Train Epoch: 0 [31800/33600 (95%)]\tLoss: 1.599518\n","Train Epoch: 0 [32000/33600 (95%)]\tLoss: 2.485419\n","Train Epoch: 0 [32200/33600 (96%)]\tLoss: 1.824144\n","Train Epoch: 0 [32400/33600 (96%)]\tLoss: 1.485058\n","Train Epoch: 0 [32600/33600 (97%)]\tLoss: 1.918727\n","Train Epoch: 0 [32800/33600 (98%)]\tLoss: 2.722126\n","Train Epoch: 0 [33000/33600 (98%)]\tLoss: 2.696195\n","Train Epoch: 0 [33200/33600 (99%)]\tLoss: 2.003614\n","Train Epoch: 0 [33400/33600 (99%)]\tLoss: 1.737678\n","Train Epoch: 0 [33600/33600 (100%)]\tLoss: 2.972780\n","\n","Validation - Average Loss: 1.8148, Accuracy: 46.488%\n","\n","Train Epoch: 1 [200/33600 (1%)]\tLoss: 2.354721\n","Train Epoch: 1 [400/33600 (1%)]\tLoss: 2.370807\n","Train Epoch: 1 [600/33600 (2%)]\tLoss: 1.732227\n","Train Epoch: 1 [800/33600 (2%)]\tLoss: 1.863171\n","Train Epoch: 1 [1000/33600 (3%)]\tLoss: 2.653847\n","Train Epoch: 1 [1200/33600 (4%)]\tLoss: 1.585205\n","Train Epoch: 1 [1400/33600 (4%)]\tLoss: 2.041900\n","Train Epoch: 1 [1600/33600 (5%)]\tLoss: 1.645506\n","Train Epoch: 1 [1800/33600 (5%)]\tLoss: 1.584173\n","Train Epoch: 1 [2000/33600 (6%)]\tLoss: 2.035929\n","Train Epoch: 1 [2200/33600 (7%)]\tLoss: 2.190050\n","Train Epoch: 1 [2400/33600 (7%)]\tLoss: 2.119466\n","Train Epoch: 1 [2600/33600 (8%)]\tLoss: 1.675963\n","Train Epoch: 1 [2800/33600 (8%)]\tLoss: 2.183441\n","Train Epoch: 1 [3000/33600 (9%)]\tLoss: 2.228435\n","Train Epoch: 1 [3200/33600 (10%)]\tLoss: 3.186420\n","Train Epoch: 1 [3400/33600 (10%)]\tLoss: 2.318958\n","Train Epoch: 1 [3600/33600 (11%)]\tLoss: 2.482653\n","Train Epoch: 1 [3800/33600 (11%)]\tLoss: 2.081295\n","Train Epoch: 1 [4000/33600 (12%)]\tLoss: 2.788183\n","Train Epoch: 1 [4200/33600 (12%)]\tLoss: 2.102983\n","Train Epoch: 1 [4400/33600 (13%)]\tLoss: 2.622640\n","Train Epoch: 1 [4600/33600 (14%)]\tLoss: 2.568877\n","Train Epoch: 1 [4800/33600 (14%)]\tLoss: 1.106893\n","Train Epoch: 1 [5000/33600 (15%)]\tLoss: 1.765878\n","Train Epoch: 1 [5200/33600 (15%)]\tLoss: 1.815569\n","Train Epoch: 1 [5400/33600 (16%)]\tLoss: 2.071712\n","Train Epoch: 1 [5600/33600 (17%)]\tLoss: 2.531049\n","Train Epoch: 1 [5800/33600 (17%)]\tLoss: 1.871789\n","Train Epoch: 1 [6000/33600 (18%)]\tLoss: 1.827042\n","Train Epoch: 1 [6200/33600 (18%)]\tLoss: 2.070930\n","Train Epoch: 1 [6400/33600 (19%)]\tLoss: 2.314425\n","Train Epoch: 1 [6600/33600 (20%)]\tLoss: 2.250251\n","Train Epoch: 1 [6800/33600 (20%)]\tLoss: 1.644388\n","Train Epoch: 1 [7000/33600 (21%)]\tLoss: 2.416565\n","Train Epoch: 1 [7200/33600 (21%)]\tLoss: 1.741973\n","Train Epoch: 1 [7400/33600 (22%)]\tLoss: 2.140912\n","Train Epoch: 1 [7600/33600 (23%)]\tLoss: 2.427030\n","Train Epoch: 1 [7800/33600 (23%)]\tLoss: 1.658725\n","Train Epoch: 1 [8000/33600 (24%)]\tLoss: 2.254200\n","Train Epoch: 1 [8200/33600 (24%)]\tLoss: 2.023900\n","Train Epoch: 1 [8400/33600 (25%)]\tLoss: 1.988906\n","Train Epoch: 1 [8600/33600 (26%)]\tLoss: 2.367037\n","Train Epoch: 1 [8800/33600 (26%)]\tLoss: 2.222084\n","Train Epoch: 1 [9000/33600 (27%)]\tLoss: 1.816465\n","Train Epoch: 1 [9200/33600 (27%)]\tLoss: 2.261781\n","Train Epoch: 1 [9400/33600 (28%)]\tLoss: 1.656399\n","Train Epoch: 1 [9600/33600 (29%)]\tLoss: 2.003690\n","Train Epoch: 1 [9800/33600 (29%)]\tLoss: 2.719468\n","Train Epoch: 1 [10000/33600 (30%)]\tLoss: 2.281288\n","Train Epoch: 1 [10200/33600 (30%)]\tLoss: 2.533403\n","Train Epoch: 1 [10400/33600 (31%)]\tLoss: 2.664543\n","Train Epoch: 1 [10600/33600 (32%)]\tLoss: 2.749092\n","Train Epoch: 1 [10800/33600 (32%)]\tLoss: 1.369318\n","Train Epoch: 1 [11000/33600 (33%)]\tLoss: 2.364067\n","Train Epoch: 1 [11200/33600 (33%)]\tLoss: 2.890939\n","Train Epoch: 1 [11400/33600 (34%)]\tLoss: 1.920364\n","Train Epoch: 1 [11600/33600 (35%)]\tLoss: 2.208323\n","Train Epoch: 1 [11800/33600 (35%)]\tLoss: 2.996634\n","Train Epoch: 1 [12000/33600 (36%)]\tLoss: 2.643685\n","Train Epoch: 1 [12200/33600 (36%)]\tLoss: 2.205150\n","Train Epoch: 1 [12400/33600 (37%)]\tLoss: 1.911477\n","Train Epoch: 1 [12600/33600 (38%)]\tLoss: 1.840894\n","Train Epoch: 1 [12800/33600 (38%)]\tLoss: 1.402554\n","Train Epoch: 1 [13000/33600 (39%)]\tLoss: 2.273515\n","Train Epoch: 1 [13200/33600 (39%)]\tLoss: 2.394717\n","Train Epoch: 1 [13400/33600 (40%)]\tLoss: 2.221707\n","Train Epoch: 1 [13600/33600 (40%)]\tLoss: 2.355506\n","Train Epoch: 1 [13800/33600 (41%)]\tLoss: 2.261047\n","Train Epoch: 1 [14000/33600 (42%)]\tLoss: 2.136600\n","Train Epoch: 1 [14200/33600 (42%)]\tLoss: 2.279900\n","Train Epoch: 1 [14400/33600 (43%)]\tLoss: 2.152111\n","Train Epoch: 1 [14600/33600 (43%)]\tLoss: 1.757763\n","Train Epoch: 1 [14800/33600 (44%)]\tLoss: 2.056281\n","Train Epoch: 1 [15000/33600 (45%)]\tLoss: 1.882144\n","Train Epoch: 1 [15200/33600 (45%)]\tLoss: 2.144780\n","Train Epoch: 1 [15400/33600 (46%)]\tLoss: 2.879619\n","Train Epoch: 1 [15600/33600 (46%)]\tLoss: 2.608335\n","Train Epoch: 1 [15800/33600 (47%)]\tLoss: 1.294432\n","Train Epoch: 1 [16000/33600 (48%)]\tLoss: 1.668224\n","Train Epoch: 1 [16200/33600 (48%)]\tLoss: 2.219767\n","Train Epoch: 1 [16400/33600 (49%)]\tLoss: 2.080656\n","Train Epoch: 1 [16600/33600 (49%)]\tLoss: 2.118098\n","Train Epoch: 1 [16800/33600 (50%)]\tLoss: 3.464406\n","Train Epoch: 1 [17000/33600 (51%)]\tLoss: 1.652031\n","Train Epoch: 1 [17200/33600 (51%)]\tLoss: 2.227112\n","Train Epoch: 1 [17400/33600 (52%)]\tLoss: 2.228384\n","Train Epoch: 1 [17600/33600 (52%)]\tLoss: 1.882599\n","Train Epoch: 1 [17800/33600 (53%)]\tLoss: 1.574123\n","Train Epoch: 1 [18000/33600 (54%)]\tLoss: 2.638380\n","Train Epoch: 1 [18200/33600 (54%)]\tLoss: 2.248882\n","Train Epoch: 1 [18400/33600 (55%)]\tLoss: 2.366145\n","Train Epoch: 1 [18600/33600 (55%)]\tLoss: 3.335860\n","Train Epoch: 1 [18800/33600 (56%)]\tLoss: 2.960166\n","Train Epoch: 1 [19000/33600 (57%)]\tLoss: 2.288028\n","Train Epoch: 1 [19200/33600 (57%)]\tLoss: 1.591679\n","Train Epoch: 1 [19400/33600 (58%)]\tLoss: 2.107942\n","Train Epoch: 1 [19600/33600 (58%)]\tLoss: 1.453855\n","Train Epoch: 1 [19800/33600 (59%)]\tLoss: 1.861959\n","Train Epoch: 1 [20000/33600 (60%)]\tLoss: 2.283689\n","Train Epoch: 1 [20200/33600 (60%)]\tLoss: 1.923117\n","Train Epoch: 1 [20400/33600 (61%)]\tLoss: 1.812551\n","Train Epoch: 1 [20600/33600 (61%)]\tLoss: 2.425028\n","Train Epoch: 1 [20800/33600 (62%)]\tLoss: 2.083125\n","Train Epoch: 1 [21000/33600 (62%)]\tLoss: 2.149727\n","Train Epoch: 1 [21200/33600 (63%)]\tLoss: 2.171256\n","Train Epoch: 1 [21400/33600 (64%)]\tLoss: 1.032133\n","Train Epoch: 1 [21600/33600 (64%)]\tLoss: 1.800661\n","Train Epoch: 1 [21800/33600 (65%)]\tLoss: 2.186217\n","Train Epoch: 1 [22000/33600 (65%)]\tLoss: 2.383180\n","Train Epoch: 1 [22200/33600 (66%)]\tLoss: 2.075150\n","Train Epoch: 1 [22400/33600 (67%)]\tLoss: 2.545808\n","Train Epoch: 1 [22600/33600 (67%)]\tLoss: 2.081339\n","Train Epoch: 1 [22800/33600 (68%)]\tLoss: 2.087867\n","Train Epoch: 1 [23000/33600 (68%)]\tLoss: 2.672822\n","Train Epoch: 1 [23200/33600 (69%)]\tLoss: 2.068429\n","Train Epoch: 1 [23400/33600 (70%)]\tLoss: 1.917915\n","Train Epoch: 1 [23600/33600 (70%)]\tLoss: 2.009143\n","Train Epoch: 1 [23800/33600 (71%)]\tLoss: 2.344748\n","Train Epoch: 1 [24000/33600 (71%)]\tLoss: 2.110419\n","Train Epoch: 1 [24200/33600 (72%)]\tLoss: 1.631159\n","Train Epoch: 1 [24400/33600 (73%)]\tLoss: 2.294827\n","Train Epoch: 1 [24600/33600 (73%)]\tLoss: 2.404969\n","Train Epoch: 1 [24800/33600 (74%)]\tLoss: 1.410977\n","Train Epoch: 1 [25000/33600 (74%)]\tLoss: 1.102593\n","Train Epoch: 1 [25200/33600 (75%)]\tLoss: 3.492426\n","Train Epoch: 1 [25400/33600 (76%)]\tLoss: 1.830930\n","Train Epoch: 1 [25600/33600 (76%)]\tLoss: 2.078439\n","Train Epoch: 1 [25800/33600 (77%)]\tLoss: 2.183977\n","Train Epoch: 1 [26000/33600 (77%)]\tLoss: 1.976094\n","Train Epoch: 1 [26200/33600 (78%)]\tLoss: 1.838989\n","Train Epoch: 1 [26400/33600 (79%)]\tLoss: 2.015751\n","Train Epoch: 1 [26600/33600 (79%)]\tLoss: 1.735179\n","Train Epoch: 1 [26800/33600 (80%)]\tLoss: 2.114365\n","Train Epoch: 1 [27000/33600 (80%)]\tLoss: 2.008677\n","Train Epoch: 1 [27200/33600 (81%)]\tLoss: 1.881053\n","Train Epoch: 1 [27400/33600 (82%)]\tLoss: 1.012987\n","Train Epoch: 1 [27600/33600 (82%)]\tLoss: 2.108486\n","Train Epoch: 1 [27800/33600 (83%)]\tLoss: 2.396835\n","Train Epoch: 1 [28000/33600 (83%)]\tLoss: 2.005651\n","Train Epoch: 1 [28200/33600 (84%)]\tLoss: 2.137553\n","Train Epoch: 1 [28400/33600 (85%)]\tLoss: 2.009361\n","Train Epoch: 1 [28600/33600 (85%)]\tLoss: 2.215366\n","Train Epoch: 1 [28800/33600 (86%)]\tLoss: 1.908211\n","Train Epoch: 1 [29000/33600 (86%)]\tLoss: 2.078874\n","Train Epoch: 1 [29200/33600 (87%)]\tLoss: 1.300033\n","Train Epoch: 1 [29400/33600 (88%)]\tLoss: 1.931677\n","Train Epoch: 1 [29600/33600 (88%)]\tLoss: 2.876337\n","Train Epoch: 1 [29800/33600 (89%)]\tLoss: 2.067383\n","Train Epoch: 1 [30000/33600 (89%)]\tLoss: 1.720378\n","Train Epoch: 1 [30200/33600 (90%)]\tLoss: 1.480461\n","Train Epoch: 1 [30400/33600 (90%)]\tLoss: 3.077424\n","Train Epoch: 1 [30600/33600 (91%)]\tLoss: 2.459508\n","Train Epoch: 1 [30800/33600 (92%)]\tLoss: 2.622128\n","Train Epoch: 1 [31000/33600 (92%)]\tLoss: 1.399759\n","Train Epoch: 1 [31200/33600 (93%)]\tLoss: 2.347337\n","Train Epoch: 1 [31400/33600 (93%)]\tLoss: 2.178434\n","Train Epoch: 1 [31600/33600 (94%)]\tLoss: 2.442973\n","Train Epoch: 1 [31800/33600 (95%)]\tLoss: 2.088115\n","Train Epoch: 1 [32000/33600 (95%)]\tLoss: 2.240269\n","Train Epoch: 1 [32200/33600 (96%)]\tLoss: 2.041591\n","Train Epoch: 1 [32400/33600 (96%)]\tLoss: 1.704512\n","Train Epoch: 1 [32600/33600 (97%)]\tLoss: 2.595919\n","Train Epoch: 1 [32800/33600 (98%)]\tLoss: 2.440484\n","Train Epoch: 1 [33000/33600 (98%)]\tLoss: 2.610270\n","Train Epoch: 1 [33200/33600 (99%)]\tLoss: 2.200761\n","Train Epoch: 1 [33400/33600 (99%)]\tLoss: 2.406913\n","Train Epoch: 1 [33600/33600 (100%)]\tLoss: 2.431790\n","\n","Validation - Average Loss: 1.8900, Accuracy: 41.214%\n","\n","Train Epoch: 2 [200/33600 (1%)]\tLoss: 1.915773\n","Train Epoch: 2 [400/33600 (1%)]\tLoss: 1.825179\n","Train Epoch: 2 [600/33600 (2%)]\tLoss: 1.951715\n","Train Epoch: 2 [800/33600 (2%)]\tLoss: 1.918286\n","Train Epoch: 2 [1000/33600 (3%)]\tLoss: 2.019272\n","Train Epoch: 2 [1200/33600 (4%)]\tLoss: 2.030602\n","Train Epoch: 2 [1400/33600 (4%)]\tLoss: 2.084763\n","Train Epoch: 2 [1600/33600 (5%)]\tLoss: 1.960700\n","Train Epoch: 2 [1800/33600 (5%)]\tLoss: 1.461114\n","Train Epoch: 2 [2000/33600 (6%)]\tLoss: 1.736105\n","Train Epoch: 2 [2200/33600 (7%)]\tLoss: 2.513929\n","Train Epoch: 2 [2400/33600 (7%)]\tLoss: 1.791834\n","Train Epoch: 2 [2600/33600 (8%)]\tLoss: 1.846357\n","Train Epoch: 2 [2800/33600 (8%)]\tLoss: 1.412351\n","Train Epoch: 2 [3000/33600 (9%)]\tLoss: 2.401908\n","Train Epoch: 2 [3200/33600 (10%)]\tLoss: 2.005487\n","Train Epoch: 2 [3400/33600 (10%)]\tLoss: 2.312675\n","Train Epoch: 2 [3600/33600 (11%)]\tLoss: 1.798294\n","Train Epoch: 2 [3800/33600 (11%)]\tLoss: 1.998440\n","Train Epoch: 2 [4000/33600 (12%)]\tLoss: 2.270207\n","Train Epoch: 2 [4200/33600 (12%)]\tLoss: 2.838035\n","Train Epoch: 2 [4400/33600 (13%)]\tLoss: 1.462614\n","Train Epoch: 2 [4600/33600 (14%)]\tLoss: 1.608848\n","Train Epoch: 2 [4800/33600 (14%)]\tLoss: 2.133703\n","Train Epoch: 2 [5000/33600 (15%)]\tLoss: 3.285121\n","Train Epoch: 2 [5200/33600 (15%)]\tLoss: 2.808003\n","Train Epoch: 2 [5400/33600 (16%)]\tLoss: 2.256872\n","Train Epoch: 2 [5600/33600 (17%)]\tLoss: 2.320282\n","Train Epoch: 2 [5800/33600 (17%)]\tLoss: 1.630055\n","Train Epoch: 2 [6000/33600 (18%)]\tLoss: 2.045372\n","Train Epoch: 2 [6200/33600 (18%)]\tLoss: 2.440738\n","Train Epoch: 2 [6400/33600 (19%)]\tLoss: 2.529315\n","Train Epoch: 2 [6600/33600 (20%)]\tLoss: 1.181566\n","Train Epoch: 2 [6800/33600 (20%)]\tLoss: 1.642738\n","Train Epoch: 2 [7000/33600 (21%)]\tLoss: 1.881368\n","Train Epoch: 2 [7200/33600 (21%)]\tLoss: 2.415949\n","Train Epoch: 2 [7400/33600 (22%)]\tLoss: 1.894675\n","Train Epoch: 2 [7600/33600 (23%)]\tLoss: 2.711391\n","Train Epoch: 2 [7800/33600 (23%)]\tLoss: 1.854537\n","Train Epoch: 2 [8000/33600 (24%)]\tLoss: 2.159276\n","Train Epoch: 2 [8200/33600 (24%)]\tLoss: 1.715755\n","Train Epoch: 2 [8400/33600 (25%)]\tLoss: 1.745913\n","Train Epoch: 2 [8600/33600 (26%)]\tLoss: 2.023162\n","Train Epoch: 2 [8800/33600 (26%)]\tLoss: 2.468416\n","Train Epoch: 2 [9000/33600 (27%)]\tLoss: 1.877178\n","Train Epoch: 2 [9200/33600 (27%)]\tLoss: 2.821923\n","Train Epoch: 2 [9400/33600 (28%)]\tLoss: 2.536239\n","Train Epoch: 2 [9600/33600 (29%)]\tLoss: 1.245934\n","Train Epoch: 2 [9800/33600 (29%)]\tLoss: 2.227907\n","Train Epoch: 2 [10000/33600 (30%)]\tLoss: 2.288879\n","Train Epoch: 2 [10200/33600 (30%)]\tLoss: 1.523110\n","Train Epoch: 2 [10400/33600 (31%)]\tLoss: 1.892378\n","Train Epoch: 2 [10600/33600 (32%)]\tLoss: 2.043838\n","Train Epoch: 2 [10800/33600 (32%)]\tLoss: 1.763324\n","Train Epoch: 2 [11000/33600 (33%)]\tLoss: 2.598842\n","Train Epoch: 2 [11200/33600 (33%)]\tLoss: 1.620652\n","Train Epoch: 2 [11400/33600 (34%)]\tLoss: 1.851270\n","Train Epoch: 2 [11600/33600 (35%)]\tLoss: 2.354735\n","Train Epoch: 2 [11800/33600 (35%)]\tLoss: 2.068438\n","Train Epoch: 2 [12000/33600 (36%)]\tLoss: 2.068351\n","Train Epoch: 2 [12200/33600 (36%)]\tLoss: 2.634285\n","Train Epoch: 2 [12400/33600 (37%)]\tLoss: 2.049099\n","Train Epoch: 2 [12600/33600 (38%)]\tLoss: 2.067581\n","Train Epoch: 2 [12800/33600 (38%)]\tLoss: 2.093730\n","Train Epoch: 2 [13000/33600 (39%)]\tLoss: 2.225868\n","Train Epoch: 2 [13200/33600 (39%)]\tLoss: 2.035510\n","Train Epoch: 2 [13400/33600 (40%)]\tLoss: 1.518885\n","Train Epoch: 2 [13600/33600 (40%)]\tLoss: 2.553689\n","Train Epoch: 2 [13800/33600 (41%)]\tLoss: 1.936486\n","Train Epoch: 2 [14000/33600 (42%)]\tLoss: 1.935360\n","Train Epoch: 2 [14200/33600 (42%)]\tLoss: 1.789883\n","Train Epoch: 2 [14400/33600 (43%)]\tLoss: 1.512649\n","Train Epoch: 2 [14600/33600 (43%)]\tLoss: 2.197543\n","Train Epoch: 2 [14800/33600 (44%)]\tLoss: 1.705866\n","Train Epoch: 2 [15000/33600 (45%)]\tLoss: 2.270772\n","Train Epoch: 2 [15200/33600 (45%)]\tLoss: 1.896459\n","Train Epoch: 2 [15400/33600 (46%)]\tLoss: 2.185464\n","Train Epoch: 2 [15600/33600 (46%)]\tLoss: 1.723483\n","Train Epoch: 2 [15800/33600 (47%)]\tLoss: 2.189628\n","Train Epoch: 2 [16000/33600 (48%)]\tLoss: 1.231677\n","Train Epoch: 2 [16200/33600 (48%)]\tLoss: 2.545662\n","Train Epoch: 2 [16400/33600 (49%)]\tLoss: 1.795067\n","Train Epoch: 2 [16600/33600 (49%)]\tLoss: 1.901351\n","Train Epoch: 2 [16800/33600 (50%)]\tLoss: 1.659848\n","Train Epoch: 2 [17000/33600 (51%)]\tLoss: 1.917840\n","Train Epoch: 2 [17200/33600 (51%)]\tLoss: 2.788412\n","Train Epoch: 2 [17400/33600 (52%)]\tLoss: 2.059242\n","Train Epoch: 2 [17600/33600 (52%)]\tLoss: 2.884759\n","Train Epoch: 2 [17800/33600 (53%)]\tLoss: 1.676516\n","Train Epoch: 2 [18000/33600 (54%)]\tLoss: 1.545165\n","Train Epoch: 2 [18200/33600 (54%)]\tLoss: 1.640711\n","Train Epoch: 2 [18400/33600 (55%)]\tLoss: 1.904434\n","Train Epoch: 2 [18600/33600 (55%)]\tLoss: 1.723043\n","Train Epoch: 2 [18800/33600 (56%)]\tLoss: 2.015173\n","Train Epoch: 2 [19000/33600 (57%)]\tLoss: 2.186490\n","Train Epoch: 2 [19200/33600 (57%)]\tLoss: 2.045379\n","Train Epoch: 2 [19400/33600 (58%)]\tLoss: 2.557328\n","Train Epoch: 2 [19600/33600 (58%)]\tLoss: 1.655957\n","Train Epoch: 2 [19800/33600 (59%)]\tLoss: 1.901870\n","Train Epoch: 2 [20000/33600 (60%)]\tLoss: 1.848244\n","Train Epoch: 2 [20200/33600 (60%)]\tLoss: 2.093973\n","Train Epoch: 2 [20400/33600 (61%)]\tLoss: 2.434963\n","Train Epoch: 2 [20600/33600 (61%)]\tLoss: 2.448185\n","Train Epoch: 2 [20800/33600 (62%)]\tLoss: 2.773757\n","Train Epoch: 2 [21000/33600 (62%)]\tLoss: 2.959865\n","Train Epoch: 2 [21200/33600 (63%)]\tLoss: 2.333442\n","Train Epoch: 2 [21400/33600 (64%)]\tLoss: 1.508960\n","Train Epoch: 2 [21600/33600 (64%)]\tLoss: 1.815512\n","Train Epoch: 2 [21800/33600 (65%)]\tLoss: 1.544822\n","Train Epoch: 2 [22000/33600 (65%)]\tLoss: 2.547765\n","Train Epoch: 2 [22200/33600 (66%)]\tLoss: 1.672777\n","Train Epoch: 2 [22400/33600 (67%)]\tLoss: 1.965351\n","Train Epoch: 2 [22600/33600 (67%)]\tLoss: 2.001316\n","Train Epoch: 2 [22800/33600 (68%)]\tLoss: 2.394693\n","Train Epoch: 2 [23000/33600 (68%)]\tLoss: 2.152828\n","Train Epoch: 2 [23200/33600 (69%)]\tLoss: 2.124953\n","Train Epoch: 2 [23400/33600 (70%)]\tLoss: 2.431653\n","Train Epoch: 2 [23600/33600 (70%)]\tLoss: 2.097640\n","Train Epoch: 2 [23800/33600 (71%)]\tLoss: 2.100515\n","Train Epoch: 2 [24000/33600 (71%)]\tLoss: 1.929140\n","Train Epoch: 2 [24200/33600 (72%)]\tLoss: 2.199844\n","Train Epoch: 2 [24400/33600 (73%)]\tLoss: 2.483982\n","Train Epoch: 2 [24600/33600 (73%)]\tLoss: 2.428224\n","Train Epoch: 2 [24800/33600 (74%)]\tLoss: 1.912792\n","Train Epoch: 2 [25000/33600 (74%)]\tLoss: 1.303552\n","Train Epoch: 2 [25200/33600 (75%)]\tLoss: 2.242483\n","Train Epoch: 2 [25400/33600 (76%)]\tLoss: 2.618177\n","Train Epoch: 2 [25600/33600 (76%)]\tLoss: 1.914753\n","Train Epoch: 2 [25800/33600 (77%)]\tLoss: 2.363307\n","Train Epoch: 2 [26000/33600 (77%)]\tLoss: 1.809447\n","Train Epoch: 2 [26200/33600 (78%)]\tLoss: 2.378972\n","Train Epoch: 2 [26400/33600 (79%)]\tLoss: 2.346529\n","Train Epoch: 2 [26600/33600 (79%)]\tLoss: 1.703928\n","Train Epoch: 2 [26800/33600 (80%)]\tLoss: 2.296282\n","Train Epoch: 2 [27000/33600 (80%)]\tLoss: 2.780147\n","Train Epoch: 2 [27200/33600 (81%)]\tLoss: 2.651355\n","Train Epoch: 2 [27400/33600 (82%)]\tLoss: 2.402909\n","Train Epoch: 2 [27600/33600 (82%)]\tLoss: 2.099106\n","Train Epoch: 2 [27800/33600 (83%)]\tLoss: 2.109608\n","Train Epoch: 2 [28000/33600 (83%)]\tLoss: 1.882865\n","Train Epoch: 2 [28200/33600 (84%)]\tLoss: 3.389728\n","Train Epoch: 2 [28400/33600 (85%)]\tLoss: 1.903929\n","Train Epoch: 2 [28600/33600 (85%)]\tLoss: 3.048318\n","Train Epoch: 2 [28800/33600 (86%)]\tLoss: 2.678469\n","Train Epoch: 2 [29000/33600 (86%)]\tLoss: 2.147298\n","Train Epoch: 2 [29200/33600 (87%)]\tLoss: 3.342738\n","Train Epoch: 2 [29400/33600 (88%)]\tLoss: 1.688262\n","Train Epoch: 2 [29600/33600 (88%)]\tLoss: 2.898900\n","Train Epoch: 2 [29800/33600 (89%)]\tLoss: 2.088835\n","Train Epoch: 2 [30000/33600 (89%)]\tLoss: 1.846919\n","Train Epoch: 2 [30200/33600 (90%)]\tLoss: 2.012748\n","Train Epoch: 2 [30400/33600 (90%)]\tLoss: 3.040379\n","Train Epoch: 2 [30600/33600 (91%)]\tLoss: 1.870232\n","Train Epoch: 2 [30800/33600 (92%)]\tLoss: 2.131780\n","Train Epoch: 2 [31000/33600 (92%)]\tLoss: 1.646388\n","Train Epoch: 2 [31200/33600 (93%)]\tLoss: 1.867438\n","Train Epoch: 2 [31400/33600 (93%)]\tLoss: 2.271754\n","Train Epoch: 2 [31600/33600 (94%)]\tLoss: 2.118707\n","Train Epoch: 2 [31800/33600 (95%)]\tLoss: 1.909663\n","Train Epoch: 2 [32000/33600 (95%)]\tLoss: 1.554214\n","Train Epoch: 2 [32200/33600 (96%)]\tLoss: 1.533319\n","Train Epoch: 2 [32400/33600 (96%)]\tLoss: 1.639382\n","Train Epoch: 2 [32600/33600 (97%)]\tLoss: 1.744501\n","Train Epoch: 2 [32800/33600 (98%)]\tLoss: 3.018321\n","Train Epoch: 2 [33000/33600 (98%)]\tLoss: 1.976140\n","Train Epoch: 2 [33200/33600 (99%)]\tLoss: 2.084197\n","Train Epoch: 2 [33400/33600 (99%)]\tLoss: 2.244772\n","Train Epoch: 2 [33600/33600 (100%)]\tLoss: 2.649397\n","\n","Validation - Average Loss: 2.0010, Accuracy: 37.310%\n","\n","Train Epoch: 3 [200/33600 (1%)]\tLoss: 2.021795\n","Train Epoch: 3 [400/33600 (1%)]\tLoss: 2.563329\n","Train Epoch: 3 [600/33600 (2%)]\tLoss: 2.184670\n","Train Epoch: 3 [800/33600 (2%)]\tLoss: 1.680745\n","Train Epoch: 3 [1000/33600 (3%)]\tLoss: 2.156922\n","Train Epoch: 3 [1200/33600 (4%)]\tLoss: 2.523385\n","Train Epoch: 3 [1400/33600 (4%)]\tLoss: 1.998766\n","Train Epoch: 3 [1600/33600 (5%)]\tLoss: 1.673912\n","Train Epoch: 3 [1800/33600 (5%)]\tLoss: 2.328076\n","Train Epoch: 3 [2000/33600 (6%)]\tLoss: 2.177999\n","Train Epoch: 3 [2200/33600 (7%)]\tLoss: 1.955831\n","Train Epoch: 3 [2400/33600 (7%)]\tLoss: 1.385870\n","Train Epoch: 3 [2600/33600 (8%)]\tLoss: 1.784484\n","Train Epoch: 3 [2800/33600 (8%)]\tLoss: 1.896923\n","Train Epoch: 3 [3000/33600 (9%)]\tLoss: 2.166932\n","Train Epoch: 3 [3200/33600 (10%)]\tLoss: 2.139264\n","Train Epoch: 3 [3400/33600 (10%)]\tLoss: 2.545937\n","Train Epoch: 3 [3600/33600 (11%)]\tLoss: 2.083801\n","Train Epoch: 3 [3800/33600 (11%)]\tLoss: 2.543604\n","Train Epoch: 3 [4000/33600 (12%)]\tLoss: 1.920485\n","Train Epoch: 3 [4200/33600 (12%)]\tLoss: 2.360415\n","Train Epoch: 3 [4400/33600 (13%)]\tLoss: 1.892466\n","Train Epoch: 3 [4600/33600 (14%)]\tLoss: 1.620808\n","Train Epoch: 3 [4800/33600 (14%)]\tLoss: 1.994163\n","Train Epoch: 3 [5000/33600 (15%)]\tLoss: 1.671315\n","Train Epoch: 3 [5200/33600 (15%)]\tLoss: 1.752692\n","Train Epoch: 3 [5400/33600 (16%)]\tLoss: 1.933191\n","Train Epoch: 3 [5600/33600 (17%)]\tLoss: 1.843097\n","Train Epoch: 3 [5800/33600 (17%)]\tLoss: 1.516650\n","Train Epoch: 3 [6000/33600 (18%)]\tLoss: 1.634603\n","Train Epoch: 3 [6200/33600 (18%)]\tLoss: 1.733671\n","Train Epoch: 3 [6400/33600 (19%)]\tLoss: 2.666298\n","Train Epoch: 3 [6600/33600 (20%)]\tLoss: 2.426149\n","Train Epoch: 3 [6800/33600 (20%)]\tLoss: 2.217300\n","Train Epoch: 3 [7000/33600 (21%)]\tLoss: 2.620501\n","Train Epoch: 3 [7200/33600 (21%)]\tLoss: 2.608948\n","Train Epoch: 3 [7400/33600 (22%)]\tLoss: 2.131592\n","Train Epoch: 3 [7600/33600 (23%)]\tLoss: 2.300428\n","Train Epoch: 3 [7800/33600 (23%)]\tLoss: 2.661483\n","Train Epoch: 3 [8000/33600 (24%)]\tLoss: 1.738746\n","Train Epoch: 3 [8200/33600 (24%)]\tLoss: 1.941997\n","Train Epoch: 3 [8400/33600 (25%)]\tLoss: 2.823872\n","Train Epoch: 3 [8600/33600 (26%)]\tLoss: 2.625476\n","Train Epoch: 3 [8800/33600 (26%)]\tLoss: 2.416784\n","Train Epoch: 3 [9000/33600 (27%)]\tLoss: 2.436405\n","Train Epoch: 3 [9200/33600 (27%)]\tLoss: 1.506039\n","Train Epoch: 3 [9400/33600 (28%)]\tLoss: 2.631975\n","Train Epoch: 3 [9600/33600 (29%)]\tLoss: 1.273596\n","Train Epoch: 3 [9800/33600 (29%)]\tLoss: 2.032016\n","Train Epoch: 3 [10000/33600 (30%)]\tLoss: 2.595387\n","Train Epoch: 3 [10200/33600 (30%)]\tLoss: 1.957204\n","Train Epoch: 3 [10400/33600 (31%)]\tLoss: 2.206380\n","Train Epoch: 3 [10600/33600 (32%)]\tLoss: 1.755528\n","Train Epoch: 3 [10800/33600 (32%)]\tLoss: 0.980631\n","Train Epoch: 3 [11000/33600 (33%)]\tLoss: 1.864194\n","Train Epoch: 3 [11200/33600 (33%)]\tLoss: 1.971488\n","Train Epoch: 3 [11400/33600 (34%)]\tLoss: 1.181997\n","Train Epoch: 3 [11600/33600 (35%)]\tLoss: 2.719048\n","Train Epoch: 3 [11800/33600 (35%)]\tLoss: 2.583336\n","Train Epoch: 3 [12000/33600 (36%)]\tLoss: 1.961168\n","Train Epoch: 3 [12200/33600 (36%)]\tLoss: 2.172981\n","Train Epoch: 3 [12400/33600 (37%)]\tLoss: 2.444209\n","Train Epoch: 3 [12600/33600 (38%)]\tLoss: 2.251328\n","Train Epoch: 3 [12800/33600 (38%)]\tLoss: 2.022005\n","Train Epoch: 3 [13000/33600 (39%)]\tLoss: 2.170000\n","Train Epoch: 3 [13200/33600 (39%)]\tLoss: 2.120320\n","Train Epoch: 3 [13400/33600 (40%)]\tLoss: 2.517608\n","Train Epoch: 3 [13600/33600 (40%)]\tLoss: 1.821700\n","Train Epoch: 3 [13800/33600 (41%)]\tLoss: 2.640988\n","Train Epoch: 3 [14000/33600 (42%)]\tLoss: 2.267379\n","Train Epoch: 3 [14200/33600 (42%)]\tLoss: 1.664525\n","Train Epoch: 3 [14400/33600 (43%)]\tLoss: 1.542843\n","Train Epoch: 3 [14600/33600 (43%)]\tLoss: 1.938695\n","Train Epoch: 3 [14800/33600 (44%)]\tLoss: 2.921831\n","Train Epoch: 3 [15000/33600 (45%)]\tLoss: 2.198345\n","Train Epoch: 3 [15200/33600 (45%)]\tLoss: 2.148376\n","Train Epoch: 3 [15400/33600 (46%)]\tLoss: 2.500169\n","Train Epoch: 3 [15600/33600 (46%)]\tLoss: 2.276197\n","Train Epoch: 3 [15800/33600 (47%)]\tLoss: 2.987140\n","Train Epoch: 3 [16000/33600 (48%)]\tLoss: 2.269023\n","Train Epoch: 3 [16200/33600 (48%)]\tLoss: 1.822304\n","Train Epoch: 3 [16400/33600 (49%)]\tLoss: 1.818974\n","Train Epoch: 3 [16600/33600 (49%)]\tLoss: 1.323186\n","Train Epoch: 3 [16800/33600 (50%)]\tLoss: 2.637528\n","Train Epoch: 3 [17000/33600 (51%)]\tLoss: 2.695564\n","Train Epoch: 3 [17200/33600 (51%)]\tLoss: 2.501663\n","Train Epoch: 3 [17400/33600 (52%)]\tLoss: 1.961016\n","Train Epoch: 3 [17600/33600 (52%)]\tLoss: 1.921089\n","Train Epoch: 3 [17800/33600 (53%)]\tLoss: 1.747602\n","Train Epoch: 3 [18000/33600 (54%)]\tLoss: 1.870173\n","Train Epoch: 3 [18200/33600 (54%)]\tLoss: 1.461364\n","Train Epoch: 3 [18400/33600 (55%)]\tLoss: 2.107493\n","Train Epoch: 3 [18600/33600 (55%)]\tLoss: 2.326384\n","Train Epoch: 3 [18800/33600 (56%)]\tLoss: 1.221255\n","Train Epoch: 3 [19000/33600 (57%)]\tLoss: 2.133188\n","Train Epoch: 3 [19200/33600 (57%)]\tLoss: 1.445509\n","Train Epoch: 3 [19400/33600 (58%)]\tLoss: 1.705231\n","Train Epoch: 3 [19600/33600 (58%)]\tLoss: 1.931058\n","Train Epoch: 3 [19800/33600 (59%)]\tLoss: 2.180493\n","Train Epoch: 3 [20000/33600 (60%)]\tLoss: 1.398475\n","Train Epoch: 3 [20200/33600 (60%)]\tLoss: 1.746422\n","Train Epoch: 3 [20400/33600 (61%)]\tLoss: 2.392156\n","Train Epoch: 3 [20600/33600 (61%)]\tLoss: 2.398042\n","Train Epoch: 3 [20800/33600 (62%)]\tLoss: 2.371162\n","Train Epoch: 3 [21000/33600 (62%)]\tLoss: 2.703534\n","Train Epoch: 3 [21200/33600 (63%)]\tLoss: 2.717083\n","Train Epoch: 3 [21400/33600 (64%)]\tLoss: 1.622158\n","Train Epoch: 3 [21600/33600 (64%)]\tLoss: 1.969304\n","Train Epoch: 3 [21800/33600 (65%)]\tLoss: 1.908110\n","Train Epoch: 3 [22000/33600 (65%)]\tLoss: 1.840353\n","Train Epoch: 3 [22200/33600 (66%)]\tLoss: 2.568983\n","Train Epoch: 3 [22400/33600 (67%)]\tLoss: 1.902452\n","Train Epoch: 3 [22600/33600 (67%)]\tLoss: 1.910868\n","Train Epoch: 3 [22800/33600 (68%)]\tLoss: 2.265524\n","Train Epoch: 3 [23000/33600 (68%)]\tLoss: 2.617096\n","Train Epoch: 3 [23200/33600 (69%)]\tLoss: 2.296424\n","Train Epoch: 3 [23400/33600 (70%)]\tLoss: 2.206349\n","Train Epoch: 3 [23600/33600 (70%)]\tLoss: 2.041553\n","Train Epoch: 3 [23800/33600 (71%)]\tLoss: 1.960571\n","Train Epoch: 3 [24000/33600 (71%)]\tLoss: 1.740911\n","Train Epoch: 3 [24200/33600 (72%)]\tLoss: 1.522814\n","Train Epoch: 3 [24400/33600 (73%)]\tLoss: 1.967086\n","Train Epoch: 3 [24600/33600 (73%)]\tLoss: 1.854845\n","Train Epoch: 3 [24800/33600 (74%)]\tLoss: 2.819707\n","Train Epoch: 3 [25000/33600 (74%)]\tLoss: 1.630157\n","Train Epoch: 3 [25200/33600 (75%)]\tLoss: 2.468979\n","Train Epoch: 3 [25400/33600 (76%)]\tLoss: 2.370390\n","Train Epoch: 3 [25600/33600 (76%)]\tLoss: 2.141857\n","Train Epoch: 3 [25800/33600 (77%)]\tLoss: 2.238585\n","Train Epoch: 3 [26000/33600 (77%)]\tLoss: 1.812222\n","Train Epoch: 3 [26200/33600 (78%)]\tLoss: 2.423562\n","Train Epoch: 3 [26400/33600 (79%)]\tLoss: 1.876642\n","Train Epoch: 3 [26600/33600 (79%)]\tLoss: 2.006212\n","Train Epoch: 3 [26800/33600 (80%)]\tLoss: 2.423407\n","Train Epoch: 3 [27000/33600 (80%)]\tLoss: 2.353927\n","Train Epoch: 3 [27200/33600 (81%)]\tLoss: 2.213618\n","Train Epoch: 3 [27400/33600 (82%)]\tLoss: 2.168384\n","Train Epoch: 3 [27600/33600 (82%)]\tLoss: 1.729772\n","Train Epoch: 3 [27800/33600 (83%)]\tLoss: 1.844445\n","Train Epoch: 3 [28000/33600 (83%)]\tLoss: 2.120518\n","Train Epoch: 3 [28200/33600 (84%)]\tLoss: 2.369066\n","Train Epoch: 3 [28400/33600 (85%)]\tLoss: 1.844809\n","Train Epoch: 3 [28600/33600 (85%)]\tLoss: 2.661593\n","Train Epoch: 3 [28800/33600 (86%)]\tLoss: 1.934488\n","Train Epoch: 3 [29000/33600 (86%)]\tLoss: 2.048979\n","Train Epoch: 3 [29200/33600 (87%)]\tLoss: 1.830341\n","Train Epoch: 3 [29400/33600 (88%)]\tLoss: 1.611303\n","Train Epoch: 3 [29600/33600 (88%)]\tLoss: 2.923240\n","Train Epoch: 3 [29800/33600 (89%)]\tLoss: 1.995986\n","Train Epoch: 3 [30000/33600 (89%)]\tLoss: 2.828075\n","Train Epoch: 3 [30200/33600 (90%)]\tLoss: 2.253630\n","Train Epoch: 3 [30400/33600 (90%)]\tLoss: 1.686164\n","Train Epoch: 3 [30600/33600 (91%)]\tLoss: 2.302448\n","Train Epoch: 3 [30800/33600 (92%)]\tLoss: 1.683922\n","Train Epoch: 3 [31000/33600 (92%)]\tLoss: 2.154217\n","Train Epoch: 3 [31200/33600 (93%)]\tLoss: 2.519168\n","Train Epoch: 3 [31400/33600 (93%)]\tLoss: 2.010180\n","Train Epoch: 3 [31600/33600 (94%)]\tLoss: 2.967430\n","Train Epoch: 3 [31800/33600 (95%)]\tLoss: 1.649378\n","Train Epoch: 3 [32000/33600 (95%)]\tLoss: 1.960690\n","Train Epoch: 3 [32200/33600 (96%)]\tLoss: 1.434292\n","Train Epoch: 3 [32400/33600 (96%)]\tLoss: 2.467540\n","Train Epoch: 3 [32600/33600 (97%)]\tLoss: 2.107170\n","Train Epoch: 3 [32800/33600 (98%)]\tLoss: 1.921738\n","Train Epoch: 3 [33000/33600 (98%)]\tLoss: 1.716769\n","Train Epoch: 3 [33200/33600 (99%)]\tLoss: 2.754270\n","Train Epoch: 3 [33400/33600 (99%)]\tLoss: 2.314888\n","Train Epoch: 3 [33600/33600 (100%)]\tLoss: 2.377168\n","\n","Validation - Average Loss: 1.9802, Accuracy: 39.262%\n","\n","Train Epoch: 4 [200/33600 (1%)]\tLoss: 2.662163\n","Train Epoch: 4 [400/33600 (1%)]\tLoss: 1.728261\n","Train Epoch: 4 [600/33600 (2%)]\tLoss: 1.822550\n","Train Epoch: 4 [800/33600 (2%)]\tLoss: 2.180568\n","Train Epoch: 4 [1000/33600 (3%)]\tLoss: 2.454267\n","Train Epoch: 4 [1200/33600 (4%)]\tLoss: 1.711936\n","Train Epoch: 4 [1400/33600 (4%)]\tLoss: 1.877684\n","Train Epoch: 4 [1600/33600 (5%)]\tLoss: 2.566856\n","Train Epoch: 4 [1800/33600 (5%)]\tLoss: 2.076169\n","Train Epoch: 4 [2000/33600 (6%)]\tLoss: 1.669242\n","Train Epoch: 4 [2200/33600 (7%)]\tLoss: 2.416055\n","Train Epoch: 4 [2400/33600 (7%)]\tLoss: 2.323559\n","Train Epoch: 4 [2600/33600 (8%)]\tLoss: 1.591741\n","Train Epoch: 4 [2800/33600 (8%)]\tLoss: 2.293169\n","Train Epoch: 4 [3000/33600 (9%)]\tLoss: 2.592116\n","Train Epoch: 4 [3200/33600 (10%)]\tLoss: 2.597216\n","Train Epoch: 4 [3400/33600 (10%)]\tLoss: 1.692199\n","Train Epoch: 4 [3600/33600 (11%)]\tLoss: 2.732415\n","Train Epoch: 4 [3800/33600 (11%)]\tLoss: 2.675364\n","Train Epoch: 4 [4000/33600 (12%)]\tLoss: 2.153270\n","Train Epoch: 4 [4200/33600 (12%)]\tLoss: 1.155762\n","Train Epoch: 4 [4400/33600 (13%)]\tLoss: 2.961575\n","Train Epoch: 4 [4600/33600 (14%)]\tLoss: 1.921698\n","Train Epoch: 4 [4800/33600 (14%)]\tLoss: 1.752052\n","Train Epoch: 4 [5000/33600 (15%)]\tLoss: 2.497832\n","Train Epoch: 4 [5200/33600 (15%)]\tLoss: 2.813010\n","Train Epoch: 4 [5400/33600 (16%)]\tLoss: 2.702941\n","Train Epoch: 4 [5600/33600 (17%)]\tLoss: 2.093071\n","Train Epoch: 4 [5800/33600 (17%)]\tLoss: 1.207432\n","Train Epoch: 4 [6000/33600 (18%)]\tLoss: 1.324980\n","Train Epoch: 4 [6200/33600 (18%)]\tLoss: 1.717592\n","Train Epoch: 4 [6400/33600 (19%)]\tLoss: 1.398756\n","Train Epoch: 4 [6600/33600 (20%)]\tLoss: 1.791475\n","Train Epoch: 4 [6800/33600 (20%)]\tLoss: 2.293632\n","Train Epoch: 4 [7000/33600 (21%)]\tLoss: 1.940859\n","Train Epoch: 4 [7200/33600 (21%)]\tLoss: 2.061264\n","Train Epoch: 4 [7400/33600 (22%)]\tLoss: 2.103772\n","Train Epoch: 4 [7600/33600 (23%)]\tLoss: 1.882215\n","Train Epoch: 4 [7800/33600 (23%)]\tLoss: 2.334624\n","Train Epoch: 4 [8000/33600 (24%)]\tLoss: 1.864979\n","Train Epoch: 4 [8200/33600 (24%)]\tLoss: 2.227478\n","Train Epoch: 4 [8400/33600 (25%)]\tLoss: 2.503711\n","Train Epoch: 4 [8600/33600 (26%)]\tLoss: 2.291143\n","Train Epoch: 4 [8800/33600 (26%)]\tLoss: 2.566474\n","Train Epoch: 4 [9000/33600 (27%)]\tLoss: 3.032528\n","Train Epoch: 4 [9200/33600 (27%)]\tLoss: 2.623646\n","Train Epoch: 4 [9400/33600 (28%)]\tLoss: 1.951449\n","Train Epoch: 4 [9600/33600 (29%)]\tLoss: 2.034733\n","Train Epoch: 4 [9800/33600 (29%)]\tLoss: 2.404609\n","Train Epoch: 4 [10000/33600 (30%)]\tLoss: 2.552377\n","Train Epoch: 4 [10200/33600 (30%)]\tLoss: 2.767195\n","Train Epoch: 4 [10400/33600 (31%)]\tLoss: 3.717804\n","Train Epoch: 4 [10600/33600 (32%)]\tLoss: 2.363050\n","Train Epoch: 4 [10800/33600 (32%)]\tLoss: 2.098071\n","Train Epoch: 4 [11000/33600 (33%)]\tLoss: 2.169285\n","Train Epoch: 4 [11200/33600 (33%)]\tLoss: 1.743070\n","Train Epoch: 4 [11400/33600 (34%)]\tLoss: 1.892568\n","Train Epoch: 4 [11600/33600 (35%)]\tLoss: 2.349997\n","Train Epoch: 4 [11800/33600 (35%)]\tLoss: 1.976470\n","Train Epoch: 4 [12000/33600 (36%)]\tLoss: 2.172648\n","Train Epoch: 4 [12200/33600 (36%)]\tLoss: 1.949457\n","Train Epoch: 4 [12400/33600 (37%)]\tLoss: 2.229046\n","Train Epoch: 4 [12600/33600 (38%)]\tLoss: 1.668583\n","Train Epoch: 4 [12800/33600 (38%)]\tLoss: 1.584373\n","Train Epoch: 4 [13000/33600 (39%)]\tLoss: 2.806587\n","Train Epoch: 4 [13200/33600 (39%)]\tLoss: 3.100522\n","Train Epoch: 4 [13400/33600 (40%)]\tLoss: 1.587653\n","Train Epoch: 4 [13600/33600 (40%)]\tLoss: 1.269089\n","Train Epoch: 4 [13800/33600 (41%)]\tLoss: 1.828180\n","Train Epoch: 4 [14000/33600 (42%)]\tLoss: 1.696761\n","Train Epoch: 4 [14200/33600 (42%)]\tLoss: 1.284537\n","Train Epoch: 4 [14400/33600 (43%)]\tLoss: 2.071938\n","Train Epoch: 4 [14600/33600 (43%)]\tLoss: 1.932391\n","Train Epoch: 4 [14800/33600 (44%)]\tLoss: 2.481095\n","Train Epoch: 4 [15000/33600 (45%)]\tLoss: 1.950624\n","Train Epoch: 4 [15200/33600 (45%)]\tLoss: 2.350631\n","Train Epoch: 4 [15400/33600 (46%)]\tLoss: 2.706023\n","Train Epoch: 4 [15600/33600 (46%)]\tLoss: 2.081783\n","Train Epoch: 4 [15800/33600 (47%)]\tLoss: 2.128547\n","Train Epoch: 4 [16000/33600 (48%)]\tLoss: 2.288623\n","Train Epoch: 4 [16200/33600 (48%)]\tLoss: 3.067638\n","Train Epoch: 4 [16400/33600 (49%)]\tLoss: 2.471907\n","Train Epoch: 4 [16600/33600 (49%)]\tLoss: 2.240371\n","Train Epoch: 4 [16800/33600 (50%)]\tLoss: 2.059204\n","Train Epoch: 4 [17000/33600 (51%)]\tLoss: 2.602182\n","Train Epoch: 4 [17200/33600 (51%)]\tLoss: 2.382564\n","Train Epoch: 4 [17400/33600 (52%)]\tLoss: 1.915849\n","Train Epoch: 4 [17600/33600 (52%)]\tLoss: 1.982382\n","Train Epoch: 4 [17800/33600 (53%)]\tLoss: 2.577295\n","Train Epoch: 4 [18000/33600 (54%)]\tLoss: 2.475606\n","Train Epoch: 4 [18200/33600 (54%)]\tLoss: 2.680010\n","Train Epoch: 4 [18400/33600 (55%)]\tLoss: 1.959857\n","Train Epoch: 4 [18600/33600 (55%)]\tLoss: 2.354482\n","Train Epoch: 4 [18800/33600 (56%)]\tLoss: 1.890918\n","Train Epoch: 4 [19000/33600 (57%)]\tLoss: 1.858917\n","Train Epoch: 4 [19200/33600 (57%)]\tLoss: 2.124985\n","Train Epoch: 4 [19400/33600 (58%)]\tLoss: 1.570945\n","Train Epoch: 4 [19600/33600 (58%)]\tLoss: 2.503621\n","Train Epoch: 4 [19800/33600 (59%)]\tLoss: 1.862096\n","Train Epoch: 4 [20000/33600 (60%)]\tLoss: 1.583483\n","Train Epoch: 4 [20200/33600 (60%)]\tLoss: 1.201698\n","Train Epoch: 4 [20400/33600 (61%)]\tLoss: 2.402858\n","Train Epoch: 4 [20600/33600 (61%)]\tLoss: 2.991944\n","Train Epoch: 4 [20800/33600 (62%)]\tLoss: 2.313845\n","Train Epoch: 4 [21000/33600 (62%)]\tLoss: 2.530600\n","Train Epoch: 4 [21200/33600 (63%)]\tLoss: 1.738693\n","Train Epoch: 4 [21400/33600 (64%)]\tLoss: 2.131979\n","Train Epoch: 4 [21600/33600 (64%)]\tLoss: 2.512264\n","Train Epoch: 4 [21800/33600 (65%)]\tLoss: 2.109931\n","Train Epoch: 4 [22000/33600 (65%)]\tLoss: 2.429235\n","Train Epoch: 4 [22200/33600 (66%)]\tLoss: 2.082340\n","Train Epoch: 4 [22400/33600 (67%)]\tLoss: 1.900857\n","Train Epoch: 4 [22600/33600 (67%)]\tLoss: 1.912178\n","Train Epoch: 4 [22800/33600 (68%)]\tLoss: 2.011186\n","Train Epoch: 4 [23000/33600 (68%)]\tLoss: 2.415621\n","Train Epoch: 4 [23200/33600 (69%)]\tLoss: 1.498207\n","Train Epoch: 4 [23400/33600 (70%)]\tLoss: 2.433143\n","Train Epoch: 4 [23600/33600 (70%)]\tLoss: 2.290554\n","Train Epoch: 4 [23800/33600 (71%)]\tLoss: 2.548766\n","Train Epoch: 4 [24000/33600 (71%)]\tLoss: 1.823580\n","Train Epoch: 4 [24200/33600 (72%)]\tLoss: 2.338828\n","Train Epoch: 4 [24400/33600 (73%)]\tLoss: 2.153799\n","Train Epoch: 4 [24600/33600 (73%)]\tLoss: 2.253834\n","Train Epoch: 4 [24800/33600 (74%)]\tLoss: 2.602451\n","Train Epoch: 4 [25000/33600 (74%)]\tLoss: 2.073985\n","Train Epoch: 4 [25200/33600 (75%)]\tLoss: 1.779967\n","Train Epoch: 4 [25400/33600 (76%)]\tLoss: 2.906559\n","Train Epoch: 4 [25600/33600 (76%)]\tLoss: 1.546540\n","Train Epoch: 4 [25800/33600 (77%)]\tLoss: 1.970021\n","Train Epoch: 4 [26000/33600 (77%)]\tLoss: 2.734716\n","Train Epoch: 4 [26200/33600 (78%)]\tLoss: 2.331411\n","Train Epoch: 4 [26400/33600 (79%)]\tLoss: 1.980380\n","Train Epoch: 4 [26600/33600 (79%)]\tLoss: 2.056481\n","Train Epoch: 4 [26800/33600 (80%)]\tLoss: 2.071890\n","Train Epoch: 4 [27000/33600 (80%)]\tLoss: 1.438563\n","Train Epoch: 4 [27200/33600 (81%)]\tLoss: 2.699670\n","Train Epoch: 4 [27400/33600 (82%)]\tLoss: 2.150142\n","Train Epoch: 4 [27600/33600 (82%)]\tLoss: 2.459728\n","Train Epoch: 4 [27800/33600 (83%)]\tLoss: 2.487727\n","Train Epoch: 4 [28000/33600 (83%)]\tLoss: 1.529675\n","Train Epoch: 4 [28200/33600 (84%)]\tLoss: 2.035373\n","Train Epoch: 4 [28400/33600 (85%)]\tLoss: 2.207070\n","Train Epoch: 4 [28600/33600 (85%)]\tLoss: 2.202278\n","Train Epoch: 4 [28800/33600 (86%)]\tLoss: 2.786352\n","Train Epoch: 4 [29000/33600 (86%)]\tLoss: 2.331754\n","Train Epoch: 4 [29200/33600 (87%)]\tLoss: 1.941241\n","Train Epoch: 4 [29400/33600 (88%)]\tLoss: 2.483097\n","Train Epoch: 4 [29600/33600 (88%)]\tLoss: 2.421506\n","Train Epoch: 4 [29800/33600 (89%)]\tLoss: 1.755693\n","Train Epoch: 4 [30000/33600 (89%)]\tLoss: 1.844381\n","Train Epoch: 4 [30200/33600 (90%)]\tLoss: 2.216499\n","Train Epoch: 4 [30400/33600 (90%)]\tLoss: 1.314989\n","Train Epoch: 4 [30600/33600 (91%)]\tLoss: 2.377686\n","Train Epoch: 4 [30800/33600 (92%)]\tLoss: 2.223485\n","Train Epoch: 4 [31000/33600 (92%)]\tLoss: 2.129210\n","Train Epoch: 4 [31200/33600 (93%)]\tLoss: 1.857739\n","Train Epoch: 4 [31400/33600 (93%)]\tLoss: 3.060894\n","Train Epoch: 4 [31600/33600 (94%)]\tLoss: 1.648264\n","Train Epoch: 4 [31800/33600 (95%)]\tLoss: 2.773657\n","Train Epoch: 4 [32000/33600 (95%)]\tLoss: 1.418574\n","Train Epoch: 4 [32200/33600 (96%)]\tLoss: 2.500885\n","Train Epoch: 4 [32400/33600 (96%)]\tLoss: 1.228467\n","Train Epoch: 4 [32600/33600 (97%)]\tLoss: 1.928875\n","Train Epoch: 4 [32800/33600 (98%)]\tLoss: 2.093295\n","Train Epoch: 4 [33000/33600 (98%)]\tLoss: 2.596724\n","Train Epoch: 4 [33200/33600 (99%)]\tLoss: 2.142683\n","Train Epoch: 4 [33400/33600 (99%)]\tLoss: 2.675615\n","Train Epoch: 4 [33600/33600 (100%)]\tLoss: 1.796466\n","\n","Validation - Average Loss: 1.9025, Accuracy: 37.738%\n","\n","Train Epoch: 5 [200/33600 (1%)]\tLoss: 2.314742\n","Train Epoch: 5 [400/33600 (1%)]\tLoss: 1.999123\n","Train Epoch: 5 [600/33600 (2%)]\tLoss: 1.790694\n","Train Epoch: 5 [800/33600 (2%)]\tLoss: 1.965336\n","Train Epoch: 5 [1000/33600 (3%)]\tLoss: 3.896912\n","Train Epoch: 5 [1200/33600 (4%)]\tLoss: 2.326113\n","Train Epoch: 5 [1400/33600 (4%)]\tLoss: 2.331163\n","Train Epoch: 5 [1600/33600 (5%)]\tLoss: 1.893380\n","Train Epoch: 5 [1800/33600 (5%)]\tLoss: 2.445576\n","Train Epoch: 5 [2000/33600 (6%)]\tLoss: 2.137694\n","Train Epoch: 5 [2200/33600 (7%)]\tLoss: 2.116153\n","Train Epoch: 5 [2400/33600 (7%)]\tLoss: 1.690571\n","Train Epoch: 5 [2600/33600 (8%)]\tLoss: 2.378776\n","Train Epoch: 5 [2800/33600 (8%)]\tLoss: 2.033233\n","Train Epoch: 5 [3000/33600 (9%)]\tLoss: 2.364247\n","Train Epoch: 5 [3200/33600 (10%)]\tLoss: 2.025378\n","Train Epoch: 5 [3400/33600 (10%)]\tLoss: 2.323572\n","Train Epoch: 5 [3600/33600 (11%)]\tLoss: 1.850740\n","Train Epoch: 5 [3800/33600 (11%)]\tLoss: 2.471826\n","Train Epoch: 5 [4000/33600 (12%)]\tLoss: 2.209975\n","Train Epoch: 5 [4200/33600 (12%)]\tLoss: 2.747882\n","Train Epoch: 5 [4400/33600 (13%)]\tLoss: 1.808245\n","Train Epoch: 5 [4600/33600 (14%)]\tLoss: 2.257161\n","Train Epoch: 5 [4800/33600 (14%)]\tLoss: 2.246211\n","Train Epoch: 5 [5000/33600 (15%)]\tLoss: 1.539016\n","Train Epoch: 5 [5200/33600 (15%)]\tLoss: 3.221626\n","Train Epoch: 5 [5400/33600 (16%)]\tLoss: 2.885194\n","Train Epoch: 5 [5600/33600 (17%)]\tLoss: 2.210463\n","Train Epoch: 5 [5800/33600 (17%)]\tLoss: 2.508587\n","Train Epoch: 5 [6000/33600 (18%)]\tLoss: 1.709247\n","Train Epoch: 5 [6200/33600 (18%)]\tLoss: 1.976698\n","Train Epoch: 5 [6400/33600 (19%)]\tLoss: 1.659114\n","Train Epoch: 5 [6600/33600 (20%)]\tLoss: 1.502467\n","Train Epoch: 5 [6800/33600 (20%)]\tLoss: 2.629801\n","Train Epoch: 5 [7000/33600 (21%)]\tLoss: 1.861817\n","Train Epoch: 5 [7200/33600 (21%)]\tLoss: 2.232972\n","Train Epoch: 5 [7400/33600 (22%)]\tLoss: 1.951546\n","Train Epoch: 5 [7600/33600 (23%)]\tLoss: 2.543688\n","Train Epoch: 5 [7800/33600 (23%)]\tLoss: 2.329964\n","Train Epoch: 5 [8000/33600 (24%)]\tLoss: 1.846964\n","Train Epoch: 5 [8200/33600 (24%)]\tLoss: 1.670481\n","Train Epoch: 5 [8400/33600 (25%)]\tLoss: 1.812328\n","Train Epoch: 5 [8600/33600 (26%)]\tLoss: 1.898074\n","Train Epoch: 5 [8800/33600 (26%)]\tLoss: 2.346571\n","Train Epoch: 5 [9000/33600 (27%)]\tLoss: 2.102039\n","Train Epoch: 5 [9200/33600 (27%)]\tLoss: 2.044531\n","Train Epoch: 5 [9400/33600 (28%)]\tLoss: 2.025313\n","Train Epoch: 5 [9600/33600 (29%)]\tLoss: 2.200764\n","Train Epoch: 5 [9800/33600 (29%)]\tLoss: 2.074397\n","Train Epoch: 5 [10000/33600 (30%)]\tLoss: 2.387475\n","Train Epoch: 5 [10200/33600 (30%)]\tLoss: 1.557033\n","Train Epoch: 5 [10400/33600 (31%)]\tLoss: 2.327332\n","Train Epoch: 5 [10600/33600 (32%)]\tLoss: 2.154993\n","Train Epoch: 5 [10800/33600 (32%)]\tLoss: 2.665766\n","Train Epoch: 5 [11000/33600 (33%)]\tLoss: 1.876773\n","Train Epoch: 5 [11200/33600 (33%)]\tLoss: 2.487537\n","Train Epoch: 5 [11400/33600 (34%)]\tLoss: 2.475237\n","Train Epoch: 5 [11600/33600 (35%)]\tLoss: 2.006467\n","Train Epoch: 5 [11800/33600 (35%)]\tLoss: 2.461194\n","Train Epoch: 5 [12000/33600 (36%)]\tLoss: 2.733688\n","Train Epoch: 5 [12200/33600 (36%)]\tLoss: 1.441507\n","Train Epoch: 5 [12400/33600 (37%)]\tLoss: 2.235312\n","Train Epoch: 5 [12600/33600 (38%)]\tLoss: 2.137403\n","Train Epoch: 5 [12800/33600 (38%)]\tLoss: 1.913605\n","Train Epoch: 5 [13000/33600 (39%)]\tLoss: 2.232187\n","Train Epoch: 5 [13200/33600 (39%)]\tLoss: 3.185955\n","Train Epoch: 5 [13400/33600 (40%)]\tLoss: 2.041382\n","Train Epoch: 5 [13600/33600 (40%)]\tLoss: 2.696132\n","Train Epoch: 5 [13800/33600 (41%)]\tLoss: 2.352514\n","Train Epoch: 5 [14000/33600 (42%)]\tLoss: 2.581295\n","Train Epoch: 5 [14200/33600 (42%)]\tLoss: 2.421227\n","Train Epoch: 5 [14400/33600 (43%)]\tLoss: 2.150323\n","Train Epoch: 5 [14600/33600 (43%)]\tLoss: 1.723679\n","Train Epoch: 5 [14800/33600 (44%)]\tLoss: 1.720573\n","Train Epoch: 5 [15000/33600 (45%)]\tLoss: 3.546977\n","Train Epoch: 5 [15200/33600 (45%)]\tLoss: 1.734123\n","Train Epoch: 5 [15400/33600 (46%)]\tLoss: 1.923155\n","Train Epoch: 5 [15600/33600 (46%)]\tLoss: 2.185015\n","Train Epoch: 5 [15800/33600 (47%)]\tLoss: 1.523328\n","Train Epoch: 5 [16000/33600 (48%)]\tLoss: 3.071697\n","Train Epoch: 5 [16200/33600 (48%)]\tLoss: 1.518906\n","Train Epoch: 5 [16400/33600 (49%)]\tLoss: 2.483284\n","Train Epoch: 5 [16600/33600 (49%)]\tLoss: 2.190453\n","Train Epoch: 5 [16800/33600 (50%)]\tLoss: 2.155092\n","Train Epoch: 5 [17000/33600 (51%)]\tLoss: 1.442206\n","Train Epoch: 5 [17200/33600 (51%)]\tLoss: 2.398769\n","Train Epoch: 5 [17400/33600 (52%)]\tLoss: 1.800144\n","Train Epoch: 5 [17600/33600 (52%)]\tLoss: 2.338953\n","Train Epoch: 5 [17800/33600 (53%)]\tLoss: 1.768698\n","Train Epoch: 5 [18000/33600 (54%)]\tLoss: 3.720901\n","Train Epoch: 5 [18200/33600 (54%)]\tLoss: 2.580217\n","Train Epoch: 5 [18400/33600 (55%)]\tLoss: 3.478405\n","Train Epoch: 5 [18600/33600 (55%)]\tLoss: 2.265357\n","Train Epoch: 5 [18800/33600 (56%)]\tLoss: 2.258088\n","Train Epoch: 5 [19000/33600 (57%)]\tLoss: 2.977397\n","Train Epoch: 5 [19200/33600 (57%)]\tLoss: 1.610034\n","Train Epoch: 5 [19400/33600 (58%)]\tLoss: 1.919322\n","Train Epoch: 5 [19600/33600 (58%)]\tLoss: 2.193661\n","Train Epoch: 5 [19800/33600 (59%)]\tLoss: 2.392193\n","Train Epoch: 5 [20000/33600 (60%)]\tLoss: 1.748283\n","Train Epoch: 5 [20200/33600 (60%)]\tLoss: 1.852804\n","Train Epoch: 5 [20400/33600 (61%)]\tLoss: 2.279497\n","Train Epoch: 5 [20600/33600 (61%)]\tLoss: 3.185620\n","Train Epoch: 5 [20800/33600 (62%)]\tLoss: 1.694149\n","Train Epoch: 5 [21000/33600 (62%)]\tLoss: 1.728854\n","Train Epoch: 5 [21200/33600 (63%)]\tLoss: 1.832653\n","Train Epoch: 5 [21400/33600 (64%)]\tLoss: 2.642149\n","Train Epoch: 5 [21600/33600 (64%)]\tLoss: 2.462683\n","Train Epoch: 5 [21800/33600 (65%)]\tLoss: 2.218073\n","Train Epoch: 5 [22000/33600 (65%)]\tLoss: 1.906620\n","Train Epoch: 5 [22200/33600 (66%)]\tLoss: 1.766169\n","Train Epoch: 5 [22400/33600 (67%)]\tLoss: 2.233070\n","Train Epoch: 5 [22600/33600 (67%)]\tLoss: 2.098120\n","Train Epoch: 5 [22800/33600 (68%)]\tLoss: 2.414929\n","Train Epoch: 5 [23000/33600 (68%)]\tLoss: 1.836540\n","Train Epoch: 5 [23200/33600 (69%)]\tLoss: 2.160693\n","Train Epoch: 5 [23400/33600 (70%)]\tLoss: 2.453833\n","Train Epoch: 5 [23600/33600 (70%)]\tLoss: 1.477208\n","Train Epoch: 5 [23800/33600 (71%)]\tLoss: 2.490842\n","Train Epoch: 5 [24000/33600 (71%)]\tLoss: 1.886262\n","Train Epoch: 5 [24200/33600 (72%)]\tLoss: 3.533393\n","Train Epoch: 5 [24400/33600 (73%)]\tLoss: 2.112198\n","Train Epoch: 5 [24600/33600 (73%)]\tLoss: 2.344394\n","Train Epoch: 5 [24800/33600 (74%)]\tLoss: 2.568859\n","Train Epoch: 5 [25000/33600 (74%)]\tLoss: 1.427446\n","Train Epoch: 5 [25200/33600 (75%)]\tLoss: 1.933921\n","Train Epoch: 5 [25400/33600 (76%)]\tLoss: 2.154773\n","Train Epoch: 5 [25600/33600 (76%)]\tLoss: 2.248687\n","Train Epoch: 5 [25800/33600 (77%)]\tLoss: 1.739367\n","Train Epoch: 5 [26000/33600 (77%)]\tLoss: 1.881107\n","Train Epoch: 5 [26200/33600 (78%)]\tLoss: 1.962009\n","Train Epoch: 5 [26400/33600 (79%)]\tLoss: 2.199321\n","Train Epoch: 5 [26600/33600 (79%)]\tLoss: 2.529616\n","Train Epoch: 5 [26800/33600 (80%)]\tLoss: 1.572288\n","Train Epoch: 5 [27000/33600 (80%)]\tLoss: 2.192084\n","Train Epoch: 5 [27200/33600 (81%)]\tLoss: 2.170126\n","Train Epoch: 5 [27400/33600 (82%)]\tLoss: 1.956472\n","Train Epoch: 5 [27600/33600 (82%)]\tLoss: 2.254134\n","Train Epoch: 5 [27800/33600 (83%)]\tLoss: 3.344293\n","Train Epoch: 5 [28000/33600 (83%)]\tLoss: 2.407853\n","Train Epoch: 5 [28200/33600 (84%)]\tLoss: 2.445304\n","Train Epoch: 5 [28400/33600 (85%)]\tLoss: 1.879772\n","Train Epoch: 5 [28600/33600 (85%)]\tLoss: 2.342963\n","Train Epoch: 5 [28800/33600 (86%)]\tLoss: 3.017539\n","Train Epoch: 5 [29000/33600 (86%)]\tLoss: 1.909392\n","Train Epoch: 5 [29200/33600 (87%)]\tLoss: 3.008840\n","Train Epoch: 5 [29400/33600 (88%)]\tLoss: 1.710483\n","Train Epoch: 5 [29600/33600 (88%)]\tLoss: 1.874519\n","Train Epoch: 5 [29800/33600 (89%)]\tLoss: 1.643739\n","Train Epoch: 5 [30000/33600 (89%)]\tLoss: 1.651729\n","Train Epoch: 5 [30200/33600 (90%)]\tLoss: 1.584884\n","Train Epoch: 5 [30400/33600 (90%)]\tLoss: 2.046099\n","Train Epoch: 5 [30600/33600 (91%)]\tLoss: 2.042949\n","Train Epoch: 5 [30800/33600 (92%)]\tLoss: 1.702473\n","Train Epoch: 5 [31000/33600 (92%)]\tLoss: 2.176712\n","Train Epoch: 5 [31200/33600 (93%)]\tLoss: 2.060338\n","Train Epoch: 5 [31400/33600 (93%)]\tLoss: 2.567612\n","Train Epoch: 5 [31600/33600 (94%)]\tLoss: 2.036622\n","Train Epoch: 5 [31800/33600 (95%)]\tLoss: 2.351407\n","Train Epoch: 5 [32000/33600 (95%)]\tLoss: 2.245676\n","Train Epoch: 5 [32200/33600 (96%)]\tLoss: 2.200463\n","Train Epoch: 5 [32400/33600 (96%)]\tLoss: 2.793989\n","Train Epoch: 5 [32600/33600 (97%)]\tLoss: 2.017170\n","Train Epoch: 5 [32800/33600 (98%)]\tLoss: 1.806490\n","Train Epoch: 5 [33000/33600 (98%)]\tLoss: 1.594471\n","Train Epoch: 5 [33200/33600 (99%)]\tLoss: 2.856432\n","Train Epoch: 5 [33400/33600 (99%)]\tLoss: 2.317275\n","Train Epoch: 5 [33600/33600 (100%)]\tLoss: 1.532286\n","\n","Validation - Average Loss: 2.0048, Accuracy: 33.393%\n","\n","Train Epoch: 6 [200/33600 (1%)]\tLoss: 2.083079\n","Train Epoch: 6 [400/33600 (1%)]\tLoss: 2.272321\n","Train Epoch: 6 [600/33600 (2%)]\tLoss: 2.669692\n","Train Epoch: 6 [800/33600 (2%)]\tLoss: 1.860206\n","Train Epoch: 6 [1000/33600 (3%)]\tLoss: 2.049179\n","Train Epoch: 6 [1200/33600 (4%)]\tLoss: 1.530627\n","Train Epoch: 6 [1400/33600 (4%)]\tLoss: 1.342421\n","Train Epoch: 6 [1600/33600 (5%)]\tLoss: 1.845823\n","Train Epoch: 6 [1800/33600 (5%)]\tLoss: 2.132193\n","Train Epoch: 6 [2000/33600 (6%)]\tLoss: 2.197427\n","Train Epoch: 6 [2200/33600 (7%)]\tLoss: 1.673308\n","Train Epoch: 6 [2400/33600 (7%)]\tLoss: 2.821335\n","Train Epoch: 6 [2600/33600 (8%)]\tLoss: 2.031472\n","Train Epoch: 6 [2800/33600 (8%)]\tLoss: 2.557874\n","Train Epoch: 6 [3000/33600 (9%)]\tLoss: 1.751284\n","Train Epoch: 6 [3200/33600 (10%)]\tLoss: 2.351454\n","Train Epoch: 6 [3400/33600 (10%)]\tLoss: 1.506181\n","Train Epoch: 6 [3600/33600 (11%)]\tLoss: 1.550191\n","Train Epoch: 6 [3800/33600 (11%)]\tLoss: 1.972915\n","Train Epoch: 6 [4000/33600 (12%)]\tLoss: 1.930740\n","Train Epoch: 6 [4200/33600 (12%)]\tLoss: 2.066130\n","Train Epoch: 6 [4400/33600 (13%)]\tLoss: 2.104021\n","Train Epoch: 6 [4600/33600 (14%)]\tLoss: 2.053554\n","Train Epoch: 6 [4800/33600 (14%)]\tLoss: 2.256247\n","Train Epoch: 6 [5000/33600 (15%)]\tLoss: 2.557704\n","Train Epoch: 6 [5200/33600 (15%)]\tLoss: 1.906478\n","Train Epoch: 6 [5400/33600 (16%)]\tLoss: 2.209183\n","Train Epoch: 6 [5600/33600 (17%)]\tLoss: 1.489432\n","Train Epoch: 6 [5800/33600 (17%)]\tLoss: 1.946883\n","Train Epoch: 6 [6000/33600 (18%)]\tLoss: 2.005576\n","Train Epoch: 6 [6200/33600 (18%)]\tLoss: 3.778493\n","Train Epoch: 6 [6400/33600 (19%)]\tLoss: 2.491771\n","Train Epoch: 6 [6600/33600 (20%)]\tLoss: 2.006669\n","Train Epoch: 6 [6800/33600 (20%)]\tLoss: 2.272675\n","Train Epoch: 6 [7000/33600 (21%)]\tLoss: 1.998044\n","Train Epoch: 6 [7200/33600 (21%)]\tLoss: 1.573557\n","Train Epoch: 6 [7400/33600 (22%)]\tLoss: 1.349661\n","Train Epoch: 6 [7600/33600 (23%)]\tLoss: 2.354411\n","Train Epoch: 6 [7800/33600 (23%)]\tLoss: 1.914908\n","Train Epoch: 6 [8000/33600 (24%)]\tLoss: 1.691021\n","Train Epoch: 6 [8200/33600 (24%)]\tLoss: 2.299637\n","Train Epoch: 6 [8400/33600 (25%)]\tLoss: 2.145200\n","Train Epoch: 6 [8600/33600 (26%)]\tLoss: 2.155529\n","Train Epoch: 6 [8800/33600 (26%)]\tLoss: 2.337888\n","Train Epoch: 6 [9000/33600 (27%)]\tLoss: 1.644728\n","Train Epoch: 6 [9200/33600 (27%)]\tLoss: 2.222579\n","Train Epoch: 6 [9400/33600 (28%)]\tLoss: 2.948237\n","Train Epoch: 6 [9600/33600 (29%)]\tLoss: 1.960699\n","Train Epoch: 6 [9800/33600 (29%)]\tLoss: 1.606403\n","Train Epoch: 6 [10000/33600 (30%)]\tLoss: 2.276020\n","Train Epoch: 6 [10200/33600 (30%)]\tLoss: 2.126934\n","Train Epoch: 6 [10400/33600 (31%)]\tLoss: 2.116735\n","Train Epoch: 6 [10600/33600 (32%)]\tLoss: 2.313306\n","Train Epoch: 6 [10800/33600 (32%)]\tLoss: 1.766134\n","Train Epoch: 6 [11000/33600 (33%)]\tLoss: 2.417470\n","Train Epoch: 6 [11200/33600 (33%)]\tLoss: 1.821064\n","Train Epoch: 6 [11400/33600 (34%)]\tLoss: 2.495061\n","Train Epoch: 6 [11600/33600 (35%)]\tLoss: 1.614058\n","Train Epoch: 6 [11800/33600 (35%)]\tLoss: 1.566553\n","Train Epoch: 6 [12000/33600 (36%)]\tLoss: 2.873588\n","Train Epoch: 6 [12200/33600 (36%)]\tLoss: 2.304978\n","Train Epoch: 6 [12400/33600 (37%)]\tLoss: 1.382805\n","Train Epoch: 6 [12600/33600 (38%)]\tLoss: 1.555135\n","Train Epoch: 6 [12800/33600 (38%)]\tLoss: 2.216491\n","Train Epoch: 6 [13000/33600 (39%)]\tLoss: 2.283981\n","Train Epoch: 6 [13200/33600 (39%)]\tLoss: 2.482453\n","Train Epoch: 6 [13400/33600 (40%)]\tLoss: 1.467240\n","Train Epoch: 6 [13600/33600 (40%)]\tLoss: 2.584061\n","Train Epoch: 6 [13800/33600 (41%)]\tLoss: 2.583060\n","Train Epoch: 6 [14000/33600 (42%)]\tLoss: 1.773914\n","Train Epoch: 6 [14200/33600 (42%)]\tLoss: 2.078523\n","Train Epoch: 6 [14400/33600 (43%)]\tLoss: 2.165873\n","Train Epoch: 6 [14600/33600 (43%)]\tLoss: 2.774411\n","Train Epoch: 6 [14800/33600 (44%)]\tLoss: 2.232141\n","Train Epoch: 6 [15000/33600 (45%)]\tLoss: 2.060099\n","Train Epoch: 6 [15200/33600 (45%)]\tLoss: 1.963792\n","Train Epoch: 6 [15400/33600 (46%)]\tLoss: 1.534752\n","Train Epoch: 6 [15600/33600 (46%)]\tLoss: 1.738156\n","Train Epoch: 6 [15800/33600 (47%)]\tLoss: 2.134620\n","Train Epoch: 6 [16000/33600 (48%)]\tLoss: 1.931562\n","Train Epoch: 6 [16200/33600 (48%)]\tLoss: 1.667522\n","Train Epoch: 6 [16400/33600 (49%)]\tLoss: 1.973362\n","Train Epoch: 6 [16600/33600 (49%)]\tLoss: 1.912671\n","Train Epoch: 6 [16800/33600 (50%)]\tLoss: 1.836435\n","Train Epoch: 6 [17000/33600 (51%)]\tLoss: 2.041181\n","Train Epoch: 6 [17200/33600 (51%)]\tLoss: 2.445498\n","Train Epoch: 6 [17400/33600 (52%)]\tLoss: 2.196592\n","Train Epoch: 6 [17600/33600 (52%)]\tLoss: 2.337914\n","Train Epoch: 6 [17800/33600 (53%)]\tLoss: 2.227856\n","Train Epoch: 6 [18000/33600 (54%)]\tLoss: 2.245908\n","Train Epoch: 6 [18200/33600 (54%)]\tLoss: 1.932121\n","Train Epoch: 6 [18400/33600 (55%)]\tLoss: 1.784187\n","Train Epoch: 6 [18600/33600 (55%)]\tLoss: 1.850569\n","Train Epoch: 6 [18800/33600 (56%)]\tLoss: 2.976696\n","Train Epoch: 6 [19000/33600 (57%)]\tLoss: 2.309904\n","Train Epoch: 6 [19200/33600 (57%)]\tLoss: 2.175752\n","Train Epoch: 6 [19400/33600 (58%)]\tLoss: 2.201051\n","Train Epoch: 6 [19600/33600 (58%)]\tLoss: 2.000678\n","Train Epoch: 6 [19800/33600 (59%)]\tLoss: 2.417308\n","Train Epoch: 6 [20000/33600 (60%)]\tLoss: 2.128478\n","Train Epoch: 6 [20200/33600 (60%)]\tLoss: 2.055968\n","Train Epoch: 6 [20400/33600 (61%)]\tLoss: 1.884733\n","Train Epoch: 6 [20600/33600 (61%)]\tLoss: 1.388861\n","Train Epoch: 6 [20800/33600 (62%)]\tLoss: 2.020202\n","Train Epoch: 6 [21000/33600 (62%)]\tLoss: 3.108058\n","Train Epoch: 6 [21200/33600 (63%)]\tLoss: 1.901148\n","Train Epoch: 6 [21400/33600 (64%)]\tLoss: 1.746371\n","Train Epoch: 6 [21600/33600 (64%)]\tLoss: 1.944264\n","Train Epoch: 6 [21800/33600 (65%)]\tLoss: 2.496198\n","Train Epoch: 6 [22000/33600 (65%)]\tLoss: 1.978788\n","Train Epoch: 6 [22200/33600 (66%)]\tLoss: 2.136455\n","Train Epoch: 6 [22400/33600 (67%)]\tLoss: 2.284223\n","Train Epoch: 6 [22600/33600 (67%)]\tLoss: 1.948290\n","Train Epoch: 6 [22800/33600 (68%)]\tLoss: 1.860083\n","Train Epoch: 6 [23000/33600 (68%)]\tLoss: 2.739868\n","Train Epoch: 6 [23200/33600 (69%)]\tLoss: 2.328447\n","Train Epoch: 6 [23400/33600 (70%)]\tLoss: 2.369178\n","Train Epoch: 6 [23600/33600 (70%)]\tLoss: 2.173168\n","Train Epoch: 6 [23800/33600 (71%)]\tLoss: 1.615269\n","Train Epoch: 6 [24000/33600 (71%)]\tLoss: 2.164729\n","Train Epoch: 6 [24200/33600 (72%)]\tLoss: 1.804579\n","Train Epoch: 6 [24400/33600 (73%)]\tLoss: 2.024656\n","Train Epoch: 6 [24600/33600 (73%)]\tLoss: 1.909482\n","Train Epoch: 6 [24800/33600 (74%)]\tLoss: 2.755102\n","Train Epoch: 6 [25000/33600 (74%)]\tLoss: 3.209160\n","Train Epoch: 6 [25200/33600 (75%)]\tLoss: 2.400756\n","Train Epoch: 6 [25400/33600 (76%)]\tLoss: 1.843642\n","Train Epoch: 6 [25600/33600 (76%)]\tLoss: 2.559734\n","Train Epoch: 6 [25800/33600 (77%)]\tLoss: 2.532004\n","Train Epoch: 6 [26000/33600 (77%)]\tLoss: 1.744557\n","Train Epoch: 6 [26200/33600 (78%)]\tLoss: 2.783308\n","Train Epoch: 6 [26400/33600 (79%)]\tLoss: 2.585341\n","Train Epoch: 6 [26600/33600 (79%)]\tLoss: 2.170451\n","Train Epoch: 6 [26800/33600 (80%)]\tLoss: 2.078272\n","Train Epoch: 6 [27000/33600 (80%)]\tLoss: 2.078005\n","Train Epoch: 6 [27200/33600 (81%)]\tLoss: 2.025641\n","Train Epoch: 6 [27400/33600 (82%)]\tLoss: 2.580865\n","Train Epoch: 6 [27600/33600 (82%)]\tLoss: 2.392644\n","Train Epoch: 6 [27800/33600 (83%)]\tLoss: 2.183373\n","Train Epoch: 6 [28000/33600 (83%)]\tLoss: 2.463294\n","Train Epoch: 6 [28200/33600 (84%)]\tLoss: 1.833122\n","Train Epoch: 6 [28400/33600 (85%)]\tLoss: 2.247771\n","Train Epoch: 6 [28600/33600 (85%)]\tLoss: 2.615132\n","Train Epoch: 6 [28800/33600 (86%)]\tLoss: 2.077191\n","Train Epoch: 6 [29000/33600 (86%)]\tLoss: 2.352003\n","Train Epoch: 6 [29200/33600 (87%)]\tLoss: 2.511879\n","Train Epoch: 6 [29400/33600 (88%)]\tLoss: 1.948575\n","Train Epoch: 6 [29600/33600 (88%)]\tLoss: 2.846405\n","Train Epoch: 6 [29800/33600 (89%)]\tLoss: 1.445445\n","Train Epoch: 6 [30000/33600 (89%)]\tLoss: 2.933237\n","Train Epoch: 6 [30200/33600 (90%)]\tLoss: 2.089830\n","Train Epoch: 6 [30400/33600 (90%)]\tLoss: 2.489369\n","Train Epoch: 6 [30600/33600 (91%)]\tLoss: 2.218657\n","Train Epoch: 6 [30800/33600 (92%)]\tLoss: 2.629824\n","Train Epoch: 6 [31000/33600 (92%)]\tLoss: 1.847368\n","Train Epoch: 6 [31200/33600 (93%)]\tLoss: 2.268925\n","Train Epoch: 6 [31400/33600 (93%)]\tLoss: 2.237980\n","Train Epoch: 6 [31600/33600 (94%)]\tLoss: 1.857698\n","Train Epoch: 6 [31800/33600 (95%)]\tLoss: 2.037157\n","Train Epoch: 6 [32000/33600 (95%)]\tLoss: 2.053645\n","Train Epoch: 6 [32200/33600 (96%)]\tLoss: 2.111446\n","Train Epoch: 6 [32400/33600 (96%)]\tLoss: 2.170782\n","Train Epoch: 6 [32600/33600 (97%)]\tLoss: 1.496314\n","Train Epoch: 6 [32800/33600 (98%)]\tLoss: 2.316449\n","Train Epoch: 6 [33000/33600 (98%)]\tLoss: 2.051816\n","Train Epoch: 6 [33200/33600 (99%)]\tLoss: 2.353063\n","Train Epoch: 6 [33400/33600 (99%)]\tLoss: 2.635093\n","Train Epoch: 6 [33600/33600 (100%)]\tLoss: 2.496222\n","\n","Validation - Average Loss: 1.9640, Accuracy: 38.464%\n","\n","Train Epoch: 7 [200/33600 (1%)]\tLoss: 1.769403\n","Train Epoch: 7 [400/33600 (1%)]\tLoss: 1.517798\n","Train Epoch: 7 [600/33600 (2%)]\tLoss: 2.272659\n","Train Epoch: 7 [800/33600 (2%)]\tLoss: 2.064492\n","Train Epoch: 7 [1000/33600 (3%)]\tLoss: 2.756256\n","Train Epoch: 7 [1200/33600 (4%)]\tLoss: 2.959009\n","Train Epoch: 7 [1400/33600 (4%)]\tLoss: 2.847286\n","Train Epoch: 7 [1600/33600 (5%)]\tLoss: 2.131547\n","Train Epoch: 7 [1800/33600 (5%)]\tLoss: 2.232516\n","Train Epoch: 7 [2000/33600 (6%)]\tLoss: 2.071946\n","Train Epoch: 7 [2200/33600 (7%)]\tLoss: 1.601073\n","Train Epoch: 7 [2400/33600 (7%)]\tLoss: 1.499168\n","Train Epoch: 7 [2600/33600 (8%)]\tLoss: 2.598541\n","Train Epoch: 7 [2800/33600 (8%)]\tLoss: 2.057360\n","Train Epoch: 7 [3000/33600 (9%)]\tLoss: 3.004068\n","Train Epoch: 7 [3200/33600 (10%)]\tLoss: 2.362324\n","Train Epoch: 7 [3400/33600 (10%)]\tLoss: 1.863048\n","Train Epoch: 7 [3600/33600 (11%)]\tLoss: 3.529082\n","Train Epoch: 7 [3800/33600 (11%)]\tLoss: 2.066218\n","Train Epoch: 7 [4000/33600 (12%)]\tLoss: 2.219954\n","Train Epoch: 7 [4200/33600 (12%)]\tLoss: 1.858672\n","Train Epoch: 7 [4400/33600 (13%)]\tLoss: 1.924815\n","Train Epoch: 7 [4600/33600 (14%)]\tLoss: 2.071333\n","Train Epoch: 7 [4800/33600 (14%)]\tLoss: 2.580495\n","Train Epoch: 7 [5000/33600 (15%)]\tLoss: 1.896613\n","Train Epoch: 7 [5200/33600 (15%)]\tLoss: 2.111935\n","Train Epoch: 7 [5400/33600 (16%)]\tLoss: 1.720644\n","Train Epoch: 7 [5600/33600 (17%)]\tLoss: 1.871113\n","Train Epoch: 7 [5800/33600 (17%)]\tLoss: 1.775665\n","Train Epoch: 7 [6000/33600 (18%)]\tLoss: 1.705867\n","Train Epoch: 7 [6200/33600 (18%)]\tLoss: 2.264551\n","Train Epoch: 7 [6400/33600 (19%)]\tLoss: 2.582806\n","Train Epoch: 7 [6600/33600 (20%)]\tLoss: 1.970399\n","Train Epoch: 7 [6800/33600 (20%)]\tLoss: 1.886283\n","Train Epoch: 7 [7000/33600 (21%)]\tLoss: 1.738403\n","Train Epoch: 7 [7200/33600 (21%)]\tLoss: 1.838259\n","Train Epoch: 7 [7400/33600 (22%)]\tLoss: 2.152167\n","Train Epoch: 7 [7600/33600 (23%)]\tLoss: 2.869821\n","Train Epoch: 7 [7800/33600 (23%)]\tLoss: 1.485153\n","Train Epoch: 7 [8000/33600 (24%)]\tLoss: 2.223922\n","Train Epoch: 7 [8200/33600 (24%)]\tLoss: 1.881423\n","Train Epoch: 7 [8400/33600 (25%)]\tLoss: 1.627488\n","Train Epoch: 7 [8600/33600 (26%)]\tLoss: 2.089714\n","Train Epoch: 7 [8800/33600 (26%)]\tLoss: 1.392828\n","Train Epoch: 7 [9000/33600 (27%)]\tLoss: 2.358695\n","Train Epoch: 7 [9200/33600 (27%)]\tLoss: 2.124657\n","Train Epoch: 7 [9400/33600 (28%)]\tLoss: 1.902674\n","Train Epoch: 7 [9600/33600 (29%)]\tLoss: 2.490245\n","Train Epoch: 7 [9800/33600 (29%)]\tLoss: 3.475965\n","Train Epoch: 7 [10000/33600 (30%)]\tLoss: 2.251186\n","Train Epoch: 7 [10200/33600 (30%)]\tLoss: 2.417813\n","Train Epoch: 7 [10400/33600 (31%)]\tLoss: 2.069628\n","Train Epoch: 7 [10600/33600 (32%)]\tLoss: 2.287215\n","Train Epoch: 7 [10800/33600 (32%)]\tLoss: 1.984283\n","Train Epoch: 7 [11000/33600 (33%)]\tLoss: 2.529449\n","Train Epoch: 7 [11200/33600 (33%)]\tLoss: 1.616563\n","Train Epoch: 7 [11400/33600 (34%)]\tLoss: 1.574464\n","Train Epoch: 7 [11600/33600 (35%)]\tLoss: 2.966583\n","Train Epoch: 7 [11800/33600 (35%)]\tLoss: 2.023495\n","Train Epoch: 7 [12000/33600 (36%)]\tLoss: 2.088839\n","Train Epoch: 7 [12200/33600 (36%)]\tLoss: 2.629901\n","Train Epoch: 7 [12400/33600 (37%)]\tLoss: 2.240276\n","Train Epoch: 7 [12600/33600 (38%)]\tLoss: 2.165412\n","Train Epoch: 7 [12800/33600 (38%)]\tLoss: 2.042528\n","Train Epoch: 7 [13000/33600 (39%)]\tLoss: 2.104374\n","Train Epoch: 7 [13200/33600 (39%)]\tLoss: 1.703708\n","Train Epoch: 7 [13400/33600 (40%)]\tLoss: 2.030519\n","Train Epoch: 7 [13600/33600 (40%)]\tLoss: 2.346438\n","Train Epoch: 7 [13800/33600 (41%)]\tLoss: 2.762614\n","Train Epoch: 7 [14000/33600 (42%)]\tLoss: 2.425821\n","Train Epoch: 7 [14200/33600 (42%)]\tLoss: 1.768559\n","Train Epoch: 7 [14400/33600 (43%)]\tLoss: 1.852876\n","Train Epoch: 7 [14600/33600 (43%)]\tLoss: 2.369867\n","Train Epoch: 7 [14800/33600 (44%)]\tLoss: 2.172051\n","Train Epoch: 7 [15000/33600 (45%)]\tLoss: 1.913652\n","Train Epoch: 7 [15200/33600 (45%)]\tLoss: 2.009463\n","Train Epoch: 7 [15400/33600 (46%)]\tLoss: 2.253811\n","Train Epoch: 7 [15600/33600 (46%)]\tLoss: 1.930621\n","Train Epoch: 7 [15800/33600 (47%)]\tLoss: 1.972958\n","Train Epoch: 7 [16000/33600 (48%)]\tLoss: 1.956896\n","Train Epoch: 7 [16200/33600 (48%)]\tLoss: 2.632586\n","Train Epoch: 7 [16400/33600 (49%)]\tLoss: 1.435175\n","Train Epoch: 7 [16600/33600 (49%)]\tLoss: 1.820833\n","Train Epoch: 7 [16800/33600 (50%)]\tLoss: 2.692762\n","Train Epoch: 7 [17000/33600 (51%)]\tLoss: 2.383044\n","Train Epoch: 7 [17200/33600 (51%)]\tLoss: 2.280930\n","Train Epoch: 7 [17400/33600 (52%)]\tLoss: 1.582283\n","Train Epoch: 7 [17600/33600 (52%)]\tLoss: 2.324677\n","Train Epoch: 7 [17800/33600 (53%)]\tLoss: 2.220106\n","Train Epoch: 7 [18000/33600 (54%)]\tLoss: 1.691748\n","Train Epoch: 7 [18200/33600 (54%)]\tLoss: 1.673582\n","Train Epoch: 7 [18400/33600 (55%)]\tLoss: 1.752858\n","Train Epoch: 7 [18600/33600 (55%)]\tLoss: 2.216580\n","Train Epoch: 7 [18800/33600 (56%)]\tLoss: 1.567823\n","Train Epoch: 7 [19000/33600 (57%)]\tLoss: 2.699435\n","Train Epoch: 7 [19200/33600 (57%)]\tLoss: 2.648026\n","Train Epoch: 7 [19400/33600 (58%)]\tLoss: 2.049991\n","Train Epoch: 7 [19600/33600 (58%)]\tLoss: 2.631273\n","Train Epoch: 7 [19800/33600 (59%)]\tLoss: 1.980504\n","Train Epoch: 7 [20000/33600 (60%)]\tLoss: 1.762167\n","Train Epoch: 7 [20200/33600 (60%)]\tLoss: 1.944502\n","Train Epoch: 7 [20400/33600 (61%)]\tLoss: 1.802107\n","Train Epoch: 7 [20600/33600 (61%)]\tLoss: 2.118380\n","Train Epoch: 7 [20800/33600 (62%)]\tLoss: 1.598751\n","Train Epoch: 7 [21000/33600 (62%)]\tLoss: 2.125467\n","Train Epoch: 7 [21200/33600 (63%)]\tLoss: 1.958876\n","Train Epoch: 7 [21400/33600 (64%)]\tLoss: 1.848054\n","Train Epoch: 7 [21600/33600 (64%)]\tLoss: 2.978783\n","Train Epoch: 7 [21800/33600 (65%)]\tLoss: 1.980269\n","Train Epoch: 7 [22000/33600 (65%)]\tLoss: 2.463777\n","Train Epoch: 7 [22200/33600 (66%)]\tLoss: 2.839873\n","Train Epoch: 7 [22400/33600 (67%)]\tLoss: 2.203441\n","Train Epoch: 7 [22600/33600 (67%)]\tLoss: 2.253652\n","Train Epoch: 7 [22800/33600 (68%)]\tLoss: 2.439142\n","Train Epoch: 7 [23000/33600 (68%)]\tLoss: 2.225146\n","Train Epoch: 7 [23200/33600 (69%)]\tLoss: 2.552364\n","Train Epoch: 7 [23400/33600 (70%)]\tLoss: 2.071963\n","Train Epoch: 7 [23600/33600 (70%)]\tLoss: 2.211236\n","Train Epoch: 7 [23800/33600 (71%)]\tLoss: 2.102582\n","Train Epoch: 7 [24000/33600 (71%)]\tLoss: 1.967803\n","Train Epoch: 7 [24200/33600 (72%)]\tLoss: 2.248234\n","Train Epoch: 7 [24400/33600 (73%)]\tLoss: 1.894672\n","Train Epoch: 7 [24600/33600 (73%)]\tLoss: 2.079583\n","Train Epoch: 7 [24800/33600 (74%)]\tLoss: 2.415775\n","Train Epoch: 7 [25000/33600 (74%)]\tLoss: 2.081160\n","Train Epoch: 7 [25200/33600 (75%)]\tLoss: 1.952097\n","Train Epoch: 7 [25400/33600 (76%)]\tLoss: 2.248437\n","Train Epoch: 7 [25600/33600 (76%)]\tLoss: 2.585852\n","Train Epoch: 7 [25800/33600 (77%)]\tLoss: 1.966549\n","Train Epoch: 7 [26000/33600 (77%)]\tLoss: 1.663607\n","Train Epoch: 7 [26200/33600 (78%)]\tLoss: 2.219383\n","Train Epoch: 7 [26400/33600 (79%)]\tLoss: 2.631434\n","Train Epoch: 7 [26600/33600 (79%)]\tLoss: 2.119472\n","Train Epoch: 7 [26800/33600 (80%)]\tLoss: 2.212368\n","Train Epoch: 7 [27000/33600 (80%)]\tLoss: 1.863127\n","Train Epoch: 7 [27200/33600 (81%)]\tLoss: 2.033199\n","Train Epoch: 7 [27400/33600 (82%)]\tLoss: 1.727087\n","Train Epoch: 7 [27600/33600 (82%)]\tLoss: 2.444814\n","Train Epoch: 7 [27800/33600 (83%)]\tLoss: 2.502882\n","Train Epoch: 7 [28000/33600 (83%)]\tLoss: 1.840253\n","Train Epoch: 7 [28200/33600 (84%)]\tLoss: 1.164797\n","Train Epoch: 7 [28400/33600 (85%)]\tLoss: 2.075369\n","Train Epoch: 7 [28600/33600 (85%)]\tLoss: 1.950757\n","Train Epoch: 7 [28800/33600 (86%)]\tLoss: 1.829728\n","Train Epoch: 7 [29000/33600 (86%)]\tLoss: 2.564926\n","Train Epoch: 7 [29200/33600 (87%)]\tLoss: 2.147000\n","Train Epoch: 7 [29400/33600 (88%)]\tLoss: 1.561548\n","Train Epoch: 7 [29600/33600 (88%)]\tLoss: 2.638436\n","Train Epoch: 7 [29800/33600 (89%)]\tLoss: 2.090505\n","Train Epoch: 7 [30000/33600 (89%)]\tLoss: 1.409334\n","Train Epoch: 7 [30200/33600 (90%)]\tLoss: 2.180541\n","Train Epoch: 7 [30400/33600 (90%)]\tLoss: 1.664649\n","Train Epoch: 7 [30600/33600 (91%)]\tLoss: 1.838221\n","Train Epoch: 7 [30800/33600 (92%)]\tLoss: 2.486824\n","Train Epoch: 7 [31000/33600 (92%)]\tLoss: 2.381061\n","Train Epoch: 7 [31200/33600 (93%)]\tLoss: 2.373638\n","Train Epoch: 7 [31400/33600 (93%)]\tLoss: 2.113090\n","Train Epoch: 7 [31600/33600 (94%)]\tLoss: 2.000722\n","Train Epoch: 7 [31800/33600 (95%)]\tLoss: 2.133662\n","Train Epoch: 7 [32000/33600 (95%)]\tLoss: 2.079692\n","Train Epoch: 7 [32200/33600 (96%)]\tLoss: 2.361809\n","Train Epoch: 7 [32400/33600 (96%)]\tLoss: 2.021382\n","Train Epoch: 7 [32600/33600 (97%)]\tLoss: 1.832049\n","Train Epoch: 7 [32800/33600 (98%)]\tLoss: 2.344016\n","Train Epoch: 7 [33000/33600 (98%)]\tLoss: 1.586249\n","Train Epoch: 7 [33200/33600 (99%)]\tLoss: 2.257807\n","Train Epoch: 7 [33400/33600 (99%)]\tLoss: 2.404439\n","Train Epoch: 7 [33600/33600 (100%)]\tLoss: 1.560219\n","\n","Validation - Average Loss: 2.0537, Accuracy: 30.464%\n","\n","Train Epoch: 8 [200/33600 (1%)]\tLoss: 2.197855\n","Train Epoch: 8 [400/33600 (1%)]\tLoss: 1.532421\n","Train Epoch: 8 [600/33600 (2%)]\tLoss: 2.484095\n","Train Epoch: 8 [800/33600 (2%)]\tLoss: 1.596709\n","Train Epoch: 8 [1000/33600 (3%)]\tLoss: 1.967574\n","Train Epoch: 8 [1200/33600 (4%)]\tLoss: 2.158940\n","Train Epoch: 8 [1400/33600 (4%)]\tLoss: 1.624683\n","Train Epoch: 8 [1600/33600 (5%)]\tLoss: 1.440173\n","Train Epoch: 8 [1800/33600 (5%)]\tLoss: 1.668603\n","Train Epoch: 8 [2000/33600 (6%)]\tLoss: 1.270780\n","Train Epoch: 8 [2200/33600 (7%)]\tLoss: 2.922675\n","Train Epoch: 8 [2400/33600 (7%)]\tLoss: 2.377248\n","Train Epoch: 8 [2600/33600 (8%)]\tLoss: 1.696277\n","Train Epoch: 8 [2800/33600 (8%)]\tLoss: 2.259893\n","Train Epoch: 8 [3000/33600 (9%)]\tLoss: 2.512735\n","Train Epoch: 8 [3200/33600 (10%)]\tLoss: 2.279866\n","Train Epoch: 8 [3400/33600 (10%)]\tLoss: 2.386150\n","Train Epoch: 8 [3600/33600 (11%)]\tLoss: 2.324455\n","Train Epoch: 8 [3800/33600 (11%)]\tLoss: 2.359978\n","Train Epoch: 8 [4000/33600 (12%)]\tLoss: 1.749593\n","Train Epoch: 8 [4200/33600 (12%)]\tLoss: 2.298539\n","Train Epoch: 8 [4400/33600 (13%)]\tLoss: 2.036564\n","Train Epoch: 8 [4600/33600 (14%)]\tLoss: 1.967298\n","Train Epoch: 8 [4800/33600 (14%)]\tLoss: 2.332349\n","Train Epoch: 8 [5000/33600 (15%)]\tLoss: 1.916324\n","Train Epoch: 8 [5200/33600 (15%)]\tLoss: 2.022373\n","Train Epoch: 8 [5400/33600 (16%)]\tLoss: 1.948342\n","Train Epoch: 8 [5600/33600 (17%)]\tLoss: 2.217956\n","Train Epoch: 8 [5800/33600 (17%)]\tLoss: 2.016451\n","Train Epoch: 8 [6000/33600 (18%)]\tLoss: 2.164912\n","Train Epoch: 8 [6200/33600 (18%)]\tLoss: 1.810474\n","Train Epoch: 8 [6400/33600 (19%)]\tLoss: 1.753753\n","Train Epoch: 8 [6600/33600 (20%)]\tLoss: 2.133278\n","Train Epoch: 8 [6800/33600 (20%)]\tLoss: 1.934368\n","Train Epoch: 8 [7000/33600 (21%)]\tLoss: 1.861064\n","Train Epoch: 8 [7200/33600 (21%)]\tLoss: 2.070858\n","Train Epoch: 8 [7400/33600 (22%)]\tLoss: 2.919521\n","Train Epoch: 8 [7600/33600 (23%)]\tLoss: 2.477878\n","Train Epoch: 8 [7800/33600 (23%)]\tLoss: 2.883112\n","Train Epoch: 8 [8000/33600 (24%)]\tLoss: 2.121438\n","Train Epoch: 8 [8200/33600 (24%)]\tLoss: 1.508533\n","Train Epoch: 8 [8400/33600 (25%)]\tLoss: 2.250542\n","Train Epoch: 8 [8600/33600 (26%)]\tLoss: 2.903688\n","Train Epoch: 8 [8800/33600 (26%)]\tLoss: 1.733651\n","Train Epoch: 8 [9000/33600 (27%)]\tLoss: 1.721758\n","Train Epoch: 8 [9200/33600 (27%)]\tLoss: 2.519356\n","Train Epoch: 8 [9400/33600 (28%)]\tLoss: 1.674667\n","Train Epoch: 8 [9600/33600 (29%)]\tLoss: 2.221255\n","Train Epoch: 8 [9800/33600 (29%)]\tLoss: 2.388009\n","Train Epoch: 8 [10000/33600 (30%)]\tLoss: 2.901050\n","Train Epoch: 8 [10200/33600 (30%)]\tLoss: 1.966962\n","Train Epoch: 8 [10400/33600 (31%)]\tLoss: 2.163203\n","Train Epoch: 8 [10600/33600 (32%)]\tLoss: 2.129420\n","Train Epoch: 8 [10800/33600 (32%)]\tLoss: 2.174078\n","Train Epoch: 8 [11000/33600 (33%)]\tLoss: 2.078057\n","Train Epoch: 8 [11200/33600 (33%)]\tLoss: 1.613231\n","Train Epoch: 8 [11400/33600 (34%)]\tLoss: 2.011406\n","Train Epoch: 8 [11600/33600 (35%)]\tLoss: 1.617275\n","Train Epoch: 8 [11800/33600 (35%)]\tLoss: 1.760841\n","Train Epoch: 8 [12000/33600 (36%)]\tLoss: 2.033624\n","Train Epoch: 8 [12200/33600 (36%)]\tLoss: 2.005952\n","Train Epoch: 8 [12400/33600 (37%)]\tLoss: 2.521783\n","Train Epoch: 8 [12600/33600 (38%)]\tLoss: 2.004590\n","Train Epoch: 8 [12800/33600 (38%)]\tLoss: 2.924114\n","Train Epoch: 8 [13000/33600 (39%)]\tLoss: 2.223609\n","Train Epoch: 8 [13200/33600 (39%)]\tLoss: 1.974085\n","Train Epoch: 8 [13400/33600 (40%)]\tLoss: 2.470099\n","Train Epoch: 8 [13600/33600 (40%)]\tLoss: 2.562663\n","Train Epoch: 8 [13800/33600 (41%)]\tLoss: 2.538778\n","Train Epoch: 8 [14000/33600 (42%)]\tLoss: 2.153352\n","Train Epoch: 8 [14200/33600 (42%)]\tLoss: 2.016756\n","Train Epoch: 8 [14400/33600 (43%)]\tLoss: 1.624221\n","Train Epoch: 8 [14600/33600 (43%)]\tLoss: 2.089039\n","Train Epoch: 8 [14800/33600 (44%)]\tLoss: 1.939299\n","Train Epoch: 8 [15000/33600 (45%)]\tLoss: 2.194437\n","Train Epoch: 8 [15200/33600 (45%)]\tLoss: 1.865982\n","Train Epoch: 8 [15400/33600 (46%)]\tLoss: 1.981071\n","Train Epoch: 8 [15600/33600 (46%)]\tLoss: 2.615119\n","Train Epoch: 8 [15800/33600 (47%)]\tLoss: 2.269695\n","Train Epoch: 8 [16000/33600 (48%)]\tLoss: 1.883729\n","Train Epoch: 8 [16200/33600 (48%)]\tLoss: 2.032464\n","Train Epoch: 8 [16400/33600 (49%)]\tLoss: 1.683771\n","Train Epoch: 8 [16600/33600 (49%)]\tLoss: 2.212541\n","Train Epoch: 8 [16800/33600 (50%)]\tLoss: 2.049850\n","Train Epoch: 8 [17000/33600 (51%)]\tLoss: 2.209038\n","Train Epoch: 8 [17200/33600 (51%)]\tLoss: 1.640811\n","Train Epoch: 8 [17400/33600 (52%)]\tLoss: 1.780985\n","Train Epoch: 8 [17600/33600 (52%)]\tLoss: 2.309132\n","Train Epoch: 8 [17800/33600 (53%)]\tLoss: 2.506012\n","Train Epoch: 8 [18000/33600 (54%)]\tLoss: 2.082688\n","Train Epoch: 8 [18200/33600 (54%)]\tLoss: 2.360150\n","Train Epoch: 8 [18400/33600 (55%)]\tLoss: 2.200135\n","Train Epoch: 8 [18600/33600 (55%)]\tLoss: 2.818814\n","Train Epoch: 8 [18800/33600 (56%)]\tLoss: 2.198737\n","Train Epoch: 8 [19000/33600 (57%)]\tLoss: 2.401772\n","Train Epoch: 8 [19200/33600 (57%)]\tLoss: 1.911941\n","Train Epoch: 8 [19400/33600 (58%)]\tLoss: 2.805998\n","Train Epoch: 8 [19600/33600 (58%)]\tLoss: 2.186710\n","Train Epoch: 8 [19800/33600 (59%)]\tLoss: 2.594616\n","Train Epoch: 8 [20000/33600 (60%)]\tLoss: 2.244689\n","Train Epoch: 8 [20200/33600 (60%)]\tLoss: 2.207184\n","Train Epoch: 8 [20400/33600 (61%)]\tLoss: 2.140823\n","Train Epoch: 8 [20600/33600 (61%)]\tLoss: 1.901126\n","Train Epoch: 8 [20800/33600 (62%)]\tLoss: 1.312744\n","Train Epoch: 8 [21000/33600 (62%)]\tLoss: 2.238546\n","Train Epoch: 8 [21200/33600 (63%)]\tLoss: 2.180233\n","Train Epoch: 8 [21400/33600 (64%)]\tLoss: 2.140811\n","Train Epoch: 8 [21600/33600 (64%)]\tLoss: 2.784819\n","Train Epoch: 8 [21800/33600 (65%)]\tLoss: 2.316637\n","Train Epoch: 8 [22000/33600 (65%)]\tLoss: 1.687753\n","Train Epoch: 8 [22200/33600 (66%)]\tLoss: 2.058943\n","Train Epoch: 8 [22400/33600 (67%)]\tLoss: 2.566502\n","Train Epoch: 8 [22600/33600 (67%)]\tLoss: 2.056749\n","Train Epoch: 8 [22800/33600 (68%)]\tLoss: 2.696738\n","Train Epoch: 8 [23000/33600 (68%)]\tLoss: 1.878414\n","Train Epoch: 8 [23200/33600 (69%)]\tLoss: 2.462157\n","Train Epoch: 8 [23400/33600 (70%)]\tLoss: 2.310841\n","Train Epoch: 8 [23600/33600 (70%)]\tLoss: 2.824785\n","Train Epoch: 8 [23800/33600 (71%)]\tLoss: 1.766837\n","Train Epoch: 8 [24000/33600 (71%)]\tLoss: 1.745690\n","Train Epoch: 8 [24200/33600 (72%)]\tLoss: 1.813827\n","Train Epoch: 8 [24400/33600 (73%)]\tLoss: 1.633962\n","Train Epoch: 8 [24600/33600 (73%)]\tLoss: 1.714325\n","Train Epoch: 8 [24800/33600 (74%)]\tLoss: 1.965857\n","Train Epoch: 8 [25000/33600 (74%)]\tLoss: 2.369265\n","Train Epoch: 8 [25200/33600 (75%)]\tLoss: 1.668988\n","Train Epoch: 8 [25400/33600 (76%)]\tLoss: 2.831893\n","Train Epoch: 8 [25600/33600 (76%)]\tLoss: 1.821994\n","Train Epoch: 8 [25800/33600 (77%)]\tLoss: 2.063185\n","Train Epoch: 8 [26000/33600 (77%)]\tLoss: 2.106948\n","Train Epoch: 8 [26200/33600 (78%)]\tLoss: 2.450728\n","Train Epoch: 8 [26400/33600 (79%)]\tLoss: 1.862839\n","Train Epoch: 8 [26600/33600 (79%)]\tLoss: 1.955968\n","Train Epoch: 8 [26800/33600 (80%)]\tLoss: 2.012787\n","Train Epoch: 8 [27000/33600 (80%)]\tLoss: 1.679743\n","Train Epoch: 8 [27200/33600 (81%)]\tLoss: 1.960587\n","Train Epoch: 8 [27400/33600 (82%)]\tLoss: 2.105945\n","Train Epoch: 8 [27600/33600 (82%)]\tLoss: 2.560631\n","Train Epoch: 8 [27800/33600 (83%)]\tLoss: 1.437795\n","Train Epoch: 8 [28000/33600 (83%)]\tLoss: 1.974501\n","Train Epoch: 8 [28200/33600 (84%)]\tLoss: 2.152615\n","Train Epoch: 8 [28400/33600 (85%)]\tLoss: 1.150788\n","Train Epoch: 8 [28600/33600 (85%)]\tLoss: 1.715058\n","Train Epoch: 8 [28800/33600 (86%)]\tLoss: 1.287776\n","Train Epoch: 8 [29000/33600 (86%)]\tLoss: 1.655837\n","Train Epoch: 8 [29200/33600 (87%)]\tLoss: 1.739936\n","Train Epoch: 8 [29400/33600 (88%)]\tLoss: 2.144206\n","Train Epoch: 8 [29600/33600 (88%)]\tLoss: 2.106720\n","Train Epoch: 8 [29800/33600 (89%)]\tLoss: 2.360305\n","Train Epoch: 8 [30000/33600 (89%)]\tLoss: 2.134840\n","Train Epoch: 8 [30200/33600 (90%)]\tLoss: 3.736669\n","Train Epoch: 8 [30400/33600 (90%)]\tLoss: 2.170224\n","Train Epoch: 8 [30600/33600 (91%)]\tLoss: 1.668331\n","Train Epoch: 8 [30800/33600 (92%)]\tLoss: 2.596865\n","Train Epoch: 8 [31000/33600 (92%)]\tLoss: 2.135968\n","Train Epoch: 8 [31200/33600 (93%)]\tLoss: 2.571005\n","Train Epoch: 8 [31400/33600 (93%)]\tLoss: 2.097342\n","Train Epoch: 8 [31600/33600 (94%)]\tLoss: 1.952783\n","Train Epoch: 8 [31800/33600 (95%)]\tLoss: 2.135124\n","Train Epoch: 8 [32000/33600 (95%)]\tLoss: 2.419818\n","Train Epoch: 8 [32200/33600 (96%)]\tLoss: 2.171776\n","Train Epoch: 8 [32400/33600 (96%)]\tLoss: 2.360738\n","Train Epoch: 8 [32600/33600 (97%)]\tLoss: 1.624623\n","Train Epoch: 8 [32800/33600 (98%)]\tLoss: 1.919383\n","Train Epoch: 8 [33000/33600 (98%)]\tLoss: 1.839223\n","Train Epoch: 8 [33200/33600 (99%)]\tLoss: 2.680350\n","Train Epoch: 8 [33400/33600 (99%)]\tLoss: 1.673307\n","Train Epoch: 8 [33600/33600 (100%)]\tLoss: 2.029355\n","\n","Validation - Average Loss: 2.0402, Accuracy: 24.667%\n","\n","Train Epoch: 9 [200/33600 (1%)]\tLoss: 2.497620\n","Train Epoch: 9 [400/33600 (1%)]\tLoss: 2.057625\n","Train Epoch: 9 [600/33600 (2%)]\tLoss: 2.529236\n","Train Epoch: 9 [800/33600 (2%)]\tLoss: 2.345675\n","Train Epoch: 9 [1000/33600 (3%)]\tLoss: 2.128986\n","Train Epoch: 9 [1200/33600 (4%)]\tLoss: 1.660694\n","Train Epoch: 9 [1400/33600 (4%)]\tLoss: 1.947326\n","Train Epoch: 9 [1600/33600 (5%)]\tLoss: 2.105784\n","Train Epoch: 9 [1800/33600 (5%)]\tLoss: 1.741721\n","Train Epoch: 9 [2000/33600 (6%)]\tLoss: 2.803057\n","Train Epoch: 9 [2200/33600 (7%)]\tLoss: 1.613579\n","Train Epoch: 9 [2400/33600 (7%)]\tLoss: 3.074641\n","Train Epoch: 9 [2600/33600 (8%)]\tLoss: 1.612925\n","Train Epoch: 9 [2800/33600 (8%)]\tLoss: 2.232783\n","Train Epoch: 9 [3000/33600 (9%)]\tLoss: 1.685202\n","Train Epoch: 9 [3200/33600 (10%)]\tLoss: 1.665443\n","Train Epoch: 9 [3400/33600 (10%)]\tLoss: 1.679163\n","Train Epoch: 9 [3600/33600 (11%)]\tLoss: 1.551707\n","Train Epoch: 9 [3800/33600 (11%)]\tLoss: 2.358566\n","Train Epoch: 9 [4000/33600 (12%)]\tLoss: 2.606111\n","Train Epoch: 9 [4200/33600 (12%)]\tLoss: 2.091690\n","Train Epoch: 9 [4400/33600 (13%)]\tLoss: 2.282234\n","Train Epoch: 9 [4600/33600 (14%)]\tLoss: 2.519214\n","Train Epoch: 9 [4800/33600 (14%)]\tLoss: 2.238181\n","Train Epoch: 9 [5000/33600 (15%)]\tLoss: 2.299968\n","Train Epoch: 9 [5200/33600 (15%)]\tLoss: 1.804514\n","Train Epoch: 9 [5400/33600 (16%)]\tLoss: 2.531332\n","Train Epoch: 9 [5600/33600 (17%)]\tLoss: 1.766606\n","Train Epoch: 9 [5800/33600 (17%)]\tLoss: 2.173806\n","Train Epoch: 9 [6000/33600 (18%)]\tLoss: 2.951701\n","Train Epoch: 9 [6200/33600 (18%)]\tLoss: 1.783787\n","Train Epoch: 9 [6400/33600 (19%)]\tLoss: 2.533703\n","Train Epoch: 9 [6600/33600 (20%)]\tLoss: 2.088508\n","Train Epoch: 9 [6800/33600 (20%)]\tLoss: 2.567692\n","Train Epoch: 9 [7000/33600 (21%)]\tLoss: 1.923051\n","Train Epoch: 9 [7200/33600 (21%)]\tLoss: 2.234429\n","Train Epoch: 9 [7400/33600 (22%)]\tLoss: 2.765589\n","Train Epoch: 9 [7600/33600 (23%)]\tLoss: 2.550939\n","Train Epoch: 9 [7800/33600 (23%)]\tLoss: 2.522304\n","Train Epoch: 9 [8000/33600 (24%)]\tLoss: 1.774497\n","Train Epoch: 9 [8200/33600 (24%)]\tLoss: 1.956861\n","Train Epoch: 9 [8400/33600 (25%)]\tLoss: 2.029696\n","Train Epoch: 9 [8600/33600 (26%)]\tLoss: 2.401962\n","Train Epoch: 9 [8800/33600 (26%)]\tLoss: 1.313926\n","Train Epoch: 9 [9000/33600 (27%)]\tLoss: 1.723131\n","Train Epoch: 9 [9200/33600 (27%)]\tLoss: 2.135134\n","Train Epoch: 9 [9400/33600 (28%)]\tLoss: 2.516541\n","Train Epoch: 9 [9600/33600 (29%)]\tLoss: 1.571573\n","Train Epoch: 9 [9800/33600 (29%)]\tLoss: 2.687782\n","Train Epoch: 9 [10000/33600 (30%)]\tLoss: 2.055751\n","Train Epoch: 9 [10200/33600 (30%)]\tLoss: 2.207450\n","Train Epoch: 9 [10400/33600 (31%)]\tLoss: 2.121888\n","Train Epoch: 9 [10600/33600 (32%)]\tLoss: 1.379690\n","Train Epoch: 9 [10800/33600 (32%)]\tLoss: 2.295841\n","Train Epoch: 9 [11000/33600 (33%)]\tLoss: 1.849855\n","Train Epoch: 9 [11200/33600 (33%)]\tLoss: 2.244038\n","Train Epoch: 9 [11400/33600 (34%)]\tLoss: 1.910453\n","Train Epoch: 9 [11600/33600 (35%)]\tLoss: 2.579915\n","Train Epoch: 9 [11800/33600 (35%)]\tLoss: 1.760585\n","Train Epoch: 9 [12000/33600 (36%)]\tLoss: 2.382843\n","Train Epoch: 9 [12200/33600 (36%)]\tLoss: 1.776792\n","Train Epoch: 9 [12400/33600 (37%)]\tLoss: 1.546544\n","Train Epoch: 9 [12600/33600 (38%)]\tLoss: 1.848964\n","Train Epoch: 9 [12800/33600 (38%)]\tLoss: 2.367706\n","Train Epoch: 9 [13000/33600 (39%)]\tLoss: 2.032549\n","Train Epoch: 9 [13200/33600 (39%)]\tLoss: 2.152753\n","Train Epoch: 9 [13400/33600 (40%)]\tLoss: 2.509891\n","Train Epoch: 9 [13600/33600 (40%)]\tLoss: 1.654679\n","Train Epoch: 9 [13800/33600 (41%)]\tLoss: 2.606652\n","Train Epoch: 9 [14000/33600 (42%)]\tLoss: 2.868084\n","Train Epoch: 9 [14200/33600 (42%)]\tLoss: 2.158293\n","Train Epoch: 9 [14400/33600 (43%)]\tLoss: 2.322248\n","Train Epoch: 9 [14600/33600 (43%)]\tLoss: 1.619054\n","Train Epoch: 9 [14800/33600 (44%)]\tLoss: 2.259967\n","Train Epoch: 9 [15000/33600 (45%)]\tLoss: 1.498109\n","Train Epoch: 9 [15200/33600 (45%)]\tLoss: 1.998903\n","Train Epoch: 9 [15400/33600 (46%)]\tLoss: 2.043281\n","Train Epoch: 9 [15600/33600 (46%)]\tLoss: 2.129122\n","Train Epoch: 9 [15800/33600 (47%)]\tLoss: 1.933916\n","Train Epoch: 9 [16000/33600 (48%)]\tLoss: 2.499240\n","Train Epoch: 9 [16200/33600 (48%)]\tLoss: 2.036353\n","Train Epoch: 9 [16400/33600 (49%)]\tLoss: 1.672641\n","Train Epoch: 9 [16600/33600 (49%)]\tLoss: 1.997664\n","Train Epoch: 9 [16800/33600 (50%)]\tLoss: 1.718777\n","Train Epoch: 9 [17000/33600 (51%)]\tLoss: 1.919995\n","Train Epoch: 9 [17200/33600 (51%)]\tLoss: 1.633322\n","Train Epoch: 9 [17400/33600 (52%)]\tLoss: 1.512721\n","Train Epoch: 9 [17600/33600 (52%)]\tLoss: 1.761637\n","Train Epoch: 9 [17800/33600 (53%)]\tLoss: 1.603402\n","Train Epoch: 9 [18000/33600 (54%)]\tLoss: 2.405853\n","Train Epoch: 9 [18200/33600 (54%)]\tLoss: 2.174547\n","Train Epoch: 9 [18400/33600 (55%)]\tLoss: 2.805976\n","Train Epoch: 9 [18600/33600 (55%)]\tLoss: 1.995286\n","Train Epoch: 9 [18800/33600 (56%)]\tLoss: 1.329906\n","Train Epoch: 9 [19000/33600 (57%)]\tLoss: 1.400002\n","Train Epoch: 9 [19200/33600 (57%)]\tLoss: 2.613652\n","Train Epoch: 9 [19400/33600 (58%)]\tLoss: 2.267169\n","Train Epoch: 9 [19600/33600 (58%)]\tLoss: 2.500841\n","Train Epoch: 9 [19800/33600 (59%)]\tLoss: 2.094950\n","Train Epoch: 9 [20000/33600 (60%)]\tLoss: 1.834769\n","Train Epoch: 9 [20200/33600 (60%)]\tLoss: 2.015615\n","Train Epoch: 9 [20400/33600 (61%)]\tLoss: 2.440921\n","Train Epoch: 9 [20600/33600 (61%)]\tLoss: 2.315340\n","Train Epoch: 9 [20800/33600 (62%)]\tLoss: 2.394007\n","Train Epoch: 9 [21000/33600 (62%)]\tLoss: 1.543072\n","Train Epoch: 9 [21200/33600 (63%)]\tLoss: 1.864302\n","Train Epoch: 9 [21400/33600 (64%)]\tLoss: 2.246495\n","Train Epoch: 9 [21600/33600 (64%)]\tLoss: 2.507941\n","Train Epoch: 9 [21800/33600 (65%)]\tLoss: 2.259840\n","Train Epoch: 9 [22000/33600 (65%)]\tLoss: 2.140414\n","Train Epoch: 9 [22200/33600 (66%)]\tLoss: 2.023632\n","Train Epoch: 9 [22400/33600 (67%)]\tLoss: 2.348629\n","Train Epoch: 9 [22600/33600 (67%)]\tLoss: 2.031725\n","Train Epoch: 9 [22800/33600 (68%)]\tLoss: 2.253930\n","Train Epoch: 9 [23000/33600 (68%)]\tLoss: 2.297307\n","Train Epoch: 9 [23200/33600 (69%)]\tLoss: 2.523364\n","Train Epoch: 9 [23400/33600 (70%)]\tLoss: 2.500398\n","Train Epoch: 9 [23600/33600 (70%)]\tLoss: 2.335859\n","Train Epoch: 9 [23800/33600 (71%)]\tLoss: 2.022971\n","Train Epoch: 9 [24000/33600 (71%)]\tLoss: 2.047477\n","Train Epoch: 9 [24200/33600 (72%)]\tLoss: 2.225840\n","Train Epoch: 9 [24400/33600 (73%)]\tLoss: 2.331352\n","Train Epoch: 9 [24600/33600 (73%)]\tLoss: 2.084036\n","Train Epoch: 9 [24800/33600 (74%)]\tLoss: 2.082842\n","Train Epoch: 9 [25000/33600 (74%)]\tLoss: 2.282460\n","Train Epoch: 9 [25200/33600 (75%)]\tLoss: 2.261262\n","Train Epoch: 9 [25400/33600 (76%)]\tLoss: 3.854470\n","Train Epoch: 9 [25600/33600 (76%)]\tLoss: 1.950529\n","Train Epoch: 9 [25800/33600 (77%)]\tLoss: 2.861403\n","Train Epoch: 9 [26000/33600 (77%)]\tLoss: 2.471937\n","Train Epoch: 9 [26200/33600 (78%)]\tLoss: 2.491745\n","Train Epoch: 9 [26400/33600 (79%)]\tLoss: 2.494542\n","Train Epoch: 9 [26600/33600 (79%)]\tLoss: 2.515924\n","Train Epoch: 9 [26800/33600 (80%)]\tLoss: 2.096512\n","Train Epoch: 9 [27000/33600 (80%)]\tLoss: 1.993679\n","Train Epoch: 9 [27200/33600 (81%)]\tLoss: 1.570277\n","Train Epoch: 9 [27400/33600 (82%)]\tLoss: 2.302344\n","Train Epoch: 9 [27600/33600 (82%)]\tLoss: 2.124012\n","Train Epoch: 9 [27800/33600 (83%)]\tLoss: 1.800098\n","Train Epoch: 9 [28000/33600 (83%)]\tLoss: 1.935428\n","Train Epoch: 9 [28200/33600 (84%)]\tLoss: 2.285516\n","Train Epoch: 9 [28400/33600 (85%)]\tLoss: 1.940131\n","Train Epoch: 9 [28600/33600 (85%)]\tLoss: 1.904686\n","Train Epoch: 9 [28800/33600 (86%)]\tLoss: 2.125911\n","Train Epoch: 9 [29000/33600 (86%)]\tLoss: 2.256021\n","Train Epoch: 9 [29200/33600 (87%)]\tLoss: 1.988811\n","Train Epoch: 9 [29400/33600 (88%)]\tLoss: 1.579307\n","Train Epoch: 9 [29600/33600 (88%)]\tLoss: 2.047636\n","Train Epoch: 9 [29800/33600 (89%)]\tLoss: 2.062559\n","Train Epoch: 9 [30000/33600 (89%)]\tLoss: 2.089941\n","Train Epoch: 9 [30200/33600 (90%)]\tLoss: 2.083989\n","Train Epoch: 9 [30400/33600 (90%)]\tLoss: 1.899025\n","Train Epoch: 9 [30600/33600 (91%)]\tLoss: 2.166818\n","Train Epoch: 9 [30800/33600 (92%)]\tLoss: 2.564240\n","Train Epoch: 9 [31000/33600 (92%)]\tLoss: 2.121095\n","Train Epoch: 9 [31200/33600 (93%)]\tLoss: 2.019871\n","Train Epoch: 9 [31400/33600 (93%)]\tLoss: 2.297052\n","Train Epoch: 9 [31600/33600 (94%)]\tLoss: 1.564675\n","Train Epoch: 9 [31800/33600 (95%)]\tLoss: 2.035640\n","Train Epoch: 9 [32000/33600 (95%)]\tLoss: 2.495070\n","Train Epoch: 9 [32200/33600 (96%)]\tLoss: 1.909337\n","Train Epoch: 9 [32400/33600 (96%)]\tLoss: 2.552100\n","Train Epoch: 9 [32600/33600 (97%)]\tLoss: 2.060133\n","Train Epoch: 9 [32800/33600 (98%)]\tLoss: 2.350059\n","Train Epoch: 9 [33000/33600 (98%)]\tLoss: 1.874987\n","Train Epoch: 9 [33200/33600 (99%)]\tLoss: 2.455432\n","Train Epoch: 9 [33400/33600 (99%)]\tLoss: 2.471778\n","Train Epoch: 9 [33600/33600 (100%)]\tLoss: 1.819951\n","\n","Validation - Average Loss: 2.0511, Accuracy: 36.702%\n","\n","Train Epoch: 10 [200/33600 (1%)]\tLoss: 2.448233\n","Train Epoch: 10 [400/33600 (1%)]\tLoss: 2.067468\n","Train Epoch: 10 [600/33600 (2%)]\tLoss: 2.309223\n","Train Epoch: 10 [800/33600 (2%)]\tLoss: 2.351106\n","Train Epoch: 10 [1000/33600 (3%)]\tLoss: 1.891438\n","Train Epoch: 10 [1200/33600 (4%)]\tLoss: 1.285207\n","Train Epoch: 10 [1400/33600 (4%)]\tLoss: 2.029534\n","Train Epoch: 10 [1600/33600 (5%)]\tLoss: 1.994292\n","Train Epoch: 10 [1800/33600 (5%)]\tLoss: 1.992234\n","Train Epoch: 10 [2000/33600 (6%)]\tLoss: 2.515991\n","Train Epoch: 10 [2200/33600 (7%)]\tLoss: 2.008946\n","Train Epoch: 10 [2400/33600 (7%)]\tLoss: 2.238769\n","Train Epoch: 10 [2600/33600 (8%)]\tLoss: 2.528955\n","Train Epoch: 10 [2800/33600 (8%)]\tLoss: 1.493652\n","Train Epoch: 10 [3000/33600 (9%)]\tLoss: 1.855451\n","Train Epoch: 10 [3200/33600 (10%)]\tLoss: 2.029623\n","Train Epoch: 10 [3400/33600 (10%)]\tLoss: 2.579501\n","Train Epoch: 10 [3600/33600 (11%)]\tLoss: 1.915894\n","Train Epoch: 10 [3800/33600 (11%)]\tLoss: 2.344484\n","Train Epoch: 10 [4000/33600 (12%)]\tLoss: 1.823220\n","Train Epoch: 10 [4200/33600 (12%)]\tLoss: 2.153774\n","Train Epoch: 10 [4400/33600 (13%)]\tLoss: 2.515841\n","Train Epoch: 10 [4600/33600 (14%)]\tLoss: 1.712519\n","Train Epoch: 10 [4800/33600 (14%)]\tLoss: 2.460329\n","Train Epoch: 10 [5000/33600 (15%)]\tLoss: 2.545322\n","Train Epoch: 10 [5200/33600 (15%)]\tLoss: 2.655996\n","Train Epoch: 10 [5400/33600 (16%)]\tLoss: 2.192650\n","Train Epoch: 10 [5600/33600 (17%)]\tLoss: 1.906372\n","Train Epoch: 10 [5800/33600 (17%)]\tLoss: 1.917887\n","Train Epoch: 10 [6000/33600 (18%)]\tLoss: 2.859201\n","Train Epoch: 10 [6200/33600 (18%)]\tLoss: 2.011270\n","Train Epoch: 10 [6400/33600 (19%)]\tLoss: 1.677229\n","Train Epoch: 10 [6600/33600 (20%)]\tLoss: 1.786393\n","Train Epoch: 10 [6800/33600 (20%)]\tLoss: 1.470239\n","Train Epoch: 10 [7000/33600 (21%)]\tLoss: 1.772121\n","Train Epoch: 10 [7200/33600 (21%)]\tLoss: 1.601382\n","Train Epoch: 10 [7400/33600 (22%)]\tLoss: 1.823652\n","Train Epoch: 10 [7600/33600 (23%)]\tLoss: 2.424982\n","Train Epoch: 10 [7800/33600 (23%)]\tLoss: 2.095176\n","Train Epoch: 10 [8000/33600 (24%)]\tLoss: 2.388190\n","Train Epoch: 10 [8200/33600 (24%)]\tLoss: 1.793790\n","Train Epoch: 10 [8400/33600 (25%)]\tLoss: 1.778534\n","Train Epoch: 10 [8600/33600 (26%)]\tLoss: 2.316202\n","Train Epoch: 10 [8800/33600 (26%)]\tLoss: 1.891038\n","Train Epoch: 10 [9000/33600 (27%)]\tLoss: 1.710692\n","Train Epoch: 10 [9200/33600 (27%)]\tLoss: 2.434225\n","Train Epoch: 10 [9400/33600 (28%)]\tLoss: 2.367122\n","Train Epoch: 10 [9600/33600 (29%)]\tLoss: 1.909470\n","Train Epoch: 10 [9800/33600 (29%)]\tLoss: 2.283652\n","Train Epoch: 10 [10000/33600 (30%)]\tLoss: 2.730098\n","Train Epoch: 10 [10200/33600 (30%)]\tLoss: 2.145801\n","Train Epoch: 10 [10400/33600 (31%)]\tLoss: 2.617491\n","Train Epoch: 10 [10600/33600 (32%)]\tLoss: 1.568651\n","Train Epoch: 10 [10800/33600 (32%)]\tLoss: 2.353631\n","Train Epoch: 10 [11000/33600 (33%)]\tLoss: 2.513088\n","Train Epoch: 10 [11200/33600 (33%)]\tLoss: 2.151677\n","Train Epoch: 10 [11400/33600 (34%)]\tLoss: 1.793873\n","Train Epoch: 10 [11600/33600 (35%)]\tLoss: 1.756677\n","Train Epoch: 10 [11800/33600 (35%)]\tLoss: 1.984332\n","Train Epoch: 10 [12000/33600 (36%)]\tLoss: 2.792685\n","Train Epoch: 10 [12200/33600 (36%)]\tLoss: 2.679766\n","Train Epoch: 10 [12400/33600 (37%)]\tLoss: 2.312050\n","Train Epoch: 10 [12600/33600 (38%)]\tLoss: 2.050093\n","Train Epoch: 10 [12800/33600 (38%)]\tLoss: 1.796057\n","Train Epoch: 10 [13000/33600 (39%)]\tLoss: 1.335217\n","Train Epoch: 10 [13200/33600 (39%)]\tLoss: 2.921677\n","Train Epoch: 10 [13400/33600 (40%)]\tLoss: 1.991835\n","Train Epoch: 10 [13600/33600 (40%)]\tLoss: 2.417440\n","Train Epoch: 10 [13800/33600 (41%)]\tLoss: 2.681199\n","Train Epoch: 10 [14000/33600 (42%)]\tLoss: 2.157761\n","Train Epoch: 10 [14200/33600 (42%)]\tLoss: 2.043745\n","Train Epoch: 10 [14400/33600 (43%)]\tLoss: 2.060044\n","Train Epoch: 10 [14600/33600 (43%)]\tLoss: 1.618053\n","Train Epoch: 10 [14800/33600 (44%)]\tLoss: 1.950716\n","Train Epoch: 10 [15000/33600 (45%)]\tLoss: 2.032507\n","Train Epoch: 10 [15200/33600 (45%)]\tLoss: 1.880486\n","Train Epoch: 10 [15400/33600 (46%)]\tLoss: 2.776836\n","Train Epoch: 10 [15600/33600 (46%)]\tLoss: 1.754188\n","Train Epoch: 10 [15800/33600 (47%)]\tLoss: 1.864348\n","Train Epoch: 10 [16000/33600 (48%)]\tLoss: 2.393696\n","Train Epoch: 10 [16200/33600 (48%)]\tLoss: 1.821358\n","Train Epoch: 10 [16400/33600 (49%)]\tLoss: 2.078139\n","Train Epoch: 10 [16600/33600 (49%)]\tLoss: 2.117714\n","Train Epoch: 10 [16800/33600 (50%)]\tLoss: 2.062557\n","Train Epoch: 10 [17000/33600 (51%)]\tLoss: 2.093007\n","Train Epoch: 10 [17200/33600 (51%)]\tLoss: 2.269922\n","Train Epoch: 10 [17400/33600 (52%)]\tLoss: 2.219157\n","Train Epoch: 10 [17600/33600 (52%)]\tLoss: 2.738855\n","Train Epoch: 10 [17800/33600 (53%)]\tLoss: 1.975548\n","Train Epoch: 10 [18000/33600 (54%)]\tLoss: 2.799925\n","Train Epoch: 10 [18200/33600 (54%)]\tLoss: 1.843280\n","Train Epoch: 10 [18400/33600 (55%)]\tLoss: 2.412012\n","Train Epoch: 10 [18600/33600 (55%)]\tLoss: 2.343959\n","Train Epoch: 10 [18800/33600 (56%)]\tLoss: 2.705994\n","Train Epoch: 10 [19000/33600 (57%)]\tLoss: 2.244091\n","Train Epoch: 10 [19200/33600 (57%)]\tLoss: 1.849889\n","Train Epoch: 10 [19400/33600 (58%)]\tLoss: 1.736545\n","Train Epoch: 10 [19600/33600 (58%)]\tLoss: 2.200957\n","Train Epoch: 10 [19800/33600 (59%)]\tLoss: 1.456825\n","Train Epoch: 10 [20000/33600 (60%)]\tLoss: 1.905475\n","Train Epoch: 10 [20200/33600 (60%)]\tLoss: 1.676009\n","Train Epoch: 10 [20400/33600 (61%)]\tLoss: 2.508748\n","Train Epoch: 10 [20600/33600 (61%)]\tLoss: 1.902106\n","Train Epoch: 10 [20800/33600 (62%)]\tLoss: 1.836414\n","Train Epoch: 10 [21000/33600 (62%)]\tLoss: 2.446471\n","Train Epoch: 10 [21200/33600 (63%)]\tLoss: 1.702653\n","Train Epoch: 10 [21400/33600 (64%)]\tLoss: 2.461309\n","Train Epoch: 10 [21600/33600 (64%)]\tLoss: 1.755322\n","Train Epoch: 10 [21800/33600 (65%)]\tLoss: 1.270776\n","Train Epoch: 10 [22000/33600 (65%)]\tLoss: 1.572412\n","Train Epoch: 10 [22200/33600 (66%)]\tLoss: 1.901435\n","Train Epoch: 10 [22400/33600 (67%)]\tLoss: 1.837220\n","Train Epoch: 10 [22600/33600 (67%)]\tLoss: 1.675542\n","Train Epoch: 10 [22800/33600 (68%)]\tLoss: 1.557912\n","Train Epoch: 10 [23000/33600 (68%)]\tLoss: 2.694412\n","Train Epoch: 10 [23200/33600 (69%)]\tLoss: 1.821437\n","Train Epoch: 10 [23400/33600 (70%)]\tLoss: 1.666176\n","Train Epoch: 10 [23600/33600 (70%)]\tLoss: 2.035675\n","Train Epoch: 10 [23800/33600 (71%)]\tLoss: 1.798591\n","Train Epoch: 10 [24000/33600 (71%)]\tLoss: 2.489041\n","Train Epoch: 10 [24200/33600 (72%)]\tLoss: 2.951266\n","Train Epoch: 10 [24400/33600 (73%)]\tLoss: 1.751090\n","Train Epoch: 10 [24600/33600 (73%)]\tLoss: 2.089300\n","Train Epoch: 10 [24800/33600 (74%)]\tLoss: 1.821020\n","Train Epoch: 10 [25000/33600 (74%)]\tLoss: 2.049184\n","Train Epoch: 10 [25200/33600 (75%)]\tLoss: 1.909741\n","Train Epoch: 10 [25400/33600 (76%)]\tLoss: 1.880267\n","Train Epoch: 10 [25600/33600 (76%)]\tLoss: 3.008357\n","Train Epoch: 10 [25800/33600 (77%)]\tLoss: 1.983712\n","Train Epoch: 10 [26000/33600 (77%)]\tLoss: 1.906275\n","Train Epoch: 10 [26200/33600 (78%)]\tLoss: 2.467986\n","Train Epoch: 10 [26400/33600 (79%)]\tLoss: 1.544091\n","Train Epoch: 10 [26600/33600 (79%)]\tLoss: 1.827999\n","Train Epoch: 10 [26800/33600 (80%)]\tLoss: 2.335721\n","Train Epoch: 10 [27000/33600 (80%)]\tLoss: 1.857612\n","Train Epoch: 10 [27200/33600 (81%)]\tLoss: 1.863946\n","Train Epoch: 10 [27400/33600 (82%)]\tLoss: 1.716786\n","Train Epoch: 10 [27600/33600 (82%)]\tLoss: 1.813608\n","Train Epoch: 10 [27800/33600 (83%)]\tLoss: 2.614863\n","Train Epoch: 10 [28000/33600 (83%)]\tLoss: 1.926129\n","Train Epoch: 10 [28200/33600 (84%)]\tLoss: 2.347378\n","Train Epoch: 10 [28400/33600 (85%)]\tLoss: 2.244322\n","Train Epoch: 10 [28600/33600 (85%)]\tLoss: 2.376203\n","Train Epoch: 10 [28800/33600 (86%)]\tLoss: 2.489696\n","Train Epoch: 10 [29000/33600 (86%)]\tLoss: 2.037412\n","Train Epoch: 10 [29200/33600 (87%)]\tLoss: 2.086988\n","Train Epoch: 10 [29400/33600 (88%)]\tLoss: 2.079337\n","Train Epoch: 10 [29600/33600 (88%)]\tLoss: 2.074227\n","Train Epoch: 10 [29800/33600 (89%)]\tLoss: 1.504608\n","Train Epoch: 10 [30000/33600 (89%)]\tLoss: 2.566840\n","Train Epoch: 10 [30200/33600 (90%)]\tLoss: 2.159970\n","Train Epoch: 10 [30400/33600 (90%)]\tLoss: 2.137861\n","Train Epoch: 10 [30600/33600 (91%)]\tLoss: 1.997130\n","Train Epoch: 10 [30800/33600 (92%)]\tLoss: 1.504808\n","Train Epoch: 10 [31000/33600 (92%)]\tLoss: 2.252041\n","Train Epoch: 10 [31200/33600 (93%)]\tLoss: 1.753321\n","Train Epoch: 10 [31400/33600 (93%)]\tLoss: 1.907083\n","Train Epoch: 10 [31600/33600 (94%)]\tLoss: 2.559604\n","Train Epoch: 10 [31800/33600 (95%)]\tLoss: 2.143374\n","Train Epoch: 10 [32000/33600 (95%)]\tLoss: 1.824294\n","Train Epoch: 10 [32200/33600 (96%)]\tLoss: 1.564165\n","Train Epoch: 10 [32400/33600 (96%)]\tLoss: 1.941640\n","Train Epoch: 10 [32600/33600 (97%)]\tLoss: 1.361223\n","Train Epoch: 10 [32800/33600 (98%)]\tLoss: 1.487788\n","Train Epoch: 10 [33000/33600 (98%)]\tLoss: 1.892646\n","Train Epoch: 10 [33200/33600 (99%)]\tLoss: 1.867233\n","Train Epoch: 10 [33400/33600 (99%)]\tLoss: 1.929121\n","Train Epoch: 10 [33600/33600 (100%)]\tLoss: 1.848857\n","\n","Validation - Average Loss: 1.9980, Accuracy: 39.905%\n","\n","Train Epoch: 11 [200/33600 (1%)]\tLoss: 2.389039\n","Train Epoch: 11 [400/33600 (1%)]\tLoss: 1.779645\n","Train Epoch: 11 [600/33600 (2%)]\tLoss: 2.497860\n","Train Epoch: 11 [800/33600 (2%)]\tLoss: 2.330347\n","Train Epoch: 11 [1000/33600 (3%)]\tLoss: 2.713892\n","Train Epoch: 11 [1200/33600 (4%)]\tLoss: 1.471942\n","Train Epoch: 11 [1400/33600 (4%)]\tLoss: 1.643294\n","Train Epoch: 11 [1600/33600 (5%)]\tLoss: 2.628690\n","Train Epoch: 11 [1800/33600 (5%)]\tLoss: 2.061440\n","Train Epoch: 11 [2000/33600 (6%)]\tLoss: 2.250206\n","Train Epoch: 11 [2200/33600 (7%)]\tLoss: 2.725995\n","Train Epoch: 11 [2400/33600 (7%)]\tLoss: 1.967147\n","Train Epoch: 11 [2600/33600 (8%)]\tLoss: 2.605689\n","Train Epoch: 11 [2800/33600 (8%)]\tLoss: 2.156859\n","Train Epoch: 11 [3000/33600 (9%)]\tLoss: 1.601995\n","Train Epoch: 11 [3200/33600 (10%)]\tLoss: 2.069145\n","Train Epoch: 11 [3400/33600 (10%)]\tLoss: 2.143661\n","Train Epoch: 11 [3600/33600 (11%)]\tLoss: 2.360965\n","Train Epoch: 11 [3800/33600 (11%)]\tLoss: 1.928982\n","Train Epoch: 11 [4000/33600 (12%)]\tLoss: 2.087212\n","Train Epoch: 11 [4200/33600 (12%)]\tLoss: 2.231275\n","Train Epoch: 11 [4400/33600 (13%)]\tLoss: 2.560612\n","Train Epoch: 11 [4600/33600 (14%)]\tLoss: 2.446216\n","Train Epoch: 11 [4800/33600 (14%)]\tLoss: 2.584623\n","Train Epoch: 11 [5000/33600 (15%)]\tLoss: 1.964875\n","Train Epoch: 11 [5200/33600 (15%)]\tLoss: 1.959900\n","Train Epoch: 11 [5400/33600 (16%)]\tLoss: 1.952954\n","Train Epoch: 11 [5600/33600 (17%)]\tLoss: 1.616435\n","Train Epoch: 11 [5800/33600 (17%)]\tLoss: 1.674646\n","Train Epoch: 11 [6000/33600 (18%)]\tLoss: 2.124382\n","Train Epoch: 11 [6200/33600 (18%)]\tLoss: 1.569488\n","Train Epoch: 11 [6400/33600 (19%)]\tLoss: 2.285551\n","Train Epoch: 11 [6600/33600 (20%)]\tLoss: 1.678624\n","Train Epoch: 11 [6800/33600 (20%)]\tLoss: 2.359931\n","Train Epoch: 11 [7000/33600 (21%)]\tLoss: 2.015908\n","Train Epoch: 11 [7200/33600 (21%)]\tLoss: 2.002158\n","Train Epoch: 11 [7400/33600 (22%)]\tLoss: 1.994807\n","Train Epoch: 11 [7600/33600 (23%)]\tLoss: 2.639997\n","Train Epoch: 11 [7800/33600 (23%)]\tLoss: 2.266291\n","Train Epoch: 11 [8000/33600 (24%)]\tLoss: 1.785686\n","Train Epoch: 11 [8200/33600 (24%)]\tLoss: 1.852004\n","Train Epoch: 11 [8400/33600 (25%)]\tLoss: 1.941477\n","Train Epoch: 11 [8600/33600 (26%)]\tLoss: 2.346977\n","Train Epoch: 11 [8800/33600 (26%)]\tLoss: 2.164463\n","Train Epoch: 11 [9000/33600 (27%)]\tLoss: 2.291446\n","Train Epoch: 11 [9200/33600 (27%)]\tLoss: 1.939435\n","Train Epoch: 11 [9400/33600 (28%)]\tLoss: 1.656827\n","Train Epoch: 11 [9600/33600 (29%)]\tLoss: 1.794953\n","Train Epoch: 11 [9800/33600 (29%)]\tLoss: 3.043090\n","Train Epoch: 11 [10000/33600 (30%)]\tLoss: 1.897564\n","Train Epoch: 11 [10200/33600 (30%)]\tLoss: 1.832975\n","Train Epoch: 11 [10400/33600 (31%)]\tLoss: 2.521558\n","Train Epoch: 11 [10600/33600 (32%)]\tLoss: 2.182499\n","Train Epoch: 11 [10800/33600 (32%)]\tLoss: 1.622763\n","Train Epoch: 11 [11000/33600 (33%)]\tLoss: 1.897931\n","Train Epoch: 11 [11200/33600 (33%)]\tLoss: 2.151500\n","Train Epoch: 11 [11400/33600 (34%)]\tLoss: 2.635673\n","Train Epoch: 11 [11600/33600 (35%)]\tLoss: 2.680373\n","Train Epoch: 11 [11800/33600 (35%)]\tLoss: 2.763302\n","Train Epoch: 11 [12000/33600 (36%)]\tLoss: 1.708054\n","Train Epoch: 11 [12200/33600 (36%)]\tLoss: 1.966279\n","Train Epoch: 11 [12400/33600 (37%)]\tLoss: 2.041713\n","Train Epoch: 11 [12600/33600 (38%)]\tLoss: 2.022168\n","Train Epoch: 11 [12800/33600 (38%)]\tLoss: 1.456590\n","Train Epoch: 11 [13000/33600 (39%)]\tLoss: 2.482951\n","Train Epoch: 11 [13200/33600 (39%)]\tLoss: 2.361645\n","Train Epoch: 11 [13400/33600 (40%)]\tLoss: 2.506474\n","Train Epoch: 11 [13600/33600 (40%)]\tLoss: 2.315538\n","Train Epoch: 11 [13800/33600 (41%)]\tLoss: 1.965540\n","Train Epoch: 11 [14000/33600 (42%)]\tLoss: 1.862548\n","Train Epoch: 11 [14200/33600 (42%)]\tLoss: 2.135867\n","Train Epoch: 11 [14400/33600 (43%)]\tLoss: 1.872743\n","Train Epoch: 11 [14600/33600 (43%)]\tLoss: 2.593640\n","Train Epoch: 11 [14800/33600 (44%)]\tLoss: 1.907123\n","Train Epoch: 11 [15000/33600 (45%)]\tLoss: 1.707053\n","Train Epoch: 11 [15200/33600 (45%)]\tLoss: 1.957065\n","Train Epoch: 11 [15400/33600 (46%)]\tLoss: 2.334542\n","Train Epoch: 11 [15600/33600 (46%)]\tLoss: 1.724116\n","Train Epoch: 11 [15800/33600 (47%)]\tLoss: 2.330854\n","Train Epoch: 11 [16000/33600 (48%)]\tLoss: 1.506051\n","Train Epoch: 11 [16200/33600 (48%)]\tLoss: 1.947384\n","Train Epoch: 11 [16400/33600 (49%)]\tLoss: 2.673531\n","Train Epoch: 11 [16600/33600 (49%)]\tLoss: 2.162657\n","Train Epoch: 11 [16800/33600 (50%)]\tLoss: 2.601971\n","Train Epoch: 11 [17000/33600 (51%)]\tLoss: 2.337021\n","Train Epoch: 11 [17200/33600 (51%)]\tLoss: 1.605417\n","Train Epoch: 11 [17400/33600 (52%)]\tLoss: 1.584641\n","Train Epoch: 11 [17600/33600 (52%)]\tLoss: 2.098816\n","Train Epoch: 11 [17800/33600 (53%)]\tLoss: 1.552555\n","Train Epoch: 11 [18000/33600 (54%)]\tLoss: 2.320577\n","Train Epoch: 11 [18200/33600 (54%)]\tLoss: 1.824427\n","Train Epoch: 11 [18400/33600 (55%)]\tLoss: 2.201921\n","Train Epoch: 11 [18600/33600 (55%)]\tLoss: 2.126498\n","Train Epoch: 11 [18800/33600 (56%)]\tLoss: 2.308755\n","Train Epoch: 11 [19000/33600 (57%)]\tLoss: 2.263808\n","Train Epoch: 11 [19200/33600 (57%)]\tLoss: 1.948933\n","Train Epoch: 11 [19400/33600 (58%)]\tLoss: 2.542224\n","Train Epoch: 11 [19600/33600 (58%)]\tLoss: 2.219952\n","Train Epoch: 11 [19800/33600 (59%)]\tLoss: 1.621598\n","Train Epoch: 11 [20000/33600 (60%)]\tLoss: 1.469442\n","Train Epoch: 11 [20200/33600 (60%)]\tLoss: 2.858029\n","Train Epoch: 11 [20400/33600 (61%)]\tLoss: 1.680867\n","Train Epoch: 11 [20600/33600 (61%)]\tLoss: 1.830729\n","Train Epoch: 11 [20800/33600 (62%)]\tLoss: 1.881588\n","Train Epoch: 11 [21000/33600 (62%)]\tLoss: 1.672918\n","Train Epoch: 11 [21200/33600 (63%)]\tLoss: 2.606018\n","Train Epoch: 11 [21400/33600 (64%)]\tLoss: 1.660746\n","Train Epoch: 11 [21600/33600 (64%)]\tLoss: 2.446285\n","Train Epoch: 11 [21800/33600 (65%)]\tLoss: 2.467805\n","Train Epoch: 11 [22000/33600 (65%)]\tLoss: 2.348155\n","Train Epoch: 11 [22200/33600 (66%)]\tLoss: 2.435426\n","Train Epoch: 11 [22400/33600 (67%)]\tLoss: 1.855366\n","Train Epoch: 11 [22600/33600 (67%)]\tLoss: 1.977257\n","Train Epoch: 11 [22800/33600 (68%)]\tLoss: 2.342358\n","Train Epoch: 11 [23000/33600 (68%)]\tLoss: 2.640488\n","Train Epoch: 11 [23200/33600 (69%)]\tLoss: 2.572541\n","Train Epoch: 11 [23400/33600 (70%)]\tLoss: 2.274516\n","Train Epoch: 11 [23600/33600 (70%)]\tLoss: 1.650005\n","Train Epoch: 11 [23800/33600 (71%)]\tLoss: 1.346187\n","Train Epoch: 11 [24000/33600 (71%)]\tLoss: 2.002965\n","Train Epoch: 11 [24200/33600 (72%)]\tLoss: 2.716680\n","Train Epoch: 11 [24400/33600 (73%)]\tLoss: 2.351730\n","Train Epoch: 11 [24600/33600 (73%)]\tLoss: 2.012660\n","Train Epoch: 11 [24800/33600 (74%)]\tLoss: 1.916558\n","Train Epoch: 11 [25000/33600 (74%)]\tLoss: 2.355077\n","Train Epoch: 11 [25200/33600 (75%)]\tLoss: 2.298050\n","Train Epoch: 11 [25400/33600 (76%)]\tLoss: 1.909683\n","Train Epoch: 11 [25600/33600 (76%)]\tLoss: 2.855237\n","Train Epoch: 11 [25800/33600 (77%)]\tLoss: 2.507309\n","Train Epoch: 11 [26000/33600 (77%)]\tLoss: 2.713428\n","Train Epoch: 11 [26200/33600 (78%)]\tLoss: 1.364522\n","Train Epoch: 11 [26400/33600 (79%)]\tLoss: 1.444452\n","Train Epoch: 11 [26600/33600 (79%)]\tLoss: 2.497109\n","Train Epoch: 11 [26800/33600 (80%)]\tLoss: 2.041277\n","Train Epoch: 11 [27000/33600 (80%)]\tLoss: 1.810342\n","Train Epoch: 11 [27200/33600 (81%)]\tLoss: 2.436739\n","Train Epoch: 11 [27400/33600 (82%)]\tLoss: 1.780818\n","Train Epoch: 11 [27600/33600 (82%)]\tLoss: 1.707007\n","Train Epoch: 11 [27800/33600 (83%)]\tLoss: 2.251869\n","Train Epoch: 11 [28000/33600 (83%)]\tLoss: 1.931938\n","Train Epoch: 11 [28200/33600 (84%)]\tLoss: 2.007993\n","Train Epoch: 11 [28400/33600 (85%)]\tLoss: 2.182330\n","Train Epoch: 11 [28600/33600 (85%)]\tLoss: 2.673968\n","Train Epoch: 11 [28800/33600 (86%)]\tLoss: 2.702221\n","Train Epoch: 11 [29000/33600 (86%)]\tLoss: 2.377422\n","Train Epoch: 11 [29200/33600 (87%)]\tLoss: 2.012672\n","Train Epoch: 11 [29400/33600 (88%)]\tLoss: 1.953080\n","Train Epoch: 11 [29600/33600 (88%)]\tLoss: 1.783321\n","Train Epoch: 11 [29800/33600 (89%)]\tLoss: 1.573803\n","Train Epoch: 11 [30000/33600 (89%)]\tLoss: 2.563588\n","Train Epoch: 11 [30200/33600 (90%)]\tLoss: 1.838631\n","Train Epoch: 11 [30400/33600 (90%)]\tLoss: 1.724265\n","Train Epoch: 11 [30600/33600 (91%)]\tLoss: 2.517411\n","Train Epoch: 11 [30800/33600 (92%)]\tLoss: 2.031259\n","Train Epoch: 11 [31000/33600 (92%)]\tLoss: 2.036119\n","Train Epoch: 11 [31200/33600 (93%)]\tLoss: 2.113860\n","Train Epoch: 11 [31400/33600 (93%)]\tLoss: 1.967129\n","Train Epoch: 11 [31600/33600 (94%)]\tLoss: 1.715499\n","Train Epoch: 11 [31800/33600 (95%)]\tLoss: 2.628872\n","Train Epoch: 11 [32000/33600 (95%)]\tLoss: 1.550686\n","Train Epoch: 11 [32200/33600 (96%)]\tLoss: 1.787011\n","Train Epoch: 11 [32400/33600 (96%)]\tLoss: 2.112024\n","Train Epoch: 11 [32600/33600 (97%)]\tLoss: 2.155750\n","Train Epoch: 11 [32800/33600 (98%)]\tLoss: 2.426398\n","Train Epoch: 11 [33000/33600 (98%)]\tLoss: 1.787599\n","Train Epoch: 11 [33200/33600 (99%)]\tLoss: 1.641984\n","Train Epoch: 11 [33400/33600 (99%)]\tLoss: 2.111166\n","Train Epoch: 11 [33600/33600 (100%)]\tLoss: 2.020827\n","\n","Validation - Average Loss: 2.0104, Accuracy: 27.881%\n","\n","Train Epoch: 12 [200/33600 (1%)]\tLoss: 2.546787\n","Train Epoch: 12 [400/33600 (1%)]\tLoss: 2.358851\n","Train Epoch: 12 [600/33600 (2%)]\tLoss: 2.465242\n","Train Epoch: 12 [800/33600 (2%)]\tLoss: 2.194943\n","Train Epoch: 12 [1000/33600 (3%)]\tLoss: 1.702014\n","Train Epoch: 12 [1200/33600 (4%)]\tLoss: 1.671010\n","Train Epoch: 12 [1400/33600 (4%)]\tLoss: 1.515986\n","Train Epoch: 12 [1600/33600 (5%)]\tLoss: 1.996404\n","Train Epoch: 12 [1800/33600 (5%)]\tLoss: 2.008565\n","Train Epoch: 12 [2000/33600 (6%)]\tLoss: 2.533520\n","Train Epoch: 12 [2200/33600 (7%)]\tLoss: 2.156290\n","Train Epoch: 12 [2400/33600 (7%)]\tLoss: 2.136895\n","Train Epoch: 12 [2600/33600 (8%)]\tLoss: 2.089793\n","Train Epoch: 12 [2800/33600 (8%)]\tLoss: 2.785286\n","Train Epoch: 12 [3000/33600 (9%)]\tLoss: 1.803120\n","Train Epoch: 12 [3200/33600 (10%)]\tLoss: 2.624393\n","Train Epoch: 12 [3400/33600 (10%)]\tLoss: 2.072414\n","Train Epoch: 12 [3600/33600 (11%)]\tLoss: 2.996918\n","Train Epoch: 12 [3800/33600 (11%)]\tLoss: 1.979513\n","Train Epoch: 12 [4000/33600 (12%)]\tLoss: 1.949482\n","Train Epoch: 12 [4200/33600 (12%)]\tLoss: 1.820440\n","Train Epoch: 12 [4400/33600 (13%)]\tLoss: 1.647849\n","Train Epoch: 12 [4600/33600 (14%)]\tLoss: 1.593625\n","Train Epoch: 12 [4800/33600 (14%)]\tLoss: 1.620547\n","Train Epoch: 12 [5000/33600 (15%)]\tLoss: 1.619523\n","Train Epoch: 12 [5200/33600 (15%)]\tLoss: 1.784994\n","Train Epoch: 12 [5400/33600 (16%)]\tLoss: 2.467663\n","Train Epoch: 12 [5600/33600 (17%)]\tLoss: 1.690799\n","Train Epoch: 12 [5800/33600 (17%)]\tLoss: 2.270179\n","Train Epoch: 12 [6000/33600 (18%)]\tLoss: 2.041728\n","Train Epoch: 12 [6200/33600 (18%)]\tLoss: 2.294822\n","Train Epoch: 12 [6400/33600 (19%)]\tLoss: 1.709112\n","Train Epoch: 12 [6600/33600 (20%)]\tLoss: 1.656546\n","Train Epoch: 12 [6800/33600 (20%)]\tLoss: 2.010496\n","Train Epoch: 12 [7000/33600 (21%)]\tLoss: 2.291398\n","Train Epoch: 12 [7200/33600 (21%)]\tLoss: 2.273171\n","Train Epoch: 12 [7400/33600 (22%)]\tLoss: 2.275326\n","Train Epoch: 12 [7600/33600 (23%)]\tLoss: 1.722489\n","Train Epoch: 12 [7800/33600 (23%)]\tLoss: 2.500981\n","Train Epoch: 12 [8000/33600 (24%)]\tLoss: 1.590171\n","Train Epoch: 12 [8200/33600 (24%)]\tLoss: 2.403763\n","Train Epoch: 12 [8400/33600 (25%)]\tLoss: 3.165038\n","Train Epoch: 12 [8600/33600 (26%)]\tLoss: 1.877481\n","Train Epoch: 12 [8800/33600 (26%)]\tLoss: 2.399981\n","Train Epoch: 12 [9000/33600 (27%)]\tLoss: 2.696488\n","Train Epoch: 12 [9200/33600 (27%)]\tLoss: 2.642418\n","Train Epoch: 12 [9400/33600 (28%)]\tLoss: 1.850743\n","Train Epoch: 12 [9600/33600 (29%)]\tLoss: 1.875454\n","Train Epoch: 12 [9800/33600 (29%)]\tLoss: 1.783798\n","Train Epoch: 12 [10000/33600 (30%)]\tLoss: 2.536020\n","Train Epoch: 12 [10200/33600 (30%)]\tLoss: 1.603029\n","Train Epoch: 12 [10400/33600 (31%)]\tLoss: 2.262217\n","Train Epoch: 12 [10600/33600 (32%)]\tLoss: 2.051127\n","Train Epoch: 12 [10800/33600 (32%)]\tLoss: 2.450291\n","Train Epoch: 12 [11000/33600 (33%)]\tLoss: 1.674040\n","Train Epoch: 12 [11200/33600 (33%)]\tLoss: 2.091477\n","Train Epoch: 12 [11400/33600 (34%)]\tLoss: 1.827342\n","Train Epoch: 12 [11600/33600 (35%)]\tLoss: 1.863452\n","Train Epoch: 12 [11800/33600 (35%)]\tLoss: 1.889114\n","Train Epoch: 12 [12000/33600 (36%)]\tLoss: 2.619711\n","Train Epoch: 12 [12200/33600 (36%)]\tLoss: 2.386637\n","Train Epoch: 12 [12400/33600 (37%)]\tLoss: 1.837730\n","Train Epoch: 12 [12600/33600 (38%)]\tLoss: 2.181386\n","Train Epoch: 12 [12800/33600 (38%)]\tLoss: 3.050493\n","Train Epoch: 12 [13000/33600 (39%)]\tLoss: 1.869031\n","Train Epoch: 12 [13200/33600 (39%)]\tLoss: 2.235236\n","Train Epoch: 12 [13400/33600 (40%)]\tLoss: 2.323226\n","Train Epoch: 12 [13600/33600 (40%)]\tLoss: 2.761009\n","Train Epoch: 12 [13800/33600 (41%)]\tLoss: 1.234352\n","Train Epoch: 12 [14000/33600 (42%)]\tLoss: 1.797369\n","Train Epoch: 12 [14200/33600 (42%)]\tLoss: 2.177019\n","Train Epoch: 12 [14400/33600 (43%)]\tLoss: 2.724885\n","Train Epoch: 12 [14600/33600 (43%)]\tLoss: 3.419515\n","Train Epoch: 12 [14800/33600 (44%)]\tLoss: 2.198641\n","Train Epoch: 12 [15000/33600 (45%)]\tLoss: 1.967654\n","Train Epoch: 12 [15200/33600 (45%)]\tLoss: 1.621756\n","Train Epoch: 12 [15400/33600 (46%)]\tLoss: 2.578035\n","Train Epoch: 12 [15600/33600 (46%)]\tLoss: 1.935836\n","Train Epoch: 12 [15800/33600 (47%)]\tLoss: 2.802507\n","Train Epoch: 12 [16000/33600 (48%)]\tLoss: 2.102306\n","Train Epoch: 12 [16200/33600 (48%)]\tLoss: 2.520408\n","Train Epoch: 12 [16400/33600 (49%)]\tLoss: 1.883449\n","Train Epoch: 12 [16600/33600 (49%)]\tLoss: 1.889975\n","Train Epoch: 12 [16800/33600 (50%)]\tLoss: 2.377645\n","Train Epoch: 12 [17000/33600 (51%)]\tLoss: 1.917436\n","Train Epoch: 12 [17200/33600 (51%)]\tLoss: 2.630614\n","Train Epoch: 12 [17400/33600 (52%)]\tLoss: 2.062253\n","Train Epoch: 12 [17600/33600 (52%)]\tLoss: 1.554905\n","Train Epoch: 12 [17800/33600 (53%)]\tLoss: 2.579797\n","Train Epoch: 12 [18000/33600 (54%)]\tLoss: 2.311607\n","Train Epoch: 12 [18200/33600 (54%)]\tLoss: 1.853114\n","Train Epoch: 12 [18400/33600 (55%)]\tLoss: 2.675070\n","Train Epoch: 12 [18600/33600 (55%)]\tLoss: 2.625952\n","Train Epoch: 12 [18800/33600 (56%)]\tLoss: 2.236376\n","Train Epoch: 12 [19000/33600 (57%)]\tLoss: 1.701276\n","Train Epoch: 12 [19200/33600 (57%)]\tLoss: 2.302859\n","Train Epoch: 12 [19400/33600 (58%)]\tLoss: 1.699948\n","Train Epoch: 12 [19600/33600 (58%)]\tLoss: 1.632453\n","Train Epoch: 12 [19800/33600 (59%)]\tLoss: 1.503472\n","Train Epoch: 12 [20000/33600 (60%)]\tLoss: 2.372145\n","Train Epoch: 12 [20200/33600 (60%)]\tLoss: 1.885182\n","Train Epoch: 12 [20400/33600 (61%)]\tLoss: 1.576700\n","Train Epoch: 12 [20600/33600 (61%)]\tLoss: 2.330621\n","Train Epoch: 12 [20800/33600 (62%)]\tLoss: 1.716198\n","Train Epoch: 12 [21000/33600 (62%)]\tLoss: 2.359234\n","Train Epoch: 12 [21200/33600 (63%)]\tLoss: 2.183112\n","Train Epoch: 12 [21400/33600 (64%)]\tLoss: 2.570047\n","Train Epoch: 12 [21600/33600 (64%)]\tLoss: 2.661218\n","Train Epoch: 12 [21800/33600 (65%)]\tLoss: 1.970664\n","Train Epoch: 12 [22000/33600 (65%)]\tLoss: 1.507286\n","Train Epoch: 12 [22200/33600 (66%)]\tLoss: 1.946460\n","Train Epoch: 12 [22400/33600 (67%)]\tLoss: 1.747726\n","Train Epoch: 12 [22600/33600 (67%)]\tLoss: 2.288734\n","Train Epoch: 12 [22800/33600 (68%)]\tLoss: 1.615672\n","Train Epoch: 12 [23000/33600 (68%)]\tLoss: 2.564435\n","Train Epoch: 12 [23200/33600 (69%)]\tLoss: 2.075232\n","Train Epoch: 12 [23400/33600 (70%)]\tLoss: 2.036850\n","Train Epoch: 12 [23600/33600 (70%)]\tLoss: 1.901169\n","Train Epoch: 12 [23800/33600 (71%)]\tLoss: 2.143716\n","Train Epoch: 12 [24000/33600 (71%)]\tLoss: 2.423641\n","Train Epoch: 12 [24200/33600 (72%)]\tLoss: 1.988746\n","Train Epoch: 12 [24400/33600 (73%)]\tLoss: 2.200451\n","Train Epoch: 12 [24600/33600 (73%)]\tLoss: 1.893378\n","Train Epoch: 12 [24800/33600 (74%)]\tLoss: 1.647967\n","Train Epoch: 12 [25000/33600 (74%)]\tLoss: 1.905785\n","Train Epoch: 12 [25200/33600 (75%)]\tLoss: 2.566140\n","Train Epoch: 12 [25400/33600 (76%)]\tLoss: 2.669316\n","Train Epoch: 12 [25600/33600 (76%)]\tLoss: 2.757171\n","Train Epoch: 12 [25800/33600 (77%)]\tLoss: 2.603777\n","Train Epoch: 12 [26000/33600 (77%)]\tLoss: 2.128242\n","Train Epoch: 12 [26200/33600 (78%)]\tLoss: 1.979535\n","Train Epoch: 12 [26400/33600 (79%)]\tLoss: 1.978992\n","Train Epoch: 12 [26600/33600 (79%)]\tLoss: 2.665730\n","Train Epoch: 12 [26800/33600 (80%)]\tLoss: 1.916784\n","Train Epoch: 12 [27000/33600 (80%)]\tLoss: 2.051424\n","Train Epoch: 12 [27200/33600 (81%)]\tLoss: 3.153438\n","Train Epoch: 12 [27400/33600 (82%)]\tLoss: 2.486540\n","Train Epoch: 12 [27600/33600 (82%)]\tLoss: 2.619265\n","Train Epoch: 12 [27800/33600 (83%)]\tLoss: 2.201155\n","Train Epoch: 12 [28000/33600 (83%)]\tLoss: 2.644233\n","Train Epoch: 12 [28200/33600 (84%)]\tLoss: 1.687056\n","Train Epoch: 12 [28400/33600 (85%)]\tLoss: 1.522628\n","Train Epoch: 12 [28600/33600 (85%)]\tLoss: 2.347398\n","Train Epoch: 12 [28800/33600 (86%)]\tLoss: 1.488971\n","Train Epoch: 12 [29000/33600 (86%)]\tLoss: 1.437461\n","Train Epoch: 12 [29200/33600 (87%)]\tLoss: 2.044007\n","Train Epoch: 12 [29400/33600 (88%)]\tLoss: 1.873939\n","Train Epoch: 12 [29600/33600 (88%)]\tLoss: 2.272407\n","Train Epoch: 12 [29800/33600 (89%)]\tLoss: 2.993706\n","Train Epoch: 12 [30000/33600 (89%)]\tLoss: 2.923988\n","Train Epoch: 12 [30200/33600 (90%)]\tLoss: 1.977376\n","Train Epoch: 12 [30400/33600 (90%)]\tLoss: 1.987375\n","Train Epoch: 12 [30600/33600 (91%)]\tLoss: 1.692621\n","Train Epoch: 12 [30800/33600 (92%)]\tLoss: 2.307283\n","Train Epoch: 12 [31000/33600 (92%)]\tLoss: 2.375175\n","Train Epoch: 12 [31200/33600 (93%)]\tLoss: 1.980110\n","Train Epoch: 12 [31400/33600 (93%)]\tLoss: 2.072145\n","Train Epoch: 12 [31600/33600 (94%)]\tLoss: 1.672747\n","Train Epoch: 12 [31800/33600 (95%)]\tLoss: 2.707463\n","Train Epoch: 12 [32000/33600 (95%)]\tLoss: 1.973472\n","Train Epoch: 12 [32200/33600 (96%)]\tLoss: 3.472486\n","Train Epoch: 12 [32400/33600 (96%)]\tLoss: 1.714201\n","Train Epoch: 12 [32600/33600 (97%)]\tLoss: 2.168090\n","Train Epoch: 12 [32800/33600 (98%)]\tLoss: 2.202807\n","Train Epoch: 12 [33000/33600 (98%)]\tLoss: 2.397642\n","Train Epoch: 12 [33200/33600 (99%)]\tLoss: 1.828015\n","Train Epoch: 12 [33400/33600 (99%)]\tLoss: 1.908068\n","Train Epoch: 12 [33600/33600 (100%)]\tLoss: 2.200838\n","\n","Validation - Average Loss: 1.9447, Accuracy: 44.214%\n","\n","Train Epoch: 13 [200/33600 (1%)]\tLoss: 2.445649\n","Train Epoch: 13 [400/33600 (1%)]\tLoss: 2.205781\n","Train Epoch: 13 [600/33600 (2%)]\tLoss: 2.276928\n","Train Epoch: 13 [800/33600 (2%)]\tLoss: 2.128468\n","Train Epoch: 13 [1000/33600 (3%)]\tLoss: 1.968988\n","Train Epoch: 13 [1200/33600 (4%)]\tLoss: 1.874721\n","Train Epoch: 13 [1400/33600 (4%)]\tLoss: 2.353609\n","Train Epoch: 13 [1600/33600 (5%)]\tLoss: 2.381858\n","Train Epoch: 13 [1800/33600 (5%)]\tLoss: 2.237294\n","Train Epoch: 13 [2000/33600 (6%)]\tLoss: 1.644506\n","Train Epoch: 13 [2200/33600 (7%)]\tLoss: 2.563147\n","Train Epoch: 13 [2400/33600 (7%)]\tLoss: 2.475473\n","Train Epoch: 13 [2600/33600 (8%)]\tLoss: 2.365605\n","Train Epoch: 13 [2800/33600 (8%)]\tLoss: 2.353961\n","Train Epoch: 13 [3000/33600 (9%)]\tLoss: 3.322110\n","Train Epoch: 13 [3200/33600 (10%)]\tLoss: 1.792571\n","Train Epoch: 13 [3400/33600 (10%)]\tLoss: 1.756193\n","Train Epoch: 13 [3600/33600 (11%)]\tLoss: 2.005346\n","Train Epoch: 13 [3800/33600 (11%)]\tLoss: 1.744927\n","Train Epoch: 13 [4000/33600 (12%)]\tLoss: 1.685465\n","Train Epoch: 13 [4200/33600 (12%)]\tLoss: 2.211827\n","Train Epoch: 13 [4400/33600 (13%)]\tLoss: 2.630263\n","Train Epoch: 13 [4600/33600 (14%)]\tLoss: 1.647766\n","Train Epoch: 13 [4800/33600 (14%)]\tLoss: 1.799609\n","Train Epoch: 13 [5000/33600 (15%)]\tLoss: 2.684869\n","Train Epoch: 13 [5200/33600 (15%)]\tLoss: 1.722579\n","Train Epoch: 13 [5400/33600 (16%)]\tLoss: 2.066871\n","Train Epoch: 13 [5600/33600 (17%)]\tLoss: 2.406395\n","Train Epoch: 13 [5800/33600 (17%)]\tLoss: 2.308065\n","Train Epoch: 13 [6000/33600 (18%)]\tLoss: 2.919355\n","Train Epoch: 13 [6200/33600 (18%)]\tLoss: 2.331280\n","Train Epoch: 13 [6400/33600 (19%)]\tLoss: 2.209646\n","Train Epoch: 13 [6600/33600 (20%)]\tLoss: 2.576323\n","Train Epoch: 13 [6800/33600 (20%)]\tLoss: 2.112510\n","Train Epoch: 13 [7000/33600 (21%)]\tLoss: 2.049802\n","Train Epoch: 13 [7200/33600 (21%)]\tLoss: 2.766870\n","Train Epoch: 13 [7400/33600 (22%)]\tLoss: 2.199932\n","Train Epoch: 13 [7600/33600 (23%)]\tLoss: 2.263288\n","Train Epoch: 13 [7800/33600 (23%)]\tLoss: 1.727243\n","Train Epoch: 13 [8000/33600 (24%)]\tLoss: 1.742913\n","Train Epoch: 13 [8200/33600 (24%)]\tLoss: 2.113280\n","Train Epoch: 13 [8400/33600 (25%)]\tLoss: 1.936356\n","Train Epoch: 13 [8600/33600 (26%)]\tLoss: 1.689397\n","Train Epoch: 13 [8800/33600 (26%)]\tLoss: 2.132890\n","Train Epoch: 13 [9000/33600 (27%)]\tLoss: 1.944422\n","Train Epoch: 13 [9200/33600 (27%)]\tLoss: 1.968667\n","Train Epoch: 13 [9400/33600 (28%)]\tLoss: 2.327658\n","Train Epoch: 13 [9600/33600 (29%)]\tLoss: 1.930075\n","Train Epoch: 13 [9800/33600 (29%)]\tLoss: 2.506824\n","Train Epoch: 13 [10000/33600 (30%)]\tLoss: 2.411519\n","Train Epoch: 13 [10200/33600 (30%)]\tLoss: 2.191751\n","Train Epoch: 13 [10400/33600 (31%)]\tLoss: 1.834288\n","Train Epoch: 13 [10600/33600 (32%)]\tLoss: 1.824085\n","Train Epoch: 13 [10800/33600 (32%)]\tLoss: 1.955483\n","Train Epoch: 13 [11000/33600 (33%)]\tLoss: 2.440799\n","Train Epoch: 13 [11200/33600 (33%)]\tLoss: 2.435355\n","Train Epoch: 13 [11400/33600 (34%)]\tLoss: 1.619683\n","Train Epoch: 13 [11600/33600 (35%)]\tLoss: 1.437451\n","Train Epoch: 13 [11800/33600 (35%)]\tLoss: 2.513065\n","Train Epoch: 13 [12000/33600 (36%)]\tLoss: 3.253031\n","Train Epoch: 13 [12200/33600 (36%)]\tLoss: 2.688829\n","Train Epoch: 13 [12400/33600 (37%)]\tLoss: 2.159852\n","Train Epoch: 13 [12600/33600 (38%)]\tLoss: 1.479789\n","Train Epoch: 13 [12800/33600 (38%)]\tLoss: 2.001348\n","Train Epoch: 13 [13000/33600 (39%)]\tLoss: 2.065034\n","Train Epoch: 13 [13200/33600 (39%)]\tLoss: 1.911177\n","Train Epoch: 13 [13400/33600 (40%)]\tLoss: 1.912016\n","Train Epoch: 13 [13600/33600 (40%)]\tLoss: 2.575981\n","Train Epoch: 13 [13800/33600 (41%)]\tLoss: 2.661366\n","Train Epoch: 13 [14000/33600 (42%)]\tLoss: 1.934690\n","Train Epoch: 13 [14200/33600 (42%)]\tLoss: 2.327464\n","Train Epoch: 13 [14400/33600 (43%)]\tLoss: 1.820780\n","Train Epoch: 13 [14600/33600 (43%)]\tLoss: 2.140612\n","Train Epoch: 13 [14800/33600 (44%)]\tLoss: 2.259190\n","Train Epoch: 13 [15000/33600 (45%)]\tLoss: 1.698045\n","Train Epoch: 13 [15200/33600 (45%)]\tLoss: 2.421284\n","Train Epoch: 13 [15400/33600 (46%)]\tLoss: 2.849525\n","Train Epoch: 13 [15600/33600 (46%)]\tLoss: 1.901376\n","Train Epoch: 13 [15800/33600 (47%)]\tLoss: 2.870699\n","Train Epoch: 13 [16000/33600 (48%)]\tLoss: 1.490708\n","Train Epoch: 13 [16200/33600 (48%)]\tLoss: 1.555060\n","Train Epoch: 13 [16400/33600 (49%)]\tLoss: 2.516325\n","Train Epoch: 13 [16600/33600 (49%)]\tLoss: 1.616370\n","Train Epoch: 13 [16800/33600 (50%)]\tLoss: 2.804217\n","Train Epoch: 13 [17000/33600 (51%)]\tLoss: 1.551145\n","Train Epoch: 13 [17200/33600 (51%)]\tLoss: 2.161135\n","Train Epoch: 13 [17400/33600 (52%)]\tLoss: 1.471143\n","Train Epoch: 13 [17600/33600 (52%)]\tLoss: 2.261104\n","Train Epoch: 13 [17800/33600 (53%)]\tLoss: 2.175512\n","Train Epoch: 13 [18000/33600 (54%)]\tLoss: 1.714864\n","Train Epoch: 13 [18200/33600 (54%)]\tLoss: 2.460917\n","Train Epoch: 13 [18400/33600 (55%)]\tLoss: 2.812082\n","Train Epoch: 13 [18600/33600 (55%)]\tLoss: 2.324171\n","Train Epoch: 13 [18800/33600 (56%)]\tLoss: 1.536084\n","Train Epoch: 13 [19000/33600 (57%)]\tLoss: 2.365002\n","Train Epoch: 13 [19200/33600 (57%)]\tLoss: 1.611319\n","Train Epoch: 13 [19400/33600 (58%)]\tLoss: 1.924921\n","Train Epoch: 13 [19600/33600 (58%)]\tLoss: 1.740238\n","Train Epoch: 13 [19800/33600 (59%)]\tLoss: 2.034177\n","Train Epoch: 13 [20000/33600 (60%)]\tLoss: 2.530228\n","Train Epoch: 13 [20200/33600 (60%)]\tLoss: 1.894356\n","Train Epoch: 13 [20400/33600 (61%)]\tLoss: 1.718165\n","Train Epoch: 13 [20600/33600 (61%)]\tLoss: 2.060025\n","Train Epoch: 13 [20800/33600 (62%)]\tLoss: 2.893403\n","Train Epoch: 13 [21000/33600 (62%)]\tLoss: 1.779687\n","Train Epoch: 13 [21200/33600 (63%)]\tLoss: 2.457632\n","Train Epoch: 13 [21400/33600 (64%)]\tLoss: 2.735748\n","Train Epoch: 13 [21600/33600 (64%)]\tLoss: 2.264380\n","Train Epoch: 13 [21800/33600 (65%)]\tLoss: 2.661788\n","Train Epoch: 13 [22000/33600 (65%)]\tLoss: 3.078529\n","Train Epoch: 13 [22200/33600 (66%)]\tLoss: 2.082048\n","Train Epoch: 13 [22400/33600 (67%)]\tLoss: 2.503432\n","Train Epoch: 13 [22600/33600 (67%)]\tLoss: 2.391985\n","Train Epoch: 13 [22800/33600 (68%)]\tLoss: 1.844586\n","Train Epoch: 13 [23000/33600 (68%)]\tLoss: 1.971001\n","Train Epoch: 13 [23200/33600 (69%)]\tLoss: 2.605783\n","Train Epoch: 13 [23400/33600 (70%)]\tLoss: 2.950482\n","Train Epoch: 13 [23600/33600 (70%)]\tLoss: 2.088588\n","Train Epoch: 13 [23800/33600 (71%)]\tLoss: 2.649452\n","Train Epoch: 13 [24000/33600 (71%)]\tLoss: 2.759898\n","Train Epoch: 13 [24200/33600 (72%)]\tLoss: 1.624074\n","Train Epoch: 13 [24400/33600 (73%)]\tLoss: 1.650466\n","Train Epoch: 13 [24600/33600 (73%)]\tLoss: 2.782708\n","Train Epoch: 13 [24800/33600 (74%)]\tLoss: 1.673922\n","Train Epoch: 13 [25000/33600 (74%)]\tLoss: 2.725102\n","Train Epoch: 13 [25200/33600 (75%)]\tLoss: 2.663363\n","Train Epoch: 13 [25400/33600 (76%)]\tLoss: 3.273530\n","Train Epoch: 13 [25600/33600 (76%)]\tLoss: 2.394973\n","Train Epoch: 13 [25800/33600 (77%)]\tLoss: 2.016428\n","Train Epoch: 13 [26000/33600 (77%)]\tLoss: 1.413136\n","Train Epoch: 13 [26200/33600 (78%)]\tLoss: 1.653156\n","Train Epoch: 13 [26400/33600 (79%)]\tLoss: 2.298818\n","Train Epoch: 13 [26600/33600 (79%)]\tLoss: 2.087803\n","Train Epoch: 13 [26800/33600 (80%)]\tLoss: 1.628846\n","Train Epoch: 13 [27000/33600 (80%)]\tLoss: 2.031178\n","Train Epoch: 13 [27200/33600 (81%)]\tLoss: 1.572713\n","Train Epoch: 13 [27400/33600 (82%)]\tLoss: 2.798756\n","Train Epoch: 13 [27600/33600 (82%)]\tLoss: 2.012034\n","Train Epoch: 13 [27800/33600 (83%)]\tLoss: 1.997464\n","Train Epoch: 13 [28000/33600 (83%)]\tLoss: 2.949673\n","Train Epoch: 13 [28200/33600 (84%)]\tLoss: 2.022846\n","Train Epoch: 13 [28400/33600 (85%)]\tLoss: 1.588694\n","Train Epoch: 13 [28600/33600 (85%)]\tLoss: 2.193552\n","Train Epoch: 13 [28800/33600 (86%)]\tLoss: 2.248448\n","Train Epoch: 13 [29000/33600 (86%)]\tLoss: 1.940307\n","Train Epoch: 13 [29200/33600 (87%)]\tLoss: 2.092148\n","Train Epoch: 13 [29400/33600 (88%)]\tLoss: 2.294374\n","Train Epoch: 13 [29600/33600 (88%)]\tLoss: 2.138503\n","Train Epoch: 13 [29800/33600 (89%)]\tLoss: 1.909785\n","Train Epoch: 13 [30000/33600 (89%)]\tLoss: 2.509300\n","Train Epoch: 13 [30200/33600 (90%)]\tLoss: 1.611699\n","Train Epoch: 13 [30400/33600 (90%)]\tLoss: 2.054410\n","Train Epoch: 13 [30600/33600 (91%)]\tLoss: 2.806853\n","Train Epoch: 13 [30800/33600 (92%)]\tLoss: 2.432317\n","Train Epoch: 13 [31000/33600 (92%)]\tLoss: 1.616719\n","Train Epoch: 13 [31200/33600 (93%)]\tLoss: 2.416658\n","Train Epoch: 13 [31400/33600 (93%)]\tLoss: 2.311482\n","Train Epoch: 13 [31600/33600 (94%)]\tLoss: 2.129330\n","Train Epoch: 13 [31800/33600 (95%)]\tLoss: 2.067851\n","Train Epoch: 13 [32000/33600 (95%)]\tLoss: 1.902319\n","Train Epoch: 13 [32200/33600 (96%)]\tLoss: 2.198806\n","Train Epoch: 13 [32400/33600 (96%)]\tLoss: 2.421813\n","Train Epoch: 13 [32600/33600 (97%)]\tLoss: 2.062270\n","Train Epoch: 13 [32800/33600 (98%)]\tLoss: 1.788003\n","Train Epoch: 13 [33000/33600 (98%)]\tLoss: 2.836962\n","Train Epoch: 13 [33200/33600 (99%)]\tLoss: 1.903272\n","Train Epoch: 13 [33400/33600 (99%)]\tLoss: 2.107806\n","Train Epoch: 13 [33600/33600 (100%)]\tLoss: 2.607432\n","\n","Validation - Average Loss: 2.0295, Accuracy: 35.738%\n","\n","Train Epoch: 14 [200/33600 (1%)]\tLoss: 2.428865\n","Train Epoch: 14 [400/33600 (1%)]\tLoss: 1.764968\n","Train Epoch: 14 [600/33600 (2%)]\tLoss: 3.012344\n","Train Epoch: 14 [800/33600 (2%)]\tLoss: 3.133777\n","Train Epoch: 14 [1000/33600 (3%)]\tLoss: 2.094212\n","Train Epoch: 14 [1200/33600 (4%)]\tLoss: 1.866929\n","Train Epoch: 14 [1400/33600 (4%)]\tLoss: 2.066122\n","Train Epoch: 14 [1600/33600 (5%)]\tLoss: 2.486392\n","Train Epoch: 14 [1800/33600 (5%)]\tLoss: 1.595792\n","Train Epoch: 14 [2000/33600 (6%)]\tLoss: 1.748044\n","Train Epoch: 14 [2200/33600 (7%)]\tLoss: 1.583216\n","Train Epoch: 14 [2400/33600 (7%)]\tLoss: 1.920704\n","Train Epoch: 14 [2600/33600 (8%)]\tLoss: 1.979069\n","Train Epoch: 14 [2800/33600 (8%)]\tLoss: 2.398417\n","Train Epoch: 14 [3000/33600 (9%)]\tLoss: 2.272018\n","Train Epoch: 14 [3200/33600 (10%)]\tLoss: 2.097497\n","Train Epoch: 14 [3400/33600 (10%)]\tLoss: 1.917232\n","Train Epoch: 14 [3600/33600 (11%)]\tLoss: 2.169106\n","Train Epoch: 14 [3800/33600 (11%)]\tLoss: 1.987828\n","Train Epoch: 14 [4000/33600 (12%)]\tLoss: 1.953876\n","Train Epoch: 14 [4200/33600 (12%)]\tLoss: 1.840957\n","Train Epoch: 14 [4400/33600 (13%)]\tLoss: 2.156534\n","Train Epoch: 14 [4600/33600 (14%)]\tLoss: 1.819848\n","Train Epoch: 14 [4800/33600 (14%)]\tLoss: 1.916287\n","Train Epoch: 14 [5000/33600 (15%)]\tLoss: 1.769832\n","Train Epoch: 14 [5200/33600 (15%)]\tLoss: 2.240371\n","Train Epoch: 14 [5400/33600 (16%)]\tLoss: 2.036139\n","Train Epoch: 14 [5600/33600 (17%)]\tLoss: 2.214027\n","Train Epoch: 14 [5800/33600 (17%)]\tLoss: 1.639363\n","Train Epoch: 14 [6000/33600 (18%)]\tLoss: 2.486408\n","Train Epoch: 14 [6200/33600 (18%)]\tLoss: 2.625641\n","Train Epoch: 14 [6400/33600 (19%)]\tLoss: 1.534166\n","Train Epoch: 14 [6600/33600 (20%)]\tLoss: 2.015341\n","Train Epoch: 14 [6800/33600 (20%)]\tLoss: 2.140126\n","Train Epoch: 14 [7000/33600 (21%)]\tLoss: 2.690384\n","Train Epoch: 14 [7200/33600 (21%)]\tLoss: 2.652782\n","Train Epoch: 14 [7400/33600 (22%)]\tLoss: 1.737824\n","Train Epoch: 14 [7600/33600 (23%)]\tLoss: 3.263393\n","Train Epoch: 14 [7800/33600 (23%)]\tLoss: 2.376735\n","Train Epoch: 14 [8000/33600 (24%)]\tLoss: 2.479405\n","Train Epoch: 14 [8200/33600 (24%)]\tLoss: 2.053906\n","Train Epoch: 14 [8400/33600 (25%)]\tLoss: 3.175010\n","Train Epoch: 14 [8600/33600 (26%)]\tLoss: 2.215930\n","Train Epoch: 14 [8800/33600 (26%)]\tLoss: 2.414907\n","Train Epoch: 14 [9000/33600 (27%)]\tLoss: 3.047823\n","Train Epoch: 14 [9200/33600 (27%)]\tLoss: 1.987955\n","Train Epoch: 14 [9400/33600 (28%)]\tLoss: 2.921409\n","Train Epoch: 14 [9600/33600 (29%)]\tLoss: 2.207293\n","Train Epoch: 14 [9800/33600 (29%)]\tLoss: 2.151194\n","Train Epoch: 14 [10000/33600 (30%)]\tLoss: 2.082340\n","Train Epoch: 14 [10200/33600 (30%)]\tLoss: 1.786526\n","Train Epoch: 14 [10400/33600 (31%)]\tLoss: 2.324587\n","Train Epoch: 14 [10600/33600 (32%)]\tLoss: 1.939417\n","Train Epoch: 14 [10800/33600 (32%)]\tLoss: 2.052346\n","Train Epoch: 14 [11000/33600 (33%)]\tLoss: 2.008874\n","Train Epoch: 14 [11200/33600 (33%)]\tLoss: 2.669069\n","Train Epoch: 14 [11400/33600 (34%)]\tLoss: 1.796128\n","Train Epoch: 14 [11600/33600 (35%)]\tLoss: 2.063505\n","Train Epoch: 14 [11800/33600 (35%)]\tLoss: 1.636909\n","Train Epoch: 14 [12000/33600 (36%)]\tLoss: 2.072703\n","Train Epoch: 14 [12200/33600 (36%)]\tLoss: 2.251842\n","Train Epoch: 14 [12400/33600 (37%)]\tLoss: 2.391221\n","Train Epoch: 14 [12600/33600 (38%)]\tLoss: 3.261919\n","Train Epoch: 14 [12800/33600 (38%)]\tLoss: 2.747827\n","Train Epoch: 14 [13000/33600 (39%)]\tLoss: 2.640930\n","Train Epoch: 14 [13200/33600 (39%)]\tLoss: 2.240418\n","Train Epoch: 14 [13400/33600 (40%)]\tLoss: 2.596011\n","Train Epoch: 14 [13600/33600 (40%)]\tLoss: 2.093803\n","Train Epoch: 14 [13800/33600 (41%)]\tLoss: 2.354075\n","Train Epoch: 14 [14000/33600 (42%)]\tLoss: 1.985097\n","Train Epoch: 14 [14200/33600 (42%)]\tLoss: 1.938388\n","Train Epoch: 14 [14400/33600 (43%)]\tLoss: 2.515221\n","Train Epoch: 14 [14600/33600 (43%)]\tLoss: 2.463438\n","Train Epoch: 14 [14800/33600 (44%)]\tLoss: 2.583688\n","Train Epoch: 14 [15000/33600 (45%)]\tLoss: 1.979105\n","Train Epoch: 14 [15200/33600 (45%)]\tLoss: 1.830226\n","Train Epoch: 14 [15400/33600 (46%)]\tLoss: 1.824343\n","Train Epoch: 14 [15600/33600 (46%)]\tLoss: 1.992792\n","Train Epoch: 14 [15800/33600 (47%)]\tLoss: 2.285648\n","Train Epoch: 14 [16000/33600 (48%)]\tLoss: 2.384774\n","Train Epoch: 14 [16200/33600 (48%)]\tLoss: 2.939119\n","Train Epoch: 14 [16400/33600 (49%)]\tLoss: 2.109585\n","Train Epoch: 14 [16600/33600 (49%)]\tLoss: 2.303273\n","Train Epoch: 14 [16800/33600 (50%)]\tLoss: 2.320174\n","Train Epoch: 14 [17000/33600 (51%)]\tLoss: 2.412069\n","Train Epoch: 14 [17200/33600 (51%)]\tLoss: 1.990431\n","Train Epoch: 14 [17400/33600 (52%)]\tLoss: 2.832713\n","Train Epoch: 14 [17600/33600 (52%)]\tLoss: 2.392642\n","Train Epoch: 14 [17800/33600 (53%)]\tLoss: 1.783796\n","Train Epoch: 14 [18000/33600 (54%)]\tLoss: 2.903286\n","Train Epoch: 14 [18200/33600 (54%)]\tLoss: 1.442959\n","Train Epoch: 14 [18400/33600 (55%)]\tLoss: 2.284939\n","Train Epoch: 14 [18600/33600 (55%)]\tLoss: 2.166679\n","Train Epoch: 14 [18800/33600 (56%)]\tLoss: 1.651719\n","Train Epoch: 14 [19000/33600 (57%)]\tLoss: 1.718229\n","Train Epoch: 14 [19200/33600 (57%)]\tLoss: 1.931022\n","Train Epoch: 14 [19400/33600 (58%)]\tLoss: 2.678344\n","Train Epoch: 14 [19600/33600 (58%)]\tLoss: 1.978947\n","Train Epoch: 14 [19800/33600 (59%)]\tLoss: 2.339375\n","Train Epoch: 14 [20000/33600 (60%)]\tLoss: 2.423689\n","Train Epoch: 14 [20200/33600 (60%)]\tLoss: 2.000652\n","Train Epoch: 14 [20400/33600 (61%)]\tLoss: 1.903206\n","Train Epoch: 14 [20600/33600 (61%)]\tLoss: 2.304629\n","Train Epoch: 14 [20800/33600 (62%)]\tLoss: 1.732289\n","Train Epoch: 14 [21000/33600 (62%)]\tLoss: 1.351452\n","Train Epoch: 14 [21200/33600 (63%)]\tLoss: 2.941052\n","Train Epoch: 14 [21400/33600 (64%)]\tLoss: 1.815658\n","Train Epoch: 14 [21600/33600 (64%)]\tLoss: 1.819989\n","Train Epoch: 14 [21800/33600 (65%)]\tLoss: 1.807336\n","Train Epoch: 14 [22000/33600 (65%)]\tLoss: 2.441603\n","Train Epoch: 14 [22200/33600 (66%)]\tLoss: 2.705313\n","Train Epoch: 14 [22400/33600 (67%)]\tLoss: 2.518951\n","Train Epoch: 14 [22600/33600 (67%)]\tLoss: 1.968051\n","Train Epoch: 14 [22800/33600 (68%)]\tLoss: 2.859579\n","Train Epoch: 14 [23000/33600 (68%)]\tLoss: 1.412018\n","Train Epoch: 14 [23200/33600 (69%)]\tLoss: 2.769768\n","Train Epoch: 14 [23400/33600 (70%)]\tLoss: 2.487288\n","Train Epoch: 14 [23600/33600 (70%)]\tLoss: 2.701739\n","Train Epoch: 14 [23800/33600 (71%)]\tLoss: 2.356469\n","Train Epoch: 14 [24000/33600 (71%)]\tLoss: 2.165110\n","Train Epoch: 14 [24200/33600 (72%)]\tLoss: 2.127032\n","Train Epoch: 14 [24400/33600 (73%)]\tLoss: 2.689378\n","Train Epoch: 14 [24600/33600 (73%)]\tLoss: 1.545980\n","Train Epoch: 14 [24800/33600 (74%)]\tLoss: 1.711125\n","Train Epoch: 14 [25000/33600 (74%)]\tLoss: 2.551569\n","Train Epoch: 14 [25200/33600 (75%)]\tLoss: 1.507993\n","Train Epoch: 14 [25400/33600 (76%)]\tLoss: 2.255898\n","Train Epoch: 14 [25600/33600 (76%)]\tLoss: 2.192010\n","Train Epoch: 14 [25800/33600 (77%)]\tLoss: 1.379963\n","Train Epoch: 14 [26000/33600 (77%)]\tLoss: 2.115463\n","Train Epoch: 14 [26200/33600 (78%)]\tLoss: 1.551209\n","Train Epoch: 14 [26400/33600 (79%)]\tLoss: 1.692946\n","Train Epoch: 14 [26600/33600 (79%)]\tLoss: 2.269981\n","Train Epoch: 14 [26800/33600 (80%)]\tLoss: 1.492587\n","Train Epoch: 14 [27000/33600 (80%)]\tLoss: 2.181704\n","Train Epoch: 14 [27200/33600 (81%)]\tLoss: 2.752776\n","Train Epoch: 14 [27400/33600 (82%)]\tLoss: 1.867640\n","Train Epoch: 14 [27600/33600 (82%)]\tLoss: 3.105630\n","Train Epoch: 14 [27800/33600 (83%)]\tLoss: 1.892107\n","Train Epoch: 14 [28000/33600 (83%)]\tLoss: 2.138158\n","Train Epoch: 14 [28200/33600 (84%)]\tLoss: 2.291589\n","Train Epoch: 14 [28400/33600 (85%)]\tLoss: 3.243719\n","Train Epoch: 14 [28600/33600 (85%)]\tLoss: 2.263734\n","Train Epoch: 14 [28800/33600 (86%)]\tLoss: 1.690782\n","Train Epoch: 14 [29000/33600 (86%)]\tLoss: 2.406669\n","Train Epoch: 14 [29200/33600 (87%)]\tLoss: 2.636019\n","Train Epoch: 14 [29400/33600 (88%)]\tLoss: 2.237063\n","Train Epoch: 14 [29600/33600 (88%)]\tLoss: 3.057073\n","Train Epoch: 14 [29800/33600 (89%)]\tLoss: 2.289041\n","Train Epoch: 14 [30000/33600 (89%)]\tLoss: 2.051140\n","Train Epoch: 14 [30200/33600 (90%)]\tLoss: 1.557249\n","Train Epoch: 14 [30400/33600 (90%)]\tLoss: 2.235948\n","Train Epoch: 14 [30600/33600 (91%)]\tLoss: 1.924573\n","Train Epoch: 14 [30800/33600 (92%)]\tLoss: 1.513033\n","Train Epoch: 14 [31000/33600 (92%)]\tLoss: 1.536708\n","Train Epoch: 14 [31200/33600 (93%)]\tLoss: 1.664143\n","Train Epoch: 14 [31400/33600 (93%)]\tLoss: 2.312852\n","Train Epoch: 14 [31600/33600 (94%)]\tLoss: 2.212684\n","Train Epoch: 14 [31800/33600 (95%)]\tLoss: 2.237342\n","Train Epoch: 14 [32000/33600 (95%)]\tLoss: 1.897100\n","Train Epoch: 14 [32200/33600 (96%)]\tLoss: 1.638198\n","Train Epoch: 14 [32400/33600 (96%)]\tLoss: 2.210658\n","Train Epoch: 14 [32600/33600 (97%)]\tLoss: 2.314907\n","Train Epoch: 14 [32800/33600 (98%)]\tLoss: 2.339363\n","Train Epoch: 14 [33000/33600 (98%)]\tLoss: 2.406992\n","Train Epoch: 14 [33200/33600 (99%)]\tLoss: 1.460375\n","Train Epoch: 14 [33400/33600 (99%)]\tLoss: 2.191799\n","Train Epoch: 14 [33600/33600 (100%)]\tLoss: 1.548252\n","\n","Validation - Average Loss: 1.8917, Accuracy: 42.536%\n","\n","Train Epoch: 15 [200/33600 (1%)]\tLoss: 2.188073\n","Train Epoch: 15 [400/33600 (1%)]\tLoss: 1.918232\n","Train Epoch: 15 [600/33600 (2%)]\tLoss: 2.136964\n","Train Epoch: 15 [800/33600 (2%)]\tLoss: 2.472776\n","Train Epoch: 15 [1000/33600 (3%)]\tLoss: 2.378853\n","Train Epoch: 15 [1200/33600 (4%)]\tLoss: 2.077216\n","Train Epoch: 15 [1400/33600 (4%)]\tLoss: 2.415562\n","Train Epoch: 15 [1600/33600 (5%)]\tLoss: 1.535824\n","Train Epoch: 15 [1800/33600 (5%)]\tLoss: 2.482775\n","Train Epoch: 15 [2000/33600 (6%)]\tLoss: 1.497810\n","Train Epoch: 15 [2200/33600 (7%)]\tLoss: 1.306166\n","Train Epoch: 15 [2400/33600 (7%)]\tLoss: 2.029993\n","Train Epoch: 15 [2600/33600 (8%)]\tLoss: 1.918837\n","Train Epoch: 15 [2800/33600 (8%)]\tLoss: 2.562467\n","Train Epoch: 15 [3000/33600 (9%)]\tLoss: 2.118916\n","Train Epoch: 15 [3200/33600 (10%)]\tLoss: 1.869018\n","Train Epoch: 15 [3400/33600 (10%)]\tLoss: 1.562665\n","Train Epoch: 15 [3600/33600 (11%)]\tLoss: 2.323784\n","Train Epoch: 15 [3800/33600 (11%)]\tLoss: 1.880044\n","Train Epoch: 15 [4000/33600 (12%)]\tLoss: 1.703456\n","Train Epoch: 15 [4200/33600 (12%)]\tLoss: 2.069064\n","Train Epoch: 15 [4400/33600 (13%)]\tLoss: 2.121253\n","Train Epoch: 15 [4600/33600 (14%)]\tLoss: 1.121747\n","Train Epoch: 15 [4800/33600 (14%)]\tLoss: 1.625001\n","Train Epoch: 15 [5000/33600 (15%)]\tLoss: 1.847146\n","Train Epoch: 15 [5200/33600 (15%)]\tLoss: 2.058331\n","Train Epoch: 15 [5400/33600 (16%)]\tLoss: 2.278807\n","Train Epoch: 15 [5600/33600 (17%)]\tLoss: 1.951339\n","Train Epoch: 15 [5800/33600 (17%)]\tLoss: 2.387562\n","Train Epoch: 15 [6000/33600 (18%)]\tLoss: 1.739953\n","Train Epoch: 15 [6200/33600 (18%)]\tLoss: 1.909177\n","Train Epoch: 15 [6400/33600 (19%)]\tLoss: 2.233217\n","Train Epoch: 15 [6600/33600 (20%)]\tLoss: 1.739452\n","Train Epoch: 15 [6800/33600 (20%)]\tLoss: 1.821383\n","Train Epoch: 15 [7000/33600 (21%)]\tLoss: 2.105134\n","Train Epoch: 15 [7200/33600 (21%)]\tLoss: 2.080414\n","Train Epoch: 15 [7400/33600 (22%)]\tLoss: 2.043348\n","Train Epoch: 15 [7600/33600 (23%)]\tLoss: 2.220586\n","Train Epoch: 15 [7800/33600 (23%)]\tLoss: 2.093316\n","Train Epoch: 15 [8000/33600 (24%)]\tLoss: 1.895296\n","Train Epoch: 15 [8200/33600 (24%)]\tLoss: 1.723106\n","Train Epoch: 15 [8400/33600 (25%)]\tLoss: 1.937669\n","Train Epoch: 15 [8600/33600 (26%)]\tLoss: 2.004817\n","Train Epoch: 15 [8800/33600 (26%)]\tLoss: 1.911388\n","Train Epoch: 15 [9000/33600 (27%)]\tLoss: 1.876422\n","Train Epoch: 15 [9200/33600 (27%)]\tLoss: 2.177678\n","Train Epoch: 15 [9400/33600 (28%)]\tLoss: 1.206789\n","Train Epoch: 15 [9600/33600 (29%)]\tLoss: 1.657091\n","Train Epoch: 15 [9800/33600 (29%)]\tLoss: 1.719406\n","Train Epoch: 15 [10000/33600 (30%)]\tLoss: 1.778083\n","Train Epoch: 15 [10200/33600 (30%)]\tLoss: 2.067504\n","Train Epoch: 15 [10400/33600 (31%)]\tLoss: 2.334199\n","Train Epoch: 15 [10600/33600 (32%)]\tLoss: 1.855729\n","Train Epoch: 15 [10800/33600 (32%)]\tLoss: 2.347641\n","Train Epoch: 15 [11000/33600 (33%)]\tLoss: 2.138368\n","Train Epoch: 15 [11200/33600 (33%)]\tLoss: 2.524216\n","Train Epoch: 15 [11400/33600 (34%)]\tLoss: 2.171341\n","Train Epoch: 15 [11600/33600 (35%)]\tLoss: 2.101228\n","Train Epoch: 15 [11800/33600 (35%)]\tLoss: 1.644186\n","Train Epoch: 15 [12000/33600 (36%)]\tLoss: 1.488734\n","Train Epoch: 15 [12200/33600 (36%)]\tLoss: 1.780058\n","Train Epoch: 15 [12400/33600 (37%)]\tLoss: 1.563040\n","Train Epoch: 15 [12600/33600 (38%)]\tLoss: 2.385576\n","Train Epoch: 15 [12800/33600 (38%)]\tLoss: 2.485536\n","Train Epoch: 15 [13000/33600 (39%)]\tLoss: 1.699431\n","Train Epoch: 15 [13200/33600 (39%)]\tLoss: 2.148161\n","Train Epoch: 15 [13400/33600 (40%)]\tLoss: 3.039264\n","Train Epoch: 15 [13600/33600 (40%)]\tLoss: 2.008826\n","Train Epoch: 15 [13800/33600 (41%)]\tLoss: 2.485517\n","Train Epoch: 15 [14000/33600 (42%)]\tLoss: 2.327423\n","Train Epoch: 15 [14200/33600 (42%)]\tLoss: 1.988196\n","Train Epoch: 15 [14400/33600 (43%)]\tLoss: 1.460173\n","Train Epoch: 15 [14600/33600 (43%)]\tLoss: 2.479174\n","Train Epoch: 15 [14800/33600 (44%)]\tLoss: 2.098303\n","Train Epoch: 15 [15000/33600 (45%)]\tLoss: 1.638863\n","Train Epoch: 15 [15200/33600 (45%)]\tLoss: 2.462397\n","Train Epoch: 15 [15400/33600 (46%)]\tLoss: 2.116580\n","Train Epoch: 15 [15600/33600 (46%)]\tLoss: 1.823800\n","Train Epoch: 15 [15800/33600 (47%)]\tLoss: 1.882212\n","Train Epoch: 15 [16000/33600 (48%)]\tLoss: 2.951779\n","Train Epoch: 15 [16200/33600 (48%)]\tLoss: 2.200018\n","Train Epoch: 15 [16400/33600 (49%)]\tLoss: 2.454345\n","Train Epoch: 15 [16600/33600 (49%)]\tLoss: 1.172332\n","Train Epoch: 15 [16800/33600 (50%)]\tLoss: 1.768729\n","Train Epoch: 15 [17000/33600 (51%)]\tLoss: 2.027624\n","Train Epoch: 15 [17200/33600 (51%)]\tLoss: 1.996169\n","Train Epoch: 15 [17400/33600 (52%)]\tLoss: 2.518391\n","Train Epoch: 15 [17600/33600 (52%)]\tLoss: 2.589895\n","Train Epoch: 15 [17800/33600 (53%)]\tLoss: 1.753542\n","Train Epoch: 15 [18000/33600 (54%)]\tLoss: 1.704944\n","Train Epoch: 15 [18200/33600 (54%)]\tLoss: 1.968885\n","Train Epoch: 15 [18400/33600 (55%)]\tLoss: 2.242773\n","Train Epoch: 15 [18600/33600 (55%)]\tLoss: 1.420555\n","Train Epoch: 15 [18800/33600 (56%)]\tLoss: 1.733280\n","Train Epoch: 15 [19000/33600 (57%)]\tLoss: 1.824577\n","Train Epoch: 15 [19200/33600 (57%)]\tLoss: 1.681581\n","Train Epoch: 15 [19400/33600 (58%)]\tLoss: 2.035646\n","Train Epoch: 15 [19600/33600 (58%)]\tLoss: 1.725493\n","Train Epoch: 15 [19800/33600 (59%)]\tLoss: 1.816288\n","Train Epoch: 15 [20000/33600 (60%)]\tLoss: 2.108979\n","Train Epoch: 15 [20200/33600 (60%)]\tLoss: 2.259623\n","Train Epoch: 15 [20400/33600 (61%)]\tLoss: 2.147594\n","Train Epoch: 15 [20600/33600 (61%)]\tLoss: 1.795436\n","Train Epoch: 15 [20800/33600 (62%)]\tLoss: 2.466267\n","Train Epoch: 15 [21000/33600 (62%)]\tLoss: 1.693282\n","Train Epoch: 15 [21200/33600 (63%)]\tLoss: 2.166410\n","Train Epoch: 15 [21400/33600 (64%)]\tLoss: 1.950153\n","Train Epoch: 15 [21600/33600 (64%)]\tLoss: 2.306721\n","Train Epoch: 15 [21800/33600 (65%)]\tLoss: 2.347741\n","Train Epoch: 15 [22000/33600 (65%)]\tLoss: 2.218650\n","Train Epoch: 15 [22200/33600 (66%)]\tLoss: 2.495356\n","Train Epoch: 15 [22400/33600 (67%)]\tLoss: 2.869674\n","Train Epoch: 15 [22600/33600 (67%)]\tLoss: 1.568874\n","Train Epoch: 15 [22800/33600 (68%)]\tLoss: 2.262543\n","Train Epoch: 15 [23000/33600 (68%)]\tLoss: 1.984666\n","Train Epoch: 15 [23200/33600 (69%)]\tLoss: 1.773614\n","Train Epoch: 15 [23400/33600 (70%)]\tLoss: 1.523917\n","Train Epoch: 15 [23600/33600 (70%)]\tLoss: 2.723778\n","Train Epoch: 15 [23800/33600 (71%)]\tLoss: 2.588045\n","Train Epoch: 15 [24000/33600 (71%)]\tLoss: 2.133082\n","Train Epoch: 15 [24200/33600 (72%)]\tLoss: 1.875206\n","Train Epoch: 15 [24400/33600 (73%)]\tLoss: 1.631016\n","Train Epoch: 15 [24600/33600 (73%)]\tLoss: 1.559665\n","Train Epoch: 15 [24800/33600 (74%)]\tLoss: 2.096121\n","Train Epoch: 15 [25000/33600 (74%)]\tLoss: 1.777191\n","Train Epoch: 15 [25200/33600 (75%)]\tLoss: 2.035034\n","Train Epoch: 15 [25400/33600 (76%)]\tLoss: 1.725206\n","Train Epoch: 15 [25600/33600 (76%)]\tLoss: 2.272471\n","Train Epoch: 15 [25800/33600 (77%)]\tLoss: 1.635382\n","Train Epoch: 15 [26000/33600 (77%)]\tLoss: 2.250973\n","Train Epoch: 15 [26200/33600 (78%)]\tLoss: 1.529655\n","Train Epoch: 15 [26400/33600 (79%)]\tLoss: 1.775056\n","Train Epoch: 15 [26600/33600 (79%)]\tLoss: 1.652153\n","Train Epoch: 15 [26800/33600 (80%)]\tLoss: 2.760415\n","Train Epoch: 15 [27000/33600 (80%)]\tLoss: 2.624338\n","Train Epoch: 15 [27200/33600 (81%)]\tLoss: 2.119771\n","Train Epoch: 15 [27400/33600 (82%)]\tLoss: 1.632371\n","Train Epoch: 15 [27600/33600 (82%)]\tLoss: 2.049255\n","Train Epoch: 15 [27800/33600 (83%)]\tLoss: 1.569336\n","Train Epoch: 15 [28000/33600 (83%)]\tLoss: 2.360315\n","Train Epoch: 15 [28200/33600 (84%)]\tLoss: 2.010459\n","Train Epoch: 15 [28400/33600 (85%)]\tLoss: 1.323334\n","Train Epoch: 15 [28600/33600 (85%)]\tLoss: 2.247011\n","Train Epoch: 15 [28800/33600 (86%)]\tLoss: 1.866202\n","Train Epoch: 15 [29000/33600 (86%)]\tLoss: 2.670925\n","Train Epoch: 15 [29200/33600 (87%)]\tLoss: 1.436811\n","Train Epoch: 15 [29400/33600 (88%)]\tLoss: 2.690712\n","Train Epoch: 15 [29600/33600 (88%)]\tLoss: 1.644148\n","Train Epoch: 15 [29800/33600 (89%)]\tLoss: 2.498797\n","Train Epoch: 15 [30000/33600 (89%)]\tLoss: 2.101451\n","Train Epoch: 15 [30200/33600 (90%)]\tLoss: 2.104452\n","Train Epoch: 15 [30400/33600 (90%)]\tLoss: 1.833090\n","Train Epoch: 15 [30600/33600 (91%)]\tLoss: 2.167052\n","Train Epoch: 15 [30800/33600 (92%)]\tLoss: 1.530826\n","Train Epoch: 15 [31000/33600 (92%)]\tLoss: 1.496132\n","Train Epoch: 15 [31200/33600 (93%)]\tLoss: 2.418305\n","Train Epoch: 15 [31400/33600 (93%)]\tLoss: 1.738661\n","Train Epoch: 15 [31600/33600 (94%)]\tLoss: 2.291705\n","Train Epoch: 15 [31800/33600 (95%)]\tLoss: 3.118113\n","Train Epoch: 15 [32000/33600 (95%)]\tLoss: 2.144543\n","Train Epoch: 15 [32200/33600 (96%)]\tLoss: 1.722259\n","Train Epoch: 15 [32400/33600 (96%)]\tLoss: 2.398546\n","Train Epoch: 15 [32600/33600 (97%)]\tLoss: 1.965644\n","Train Epoch: 15 [32800/33600 (98%)]\tLoss: 1.820694\n","Train Epoch: 15 [33000/33600 (98%)]\tLoss: 1.483888\n","Train Epoch: 15 [33200/33600 (99%)]\tLoss: 2.271900\n","Train Epoch: 15 [33400/33600 (99%)]\tLoss: 2.037558\n","Train Epoch: 15 [33600/33600 (100%)]\tLoss: 1.667770\n","\n","Validation - Average Loss: 1.8801, Accuracy: 44.190%\n","\n","Train Epoch: 16 [200/33600 (1%)]\tLoss: 1.470269\n","Train Epoch: 16 [400/33600 (1%)]\tLoss: 1.428437\n","Train Epoch: 16 [600/33600 (2%)]\tLoss: 2.034584\n","Train Epoch: 16 [800/33600 (2%)]\tLoss: 1.417669\n","Train Epoch: 16 [1000/33600 (3%)]\tLoss: 1.554406\n","Train Epoch: 16 [1200/33600 (4%)]\tLoss: 2.051676\n","Train Epoch: 16 [1400/33600 (4%)]\tLoss: 2.329249\n","Train Epoch: 16 [1600/33600 (5%)]\tLoss: 3.052690\n","Train Epoch: 16 [1800/33600 (5%)]\tLoss: 1.893755\n","Train Epoch: 16 [2000/33600 (6%)]\tLoss: 2.318075\n","Train Epoch: 16 [2200/33600 (7%)]\tLoss: 2.206953\n","Train Epoch: 16 [2400/33600 (7%)]\tLoss: 2.658139\n","Train Epoch: 16 [2600/33600 (8%)]\tLoss: 1.566640\n","Train Epoch: 16 [2800/33600 (8%)]\tLoss: 1.815112\n","Train Epoch: 16 [3000/33600 (9%)]\tLoss: 1.507729\n","Train Epoch: 16 [3200/33600 (10%)]\tLoss: 1.885597\n","Train Epoch: 16 [3400/33600 (10%)]\tLoss: 1.632739\n","Train Epoch: 16 [3600/33600 (11%)]\tLoss: 1.956958\n","Train Epoch: 16 [3800/33600 (11%)]\tLoss: 1.713090\n","Train Epoch: 16 [4000/33600 (12%)]\tLoss: 2.328816\n","Train Epoch: 16 [4200/33600 (12%)]\tLoss: 2.371792\n","Train Epoch: 16 [4400/33600 (13%)]\tLoss: 1.487819\n","Train Epoch: 16 [4600/33600 (14%)]\tLoss: 2.086682\n","Train Epoch: 16 [4800/33600 (14%)]\tLoss: 2.674764\n","Train Epoch: 16 [5000/33600 (15%)]\tLoss: 2.810262\n","Train Epoch: 16 [5200/33600 (15%)]\tLoss: 1.477677\n","Train Epoch: 16 [5400/33600 (16%)]\tLoss: 1.427994\n","Train Epoch: 16 [5600/33600 (17%)]\tLoss: 1.839267\n","Train Epoch: 16 [5800/33600 (17%)]\tLoss: 1.490995\n","Train Epoch: 16 [6000/33600 (18%)]\tLoss: 2.194750\n","Train Epoch: 16 [6200/33600 (18%)]\tLoss: 2.039555\n","Train Epoch: 16 [6400/33600 (19%)]\tLoss: 2.178148\n","Train Epoch: 16 [6600/33600 (20%)]\tLoss: 1.396356\n","Train Epoch: 16 [6800/33600 (20%)]\tLoss: 1.656739\n","Train Epoch: 16 [7000/33600 (21%)]\tLoss: 1.896543\n","Train Epoch: 16 [7200/33600 (21%)]\tLoss: 2.091060\n","Train Epoch: 16 [7400/33600 (22%)]\tLoss: 1.546139\n","Train Epoch: 16 [7600/33600 (23%)]\tLoss: 1.584476\n","Train Epoch: 16 [7800/33600 (23%)]\tLoss: 2.335756\n","Train Epoch: 16 [8000/33600 (24%)]\tLoss: 3.173306\n","Train Epoch: 16 [8200/33600 (24%)]\tLoss: 3.496264\n","Train Epoch: 16 [8400/33600 (25%)]\tLoss: 2.080244\n","Train Epoch: 16 [8600/33600 (26%)]\tLoss: 1.797839\n","Train Epoch: 16 [8800/33600 (26%)]\tLoss: 2.946737\n","Train Epoch: 16 [9000/33600 (27%)]\tLoss: 2.361506\n","Train Epoch: 16 [9200/33600 (27%)]\tLoss: 1.860836\n","Train Epoch: 16 [9400/33600 (28%)]\tLoss: 2.224187\n","Train Epoch: 16 [9600/33600 (29%)]\tLoss: 2.336290\n","Train Epoch: 16 [9800/33600 (29%)]\tLoss: 1.709204\n","Train Epoch: 16 [10000/33600 (30%)]\tLoss: 1.823282\n","Train Epoch: 16 [10200/33600 (30%)]\tLoss: 1.718978\n","Train Epoch: 16 [10400/33600 (31%)]\tLoss: 2.199918\n","Train Epoch: 16 [10600/33600 (32%)]\tLoss: 1.912874\n","Train Epoch: 16 [10800/33600 (32%)]\tLoss: 2.016615\n","Train Epoch: 16 [11000/33600 (33%)]\tLoss: 2.724112\n","Train Epoch: 16 [11200/33600 (33%)]\tLoss: 2.343364\n","Train Epoch: 16 [11400/33600 (34%)]\tLoss: 1.568329\n","Train Epoch: 16 [11600/33600 (35%)]\tLoss: 1.951871\n","Train Epoch: 16 [11800/33600 (35%)]\tLoss: 1.477932\n","Train Epoch: 16 [12000/33600 (36%)]\tLoss: 1.995754\n","Train Epoch: 16 [12200/33600 (36%)]\tLoss: 2.183482\n","Train Epoch: 16 [12400/33600 (37%)]\tLoss: 1.945503\n","Train Epoch: 16 [12600/33600 (38%)]\tLoss: 2.426490\n","Train Epoch: 16 [12800/33600 (38%)]\tLoss: 2.343528\n","Train Epoch: 16 [13000/33600 (39%)]\tLoss: 1.783593\n","Train Epoch: 16 [13200/33600 (39%)]\tLoss: 2.142390\n","Train Epoch: 16 [13400/33600 (40%)]\tLoss: 2.369598\n","Train Epoch: 16 [13600/33600 (40%)]\tLoss: 2.380034\n","Train Epoch: 16 [13800/33600 (41%)]\tLoss: 2.022938\n","Train Epoch: 16 [14000/33600 (42%)]\tLoss: 2.214690\n","Train Epoch: 16 [14200/33600 (42%)]\tLoss: 1.534486\n","Train Epoch: 16 [14400/33600 (43%)]\tLoss: 1.864758\n","Train Epoch: 16 [14600/33600 (43%)]\tLoss: 2.345345\n","Train Epoch: 16 [14800/33600 (44%)]\tLoss: 2.684547\n","Train Epoch: 16 [15000/33600 (45%)]\tLoss: 3.235522\n","Train Epoch: 16 [15200/33600 (45%)]\tLoss: 1.577784\n","Train Epoch: 16 [15400/33600 (46%)]\tLoss: 1.816922\n","Train Epoch: 16 [15600/33600 (46%)]\tLoss: 1.844727\n","Train Epoch: 16 [15800/33600 (47%)]\tLoss: 2.623562\n","Train Epoch: 16 [16000/33600 (48%)]\tLoss: 1.752154\n","Train Epoch: 16 [16200/33600 (48%)]\tLoss: 1.771156\n","Train Epoch: 16 [16400/33600 (49%)]\tLoss: 2.443647\n","Train Epoch: 16 [16600/33600 (49%)]\tLoss: 2.307302\n","Train Epoch: 16 [16800/33600 (50%)]\tLoss: 2.205241\n","Train Epoch: 16 [17000/33600 (51%)]\tLoss: 2.242886\n","Train Epoch: 16 [17200/33600 (51%)]\tLoss: 1.718747\n","Train Epoch: 16 [17400/33600 (52%)]\tLoss: 2.002933\n","Train Epoch: 16 [17600/33600 (52%)]\tLoss: 1.939747\n","Train Epoch: 16 [17800/33600 (53%)]\tLoss: 1.917581\n","Train Epoch: 16 [18000/33600 (54%)]\tLoss: 1.944818\n","Train Epoch: 16 [18200/33600 (54%)]\tLoss: 2.380031\n","Train Epoch: 16 [18400/33600 (55%)]\tLoss: 2.373368\n","Train Epoch: 16 [18600/33600 (55%)]\tLoss: 1.548612\n","Train Epoch: 16 [18800/33600 (56%)]\tLoss: 1.698722\n","Train Epoch: 16 [19000/33600 (57%)]\tLoss: 1.915350\n","Train Epoch: 16 [19200/33600 (57%)]\tLoss: 2.101064\n","Train Epoch: 16 [19400/33600 (58%)]\tLoss: 2.148160\n","Train Epoch: 16 [19600/33600 (58%)]\tLoss: 1.998938\n","Train Epoch: 16 [19800/33600 (59%)]\tLoss: 1.822113\n","Train Epoch: 16 [20000/33600 (60%)]\tLoss: 2.219038\n","Train Epoch: 16 [20200/33600 (60%)]\tLoss: 2.299904\n","Train Epoch: 16 [20400/33600 (61%)]\tLoss: 1.989706\n","Train Epoch: 16 [20600/33600 (61%)]\tLoss: 2.599197\n","Train Epoch: 16 [20800/33600 (62%)]\tLoss: 1.862863\n","Train Epoch: 16 [21000/33600 (62%)]\tLoss: 2.426590\n","Train Epoch: 16 [21200/33600 (63%)]\tLoss: 1.529473\n","Train Epoch: 16 [21400/33600 (64%)]\tLoss: 1.933716\n","Train Epoch: 16 [21600/33600 (64%)]\tLoss: 2.006874\n","Train Epoch: 16 [21800/33600 (65%)]\tLoss: 1.344069\n","Train Epoch: 16 [22000/33600 (65%)]\tLoss: 1.668916\n","Train Epoch: 16 [22200/33600 (66%)]\tLoss: 1.757817\n","Train Epoch: 16 [22400/33600 (67%)]\tLoss: 2.078913\n","Train Epoch: 16 [22600/33600 (67%)]\tLoss: 2.193319\n","Train Epoch: 16 [22800/33600 (68%)]\tLoss: 2.114117\n","Train Epoch: 16 [23000/33600 (68%)]\tLoss: 2.834006\n","Train Epoch: 16 [23200/33600 (69%)]\tLoss: 2.244508\n","Train Epoch: 16 [23400/33600 (70%)]\tLoss: 2.093501\n","Train Epoch: 16 [23600/33600 (70%)]\tLoss: 2.260583\n","Train Epoch: 16 [23800/33600 (71%)]\tLoss: 2.451851\n","Train Epoch: 16 [24000/33600 (71%)]\tLoss: 1.346215\n","Train Epoch: 16 [24200/33600 (72%)]\tLoss: 2.156152\n","Train Epoch: 16 [24400/33600 (73%)]\tLoss: 1.632354\n","Train Epoch: 16 [24600/33600 (73%)]\tLoss: 1.898257\n","Train Epoch: 16 [24800/33600 (74%)]\tLoss: 2.447711\n","Train Epoch: 16 [25000/33600 (74%)]\tLoss: 2.665562\n","Train Epoch: 16 [25200/33600 (75%)]\tLoss: 2.069099\n","Train Epoch: 16 [25400/33600 (76%)]\tLoss: 1.446056\n","Train Epoch: 16 [25600/33600 (76%)]\tLoss: 2.200934\n","Train Epoch: 16 [25800/33600 (77%)]\tLoss: 1.858909\n","Train Epoch: 16 [26000/33600 (77%)]\tLoss: 1.558022\n","Train Epoch: 16 [26200/33600 (78%)]\tLoss: 2.409082\n","Train Epoch: 16 [26400/33600 (79%)]\tLoss: 2.106236\n","Train Epoch: 16 [26600/33600 (79%)]\tLoss: 2.045354\n","Train Epoch: 16 [26800/33600 (80%)]\tLoss: 2.044946\n","Train Epoch: 16 [27000/33600 (80%)]\tLoss: 2.201737\n","Train Epoch: 16 [27200/33600 (81%)]\tLoss: 2.061716\n","Train Epoch: 16 [27400/33600 (82%)]\tLoss: 1.417515\n","Train Epoch: 16 [27600/33600 (82%)]\tLoss: 3.055442\n","Train Epoch: 16 [27800/33600 (83%)]\tLoss: 2.084256\n","Train Epoch: 16 [28000/33600 (83%)]\tLoss: 2.088302\n","Train Epoch: 16 [28200/33600 (84%)]\tLoss: 2.177655\n","Train Epoch: 16 [28400/33600 (85%)]\tLoss: 1.789233\n","Train Epoch: 16 [28600/33600 (85%)]\tLoss: 2.232082\n","Train Epoch: 16 [28800/33600 (86%)]\tLoss: 2.104306\n","Train Epoch: 16 [29000/33600 (86%)]\tLoss: 1.879681\n","Train Epoch: 16 [29200/33600 (87%)]\tLoss: 1.980438\n","Train Epoch: 16 [29400/33600 (88%)]\tLoss: 1.932993\n","Train Epoch: 16 [29600/33600 (88%)]\tLoss: 2.108373\n","Train Epoch: 16 [29800/33600 (89%)]\tLoss: 2.311944\n","Train Epoch: 16 [30000/33600 (89%)]\tLoss: 2.001485\n","Train Epoch: 16 [30200/33600 (90%)]\tLoss: 2.397433\n","Train Epoch: 16 [30400/33600 (90%)]\tLoss: 1.881813\n","Train Epoch: 16 [30600/33600 (91%)]\tLoss: 2.207572\n","Train Epoch: 16 [30800/33600 (92%)]\tLoss: 1.925745\n","Train Epoch: 16 [31000/33600 (92%)]\tLoss: 1.425888\n","Train Epoch: 16 [31200/33600 (93%)]\tLoss: 1.967173\n","Train Epoch: 16 [31400/33600 (93%)]\tLoss: 2.862685\n","Train Epoch: 16 [31600/33600 (94%)]\tLoss: 2.683369\n","Train Epoch: 16 [31800/33600 (95%)]\tLoss: 2.166892\n","Train Epoch: 16 [32000/33600 (95%)]\tLoss: 2.230542\n","Train Epoch: 16 [32200/33600 (96%)]\tLoss: 1.205182\n","Train Epoch: 16 [32400/33600 (96%)]\tLoss: 1.860357\n","Train Epoch: 16 [32600/33600 (97%)]\tLoss: 1.712891\n","Train Epoch: 16 [32800/33600 (98%)]\tLoss: 1.725835\n","Train Epoch: 16 [33000/33600 (98%)]\tLoss: 2.015122\n","Train Epoch: 16 [33200/33600 (99%)]\tLoss: 1.507394\n","Train Epoch: 16 [33400/33600 (99%)]\tLoss: 2.362493\n","Train Epoch: 16 [33600/33600 (100%)]\tLoss: 1.779178\n","\n","Validation - Average Loss: 1.8964, Accuracy: 45.167%\n","\n","Train Epoch: 17 [200/33600 (1%)]\tLoss: 1.710413\n","Train Epoch: 17 [400/33600 (1%)]\tLoss: 2.702735\n","Train Epoch: 17 [600/33600 (2%)]\tLoss: 1.707494\n","Train Epoch: 17 [800/33600 (2%)]\tLoss: 2.126538\n","Train Epoch: 17 [1000/33600 (3%)]\tLoss: 2.699846\n","Train Epoch: 17 [1200/33600 (4%)]\tLoss: 2.303357\n","Train Epoch: 17 [1400/33600 (4%)]\tLoss: 2.273764\n","Train Epoch: 17 [1600/33600 (5%)]\tLoss: 2.274783\n","Train Epoch: 17 [1800/33600 (5%)]\tLoss: 2.357955\n","Train Epoch: 17 [2000/33600 (6%)]\tLoss: 1.705703\n","Train Epoch: 17 [2200/33600 (7%)]\tLoss: 1.654109\n","Train Epoch: 17 [2400/33600 (7%)]\tLoss: 2.421788\n","Train Epoch: 17 [2600/33600 (8%)]\tLoss: 2.238266\n","Train Epoch: 17 [2800/33600 (8%)]\tLoss: 1.754061\n","Train Epoch: 17 [3000/33600 (9%)]\tLoss: 1.571131\n","Train Epoch: 17 [3200/33600 (10%)]\tLoss: 2.083775\n","Train Epoch: 17 [3400/33600 (10%)]\tLoss: 2.486240\n","Train Epoch: 17 [3600/33600 (11%)]\tLoss: 1.990606\n","Train Epoch: 17 [3800/33600 (11%)]\tLoss: 2.184895\n","Train Epoch: 17 [4000/33600 (12%)]\tLoss: 2.217239\n","Train Epoch: 17 [4200/33600 (12%)]\tLoss: 2.847866\n","Train Epoch: 17 [4400/33600 (13%)]\tLoss: 1.770210\n","Train Epoch: 17 [4600/33600 (14%)]\tLoss: 1.981412\n","Train Epoch: 17 [4800/33600 (14%)]\tLoss: 2.834946\n","Train Epoch: 17 [5000/33600 (15%)]\tLoss: 1.891022\n","Train Epoch: 17 [5200/33600 (15%)]\tLoss: 1.875143\n","Train Epoch: 17 [5400/33600 (16%)]\tLoss: 2.243813\n","Train Epoch: 17 [5600/33600 (17%)]\tLoss: 1.934498\n","Train Epoch: 17 [5800/33600 (17%)]\tLoss: 1.980582\n","Train Epoch: 17 [6000/33600 (18%)]\tLoss: 3.101911\n","Train Epoch: 17 [6200/33600 (18%)]\tLoss: 1.977505\n","Train Epoch: 17 [6400/33600 (19%)]\tLoss: 1.914396\n","Train Epoch: 17 [6600/33600 (20%)]\tLoss: 2.012994\n","Train Epoch: 17 [6800/33600 (20%)]\tLoss: 1.984839\n","Train Epoch: 17 [7000/33600 (21%)]\tLoss: 1.339825\n","Train Epoch: 17 [7200/33600 (21%)]\tLoss: 2.199542\n","Train Epoch: 17 [7400/33600 (22%)]\tLoss: 1.863941\n","Train Epoch: 17 [7600/33600 (23%)]\tLoss: 1.929983\n","Train Epoch: 17 [7800/33600 (23%)]\tLoss: 1.912941\n","Train Epoch: 17 [8000/33600 (24%)]\tLoss: 1.841617\n","Train Epoch: 17 [8200/33600 (24%)]\tLoss: 2.255691\n","Train Epoch: 17 [8400/33600 (25%)]\tLoss: 1.468743\n","Train Epoch: 17 [8600/33600 (26%)]\tLoss: 2.094286\n","Train Epoch: 17 [8800/33600 (26%)]\tLoss: 1.835850\n","Train Epoch: 17 [9000/33600 (27%)]\tLoss: 2.006265\n","Train Epoch: 17 [9200/33600 (27%)]\tLoss: 1.912796\n","Train Epoch: 17 [9400/33600 (28%)]\tLoss: 2.215666\n","Train Epoch: 17 [9600/33600 (29%)]\tLoss: 2.264160\n","Train Epoch: 17 [9800/33600 (29%)]\tLoss: 2.234661\n","Train Epoch: 17 [10000/33600 (30%)]\tLoss: 2.036108\n","Train Epoch: 17 [10200/33600 (30%)]\tLoss: 1.681965\n","Train Epoch: 17 [10400/33600 (31%)]\tLoss: 2.086912\n","Train Epoch: 17 [10600/33600 (32%)]\tLoss: 1.773256\n","Train Epoch: 17 [10800/33600 (32%)]\tLoss: 1.579340\n","Train Epoch: 17 [11000/33600 (33%)]\tLoss: 1.993535\n","Train Epoch: 17 [11200/33600 (33%)]\tLoss: 3.389870\n","Train Epoch: 17 [11400/33600 (34%)]\tLoss: 1.829028\n","Train Epoch: 17 [11600/33600 (35%)]\tLoss: 2.139674\n","Train Epoch: 17 [11800/33600 (35%)]\tLoss: 1.923368\n","Train Epoch: 17 [12000/33600 (36%)]\tLoss: 1.391716\n","Train Epoch: 17 [12200/33600 (36%)]\tLoss: 3.214616\n","Train Epoch: 17 [12400/33600 (37%)]\tLoss: 1.642037\n","Train Epoch: 17 [12600/33600 (38%)]\tLoss: 2.146942\n","Train Epoch: 17 [12800/33600 (38%)]\tLoss: 2.168821\n","Train Epoch: 17 [13000/33600 (39%)]\tLoss: 1.770643\n","Train Epoch: 17 [13200/33600 (39%)]\tLoss: 1.738876\n","Train Epoch: 17 [13400/33600 (40%)]\tLoss: 1.966577\n","Train Epoch: 17 [13600/33600 (40%)]\tLoss: 1.955513\n","Train Epoch: 17 [13800/33600 (41%)]\tLoss: 1.772051\n","Train Epoch: 17 [14000/33600 (42%)]\tLoss: 2.924347\n","Train Epoch: 17 [14200/33600 (42%)]\tLoss: 2.097269\n","Train Epoch: 17 [14400/33600 (43%)]\tLoss: 2.027590\n","Train Epoch: 17 [14600/33600 (43%)]\tLoss: 1.643559\n","Train Epoch: 17 [14800/33600 (44%)]\tLoss: 1.695479\n","Train Epoch: 17 [15000/33600 (45%)]\tLoss: 1.612869\n","Train Epoch: 17 [15200/33600 (45%)]\tLoss: 1.732696\n","Train Epoch: 17 [15400/33600 (46%)]\tLoss: 1.629046\n","Train Epoch: 17 [15600/33600 (46%)]\tLoss: 2.595769\n","Train Epoch: 17 [15800/33600 (47%)]\tLoss: 1.887266\n","Train Epoch: 17 [16000/33600 (48%)]\tLoss: 2.446327\n","Train Epoch: 17 [16200/33600 (48%)]\tLoss: 1.998999\n","Train Epoch: 17 [16400/33600 (49%)]\tLoss: 1.988407\n","Train Epoch: 17 [16600/33600 (49%)]\tLoss: 2.497305\n","Train Epoch: 17 [16800/33600 (50%)]\tLoss: 2.259359\n","Train Epoch: 17 [17000/33600 (51%)]\tLoss: 2.726261\n","Train Epoch: 17 [17200/33600 (51%)]\tLoss: 2.767623\n","Train Epoch: 17 [17400/33600 (52%)]\tLoss: 1.636633\n","Train Epoch: 17 [17600/33600 (52%)]\tLoss: 2.162787\n","Train Epoch: 17 [17800/33600 (53%)]\tLoss: 1.937596\n","Train Epoch: 17 [18000/33600 (54%)]\tLoss: 2.775759\n","Train Epoch: 17 [18200/33600 (54%)]\tLoss: 2.341147\n","Train Epoch: 17 [18400/33600 (55%)]\tLoss: 1.486675\n","Train Epoch: 17 [18600/33600 (55%)]\tLoss: 2.532900\n","Train Epoch: 17 [18800/33600 (56%)]\tLoss: 1.511853\n","Train Epoch: 17 [19000/33600 (57%)]\tLoss: 2.332571\n","Train Epoch: 17 [19200/33600 (57%)]\tLoss: 3.147274\n","Train Epoch: 17 [19400/33600 (58%)]\tLoss: 1.529592\n","Train Epoch: 17 [19600/33600 (58%)]\tLoss: 1.385789\n","Train Epoch: 17 [19800/33600 (59%)]\tLoss: 2.425418\n","Train Epoch: 17 [20000/33600 (60%)]\tLoss: 2.093033\n","Train Epoch: 17 [20200/33600 (60%)]\tLoss: 1.772804\n","Train Epoch: 17 [20400/33600 (61%)]\tLoss: 3.486763\n","Train Epoch: 17 [20600/33600 (61%)]\tLoss: 1.916181\n","Train Epoch: 17 [20800/33600 (62%)]\tLoss: 1.606474\n","Train Epoch: 17 [21000/33600 (62%)]\tLoss: 2.646990\n","Train Epoch: 17 [21200/33600 (63%)]\tLoss: 2.501949\n","Train Epoch: 17 [21400/33600 (64%)]\tLoss: 2.303598\n","Train Epoch: 17 [21600/33600 (64%)]\tLoss: 3.259664\n","Train Epoch: 17 [21800/33600 (65%)]\tLoss: 2.941116\n","Train Epoch: 17 [22000/33600 (65%)]\tLoss: 2.032113\n","Train Epoch: 17 [22200/33600 (66%)]\tLoss: 1.714083\n","Train Epoch: 17 [22400/33600 (67%)]\tLoss: 2.684690\n","Train Epoch: 17 [22600/33600 (67%)]\tLoss: 1.988711\n","Train Epoch: 17 [22800/33600 (68%)]\tLoss: 2.666269\n","Train Epoch: 17 [23000/33600 (68%)]\tLoss: 2.042779\n","Train Epoch: 17 [23200/33600 (69%)]\tLoss: 1.359487\n","Train Epoch: 17 [23400/33600 (70%)]\tLoss: 1.886662\n","Train Epoch: 17 [23600/33600 (70%)]\tLoss: 1.437745\n","Train Epoch: 17 [23800/33600 (71%)]\tLoss: 2.209791\n","Train Epoch: 17 [24000/33600 (71%)]\tLoss: 2.152170\n","Train Epoch: 17 [24200/33600 (72%)]\tLoss: 2.502324\n","Train Epoch: 17 [24400/33600 (73%)]\tLoss: 2.886688\n","Train Epoch: 17 [24600/33600 (73%)]\tLoss: 1.700338\n","Train Epoch: 17 [24800/33600 (74%)]\tLoss: 2.420146\n","Train Epoch: 17 [25000/33600 (74%)]\tLoss: 1.821185\n","Train Epoch: 17 [25200/33600 (75%)]\tLoss: 2.346197\n","Train Epoch: 17 [25400/33600 (76%)]\tLoss: 2.458891\n","Train Epoch: 17 [25600/33600 (76%)]\tLoss: 1.866281\n","Train Epoch: 17 [25800/33600 (77%)]\tLoss: 2.128711\n","Train Epoch: 17 [26000/33600 (77%)]\tLoss: 1.775785\n","Train Epoch: 17 [26200/33600 (78%)]\tLoss: 3.157637\n","Train Epoch: 17 [26400/33600 (79%)]\tLoss: 1.683912\n","Train Epoch: 17 [26600/33600 (79%)]\tLoss: 2.083504\n","Train Epoch: 17 [26800/33600 (80%)]\tLoss: 2.441384\n","Train Epoch: 17 [27000/33600 (80%)]\tLoss: 2.063193\n","Train Epoch: 17 [27200/33600 (81%)]\tLoss: 1.173942\n","Train Epoch: 17 [27400/33600 (82%)]\tLoss: 1.825648\n","Train Epoch: 17 [27600/33600 (82%)]\tLoss: 2.106224\n","Train Epoch: 17 [27800/33600 (83%)]\tLoss: 2.118066\n","Train Epoch: 17 [28000/33600 (83%)]\tLoss: 1.764199\n","Train Epoch: 17 [28200/33600 (84%)]\tLoss: 2.464369\n","Train Epoch: 17 [28400/33600 (85%)]\tLoss: 1.994726\n","Train Epoch: 17 [28600/33600 (85%)]\tLoss: 1.784776\n","Train Epoch: 17 [28800/33600 (86%)]\tLoss: 2.998438\n","Train Epoch: 17 [29000/33600 (86%)]\tLoss: 1.489643\n","Train Epoch: 17 [29200/33600 (87%)]\tLoss: 2.173642\n","Train Epoch: 17 [29400/33600 (88%)]\tLoss: 2.756993\n","Train Epoch: 17 [29600/33600 (88%)]\tLoss: 2.960907\n","Train Epoch: 17 [29800/33600 (89%)]\tLoss: 1.884737\n","Train Epoch: 17 [30000/33600 (89%)]\tLoss: 2.121885\n","Train Epoch: 17 [30200/33600 (90%)]\tLoss: 2.432607\n","Train Epoch: 17 [30400/33600 (90%)]\tLoss: 1.786082\n","Train Epoch: 17 [30600/33600 (91%)]\tLoss: 1.780645\n","Train Epoch: 17 [30800/33600 (92%)]\tLoss: 2.523064\n","Train Epoch: 17 [31000/33600 (92%)]\tLoss: 1.868451\n","Train Epoch: 17 [31200/33600 (93%)]\tLoss: 1.781514\n","Train Epoch: 17 [31400/33600 (93%)]\tLoss: 2.044232\n","Train Epoch: 17 [31600/33600 (94%)]\tLoss: 2.628758\n","Train Epoch: 17 [31800/33600 (95%)]\tLoss: 2.246149\n","Train Epoch: 17 [32000/33600 (95%)]\tLoss: 1.536153\n","Train Epoch: 17 [32200/33600 (96%)]\tLoss: 1.643848\n","Train Epoch: 17 [32400/33600 (96%)]\tLoss: 2.534853\n","Train Epoch: 17 [32600/33600 (97%)]\tLoss: 2.263029\n","Train Epoch: 17 [32800/33600 (98%)]\tLoss: 2.743271\n","Train Epoch: 17 [33000/33600 (98%)]\tLoss: 1.760302\n","Train Epoch: 17 [33200/33600 (99%)]\tLoss: 1.844766\n","Train Epoch: 17 [33400/33600 (99%)]\tLoss: 2.033046\n","Train Epoch: 17 [33600/33600 (100%)]\tLoss: 2.318222\n","\n","Validation - Average Loss: 2.0312, Accuracy: 37.845%\n","\n","Train Epoch: 18 [200/33600 (1%)]\tLoss: 2.661456\n","Train Epoch: 18 [400/33600 (1%)]\tLoss: 2.383495\n","Train Epoch: 18 [600/33600 (2%)]\tLoss: 1.854655\n","Train Epoch: 18 [800/33600 (2%)]\tLoss: 2.465746\n","Train Epoch: 18 [1000/33600 (3%)]\tLoss: 1.522309\n","Train Epoch: 18 [1200/33600 (4%)]\tLoss: 1.475074\n","Train Epoch: 18 [1400/33600 (4%)]\tLoss: 2.050338\n","Train Epoch: 18 [1600/33600 (5%)]\tLoss: 2.256605\n","Train Epoch: 18 [1800/33600 (5%)]\tLoss: 2.370432\n","Train Epoch: 18 [2000/33600 (6%)]\tLoss: 1.743924\n","Train Epoch: 18 [2200/33600 (7%)]\tLoss: 3.277040\n","Train Epoch: 18 [2400/33600 (7%)]\tLoss: 1.838622\n","Train Epoch: 18 [2600/33600 (8%)]\tLoss: 2.334933\n","Train Epoch: 18 [2800/33600 (8%)]\tLoss: 2.215846\n","Train Epoch: 18 [3000/33600 (9%)]\tLoss: 1.774673\n","Train Epoch: 18 [3200/33600 (10%)]\tLoss: 1.793305\n","Train Epoch: 18 [3400/33600 (10%)]\tLoss: 2.214952\n","Train Epoch: 18 [3600/33600 (11%)]\tLoss: 1.797033\n","Train Epoch: 18 [3800/33600 (11%)]\tLoss: 2.240335\n","Train Epoch: 18 [4000/33600 (12%)]\tLoss: 1.672330\n","Train Epoch: 18 [4200/33600 (12%)]\tLoss: 1.801779\n","Train Epoch: 18 [4400/33600 (13%)]\tLoss: 1.840401\n","Train Epoch: 18 [4600/33600 (14%)]\tLoss: 1.773935\n","Train Epoch: 18 [4800/33600 (14%)]\tLoss: 2.053570\n","Train Epoch: 18 [5000/33600 (15%)]\tLoss: 1.932961\n","Train Epoch: 18 [5200/33600 (15%)]\tLoss: 1.679590\n","Train Epoch: 18 [5400/33600 (16%)]\tLoss: 2.401769\n","Train Epoch: 18 [5600/33600 (17%)]\tLoss: 1.739738\n","Train Epoch: 18 [5800/33600 (17%)]\tLoss: 2.151446\n","Train Epoch: 18 [6000/33600 (18%)]\tLoss: 2.090731\n","Train Epoch: 18 [6200/33600 (18%)]\tLoss: 2.219284\n","Train Epoch: 18 [6400/33600 (19%)]\tLoss: 1.697204\n","Train Epoch: 18 [6600/33600 (20%)]\tLoss: 1.763826\n","Train Epoch: 18 [6800/33600 (20%)]\tLoss: 1.897048\n","Train Epoch: 18 [7000/33600 (21%)]\tLoss: 2.007417\n","Train Epoch: 18 [7200/33600 (21%)]\tLoss: 2.136844\n","Train Epoch: 18 [7400/33600 (22%)]\tLoss: 1.862164\n","Train Epoch: 18 [7600/33600 (23%)]\tLoss: 1.920930\n","Train Epoch: 18 [7800/33600 (23%)]\tLoss: 1.623892\n","Train Epoch: 18 [8000/33600 (24%)]\tLoss: 2.042768\n","Train Epoch: 18 [8200/33600 (24%)]\tLoss: 2.391932\n","Train Epoch: 18 [8400/33600 (25%)]\tLoss: 2.120964\n","Train Epoch: 18 [8600/33600 (26%)]\tLoss: 1.834094\n","Train Epoch: 18 [8800/33600 (26%)]\tLoss: 1.404155\n","Train Epoch: 18 [9000/33600 (27%)]\tLoss: 1.984285\n","Train Epoch: 18 [9200/33600 (27%)]\tLoss: 1.335227\n","Train Epoch: 18 [9400/33600 (28%)]\tLoss: 2.047587\n","Train Epoch: 18 [9600/33600 (29%)]\tLoss: 2.719186\n","Train Epoch: 18 [9800/33600 (29%)]\tLoss: 1.487683\n","Train Epoch: 18 [10000/33600 (30%)]\tLoss: 1.391937\n","Train Epoch: 18 [10200/33600 (30%)]\tLoss: 2.160178\n","Train Epoch: 18 [10400/33600 (31%)]\tLoss: 2.915359\n","Train Epoch: 18 [10600/33600 (32%)]\tLoss: 2.923775\n","Train Epoch: 18 [10800/33600 (32%)]\tLoss: 1.982453\n","Train Epoch: 18 [11000/33600 (33%)]\tLoss: 2.314988\n","Train Epoch: 18 [11200/33600 (33%)]\tLoss: 2.350425\n","Train Epoch: 18 [11400/33600 (34%)]\tLoss: 2.207456\n","Train Epoch: 18 [11600/33600 (35%)]\tLoss: 1.442327\n","Train Epoch: 18 [11800/33600 (35%)]\tLoss: 1.979773\n","Train Epoch: 18 [12000/33600 (36%)]\tLoss: 2.294792\n","Train Epoch: 18 [12200/33600 (36%)]\tLoss: 1.661298\n","Train Epoch: 18 [12400/33600 (37%)]\tLoss: 1.717638\n","Train Epoch: 18 [12600/33600 (38%)]\tLoss: 1.947864\n","Train Epoch: 18 [12800/33600 (38%)]\tLoss: 1.340877\n","Train Epoch: 18 [13000/33600 (39%)]\tLoss: 1.919816\n","Train Epoch: 18 [13200/33600 (39%)]\tLoss: 2.212670\n","Train Epoch: 18 [13400/33600 (40%)]\tLoss: 2.377879\n","Train Epoch: 18 [13600/33600 (40%)]\tLoss: 2.097749\n","Train Epoch: 18 [13800/33600 (41%)]\tLoss: 1.869133\n","Train Epoch: 18 [14000/33600 (42%)]\tLoss: 2.079382\n","Train Epoch: 18 [14200/33600 (42%)]\tLoss: 3.082175\n","Train Epoch: 18 [14400/33600 (43%)]\tLoss: 1.688485\n","Train Epoch: 18 [14600/33600 (43%)]\tLoss: 2.182464\n","Train Epoch: 18 [14800/33600 (44%)]\tLoss: 2.281510\n","Train Epoch: 18 [15000/33600 (45%)]\tLoss: 1.809488\n","Train Epoch: 18 [15200/33600 (45%)]\tLoss: 1.861840\n","Train Epoch: 18 [15400/33600 (46%)]\tLoss: 1.537282\n","Train Epoch: 18 [15600/33600 (46%)]\tLoss: 2.193128\n","Train Epoch: 18 [15800/33600 (47%)]\tLoss: 1.666046\n","Train Epoch: 18 [16000/33600 (48%)]\tLoss: 2.386679\n","Train Epoch: 18 [16200/33600 (48%)]\tLoss: 2.179048\n","Train Epoch: 18 [16400/33600 (49%)]\tLoss: 3.260900\n","Train Epoch: 18 [16600/33600 (49%)]\tLoss: 1.682862\n","Train Epoch: 18 [16800/33600 (50%)]\tLoss: 2.205641\n","Train Epoch: 18 [17000/33600 (51%)]\tLoss: 1.787898\n","Train Epoch: 18 [17200/33600 (51%)]\tLoss: 2.990288\n","Train Epoch: 18 [17400/33600 (52%)]\tLoss: 2.256479\n","Train Epoch: 18 [17600/33600 (52%)]\tLoss: 2.186311\n","Train Epoch: 18 [17800/33600 (53%)]\tLoss: 1.465092\n","Train Epoch: 18 [18000/33600 (54%)]\tLoss: 1.956341\n","Train Epoch: 18 [18200/33600 (54%)]\tLoss: 1.889699\n","Train Epoch: 18 [18400/33600 (55%)]\tLoss: 1.964599\n","Train Epoch: 18 [18600/33600 (55%)]\tLoss: 2.280378\n","Train Epoch: 18 [18800/33600 (56%)]\tLoss: 2.283882\n","Train Epoch: 18 [19000/33600 (57%)]\tLoss: 1.894248\n","Train Epoch: 18 [19200/33600 (57%)]\tLoss: 1.879497\n","Train Epoch: 18 [19400/33600 (58%)]\tLoss: 1.896120\n","Train Epoch: 18 [19600/33600 (58%)]\tLoss: 2.349341\n","Train Epoch: 18 [19800/33600 (59%)]\tLoss: 2.383144\n","Train Epoch: 18 [20000/33600 (60%)]\tLoss: 1.648225\n","Train Epoch: 18 [20200/33600 (60%)]\tLoss: 1.761240\n","Train Epoch: 18 [20400/33600 (61%)]\tLoss: 2.210681\n","Train Epoch: 18 [20600/33600 (61%)]\tLoss: 1.956079\n","Train Epoch: 18 [20800/33600 (62%)]\tLoss: 2.638475\n","Train Epoch: 18 [21000/33600 (62%)]\tLoss: 2.449635\n","Train Epoch: 18 [21200/33600 (63%)]\tLoss: 1.894227\n","Train Epoch: 18 [21400/33600 (64%)]\tLoss: 2.279071\n","Train Epoch: 18 [21600/33600 (64%)]\tLoss: 2.223193\n","Train Epoch: 18 [21800/33600 (65%)]\tLoss: 2.543334\n","Train Epoch: 18 [22000/33600 (65%)]\tLoss: 2.473804\n","Train Epoch: 18 [22200/33600 (66%)]\tLoss: 2.024660\n","Train Epoch: 18 [22400/33600 (67%)]\tLoss: 1.786646\n","Train Epoch: 18 [22600/33600 (67%)]\tLoss: 2.719021\n","Train Epoch: 18 [22800/33600 (68%)]\tLoss: 1.950061\n","Train Epoch: 18 [23000/33600 (68%)]\tLoss: 1.938000\n","Train Epoch: 18 [23200/33600 (69%)]\tLoss: 1.844011\n","Train Epoch: 18 [23400/33600 (70%)]\tLoss: 2.317600\n","Train Epoch: 18 [23600/33600 (70%)]\tLoss: 1.880744\n","Train Epoch: 18 [23800/33600 (71%)]\tLoss: 2.247585\n","Train Epoch: 18 [24000/33600 (71%)]\tLoss: 1.856080\n","Train Epoch: 18 [24200/33600 (72%)]\tLoss: 2.033887\n","Train Epoch: 18 [24400/33600 (73%)]\tLoss: 2.609591\n","Train Epoch: 18 [24600/33600 (73%)]\tLoss: 1.490954\n","Train Epoch: 18 [24800/33600 (74%)]\tLoss: 1.977954\n","Train Epoch: 18 [25000/33600 (74%)]\tLoss: 2.227021\n","Train Epoch: 18 [25200/33600 (75%)]\tLoss: 2.188351\n","Train Epoch: 18 [25400/33600 (76%)]\tLoss: 2.274830\n","Train Epoch: 18 [25600/33600 (76%)]\tLoss: 1.369803\n","Train Epoch: 18 [25800/33600 (77%)]\tLoss: 2.566589\n","Train Epoch: 18 [26000/33600 (77%)]\tLoss: 2.776832\n","Train Epoch: 18 [26200/33600 (78%)]\tLoss: 1.960930\n","Train Epoch: 18 [26400/33600 (79%)]\tLoss: 1.787893\n","Train Epoch: 18 [26600/33600 (79%)]\tLoss: 1.332633\n","Train Epoch: 18 [26800/33600 (80%)]\tLoss: 2.174803\n","Train Epoch: 18 [27000/33600 (80%)]\tLoss: 2.797683\n","Train Epoch: 18 [27200/33600 (81%)]\tLoss: 2.299486\n","Train Epoch: 18 [27400/33600 (82%)]\tLoss: 2.156108\n","Train Epoch: 18 [27600/33600 (82%)]\tLoss: 1.793195\n","Train Epoch: 18 [27800/33600 (83%)]\tLoss: 2.102751\n","Train Epoch: 18 [28000/33600 (83%)]\tLoss: 2.778481\n","Train Epoch: 18 [28200/33600 (84%)]\tLoss: 2.448905\n","Train Epoch: 18 [28400/33600 (85%)]\tLoss: 2.098638\n","Train Epoch: 18 [28600/33600 (85%)]\tLoss: 2.127540\n","Train Epoch: 18 [28800/33600 (86%)]\tLoss: 1.746692\n","Train Epoch: 18 [29000/33600 (86%)]\tLoss: 1.950599\n","Train Epoch: 18 [29200/33600 (87%)]\tLoss: 2.109535\n","Train Epoch: 18 [29400/33600 (88%)]\tLoss: 1.936082\n","Train Epoch: 18 [29600/33600 (88%)]\tLoss: 2.325421\n","Train Epoch: 18 [29800/33600 (89%)]\tLoss: 1.418456\n","Train Epoch: 18 [30000/33600 (89%)]\tLoss: 1.856060\n","Train Epoch: 18 [30200/33600 (90%)]\tLoss: 1.610775\n","Train Epoch: 18 [30400/33600 (90%)]\tLoss: 2.386213\n","Train Epoch: 18 [30600/33600 (91%)]\tLoss: 1.843931\n","Train Epoch: 18 [30800/33600 (92%)]\tLoss: 1.638057\n","Train Epoch: 18 [31000/33600 (92%)]\tLoss: 2.144856\n","Train Epoch: 18 [31200/33600 (93%)]\tLoss: 1.735759\n","Train Epoch: 18 [31400/33600 (93%)]\tLoss: 2.176709\n","Train Epoch: 18 [31600/33600 (94%)]\tLoss: 2.116810\n","Train Epoch: 18 [31800/33600 (95%)]\tLoss: 2.343435\n","Train Epoch: 18 [32000/33600 (95%)]\tLoss: 2.719435\n","Train Epoch: 18 [32200/33600 (96%)]\tLoss: 3.090697\n","Train Epoch: 18 [32400/33600 (96%)]\tLoss: 2.576212\n","Train Epoch: 18 [32600/33600 (97%)]\tLoss: 2.296186\n","Train Epoch: 18 [32800/33600 (98%)]\tLoss: 2.265692\n","Train Epoch: 18 [33000/33600 (98%)]\tLoss: 2.579868\n","Train Epoch: 18 [33200/33600 (99%)]\tLoss: 1.755428\n","Train Epoch: 18 [33400/33600 (99%)]\tLoss: 2.451690\n","Train Epoch: 18 [33600/33600 (100%)]\tLoss: 1.878984\n","\n","Validation - Average Loss: 1.9966, Accuracy: 34.429%\n","\n","Train Epoch: 19 [200/33600 (1%)]\tLoss: 2.647130\n","Train Epoch: 19 [400/33600 (1%)]\tLoss: 2.052102\n","Train Epoch: 19 [600/33600 (2%)]\tLoss: 2.236359\n","Train Epoch: 19 [800/33600 (2%)]\tLoss: 2.052986\n","Train Epoch: 19 [1000/33600 (3%)]\tLoss: 1.911330\n","Train Epoch: 19 [1200/33600 (4%)]\tLoss: 1.995055\n","Train Epoch: 19 [1400/33600 (4%)]\tLoss: 1.759896\n","Train Epoch: 19 [1600/33600 (5%)]\tLoss: 2.224481\n","Train Epoch: 19 [1800/33600 (5%)]\tLoss: 1.866413\n","Train Epoch: 19 [2000/33600 (6%)]\tLoss: 1.844131\n","Train Epoch: 19 [2200/33600 (7%)]\tLoss: 1.651767\n","Train Epoch: 19 [2400/33600 (7%)]\tLoss: 2.631789\n","Train Epoch: 19 [2600/33600 (8%)]\tLoss: 2.329146\n","Train Epoch: 19 [2800/33600 (8%)]\tLoss: 2.246679\n","Train Epoch: 19 [3000/33600 (9%)]\tLoss: 2.038996\n","Train Epoch: 19 [3200/33600 (10%)]\tLoss: 2.504887\n","Train Epoch: 19 [3400/33600 (10%)]\tLoss: 2.653395\n","Train Epoch: 19 [3600/33600 (11%)]\tLoss: 1.695834\n","Train Epoch: 19 [3800/33600 (11%)]\tLoss: 2.474790\n","Train Epoch: 19 [4000/33600 (12%)]\tLoss: 2.023284\n","Train Epoch: 19 [4200/33600 (12%)]\tLoss: 2.273498\n","Train Epoch: 19 [4400/33600 (13%)]\tLoss: 2.026431\n","Train Epoch: 19 [4600/33600 (14%)]\tLoss: 1.201022\n","Train Epoch: 19 [4800/33600 (14%)]\tLoss: 2.267765\n","Train Epoch: 19 [5000/33600 (15%)]\tLoss: 2.103593\n","Train Epoch: 19 [5200/33600 (15%)]\tLoss: 2.463106\n","Train Epoch: 19 [5400/33600 (16%)]\tLoss: 2.409685\n","Train Epoch: 19 [5600/33600 (17%)]\tLoss: 1.843524\n","Train Epoch: 19 [5800/33600 (17%)]\tLoss: 1.835960\n","Train Epoch: 19 [6000/33600 (18%)]\tLoss: 2.062824\n","Train Epoch: 19 [6200/33600 (18%)]\tLoss: 1.764572\n","Train Epoch: 19 [6400/33600 (19%)]\tLoss: 1.857938\n","Train Epoch: 19 [6600/33600 (20%)]\tLoss: 1.589586\n","Train Epoch: 19 [6800/33600 (20%)]\tLoss: 1.687773\n","Train Epoch: 19 [7000/33600 (21%)]\tLoss: 1.838853\n","Train Epoch: 19 [7200/33600 (21%)]\tLoss: 1.655399\n","Train Epoch: 19 [7400/33600 (22%)]\tLoss: 2.002579\n","Train Epoch: 19 [7600/33600 (23%)]\tLoss: 2.260688\n","Train Epoch: 19 [7800/33600 (23%)]\tLoss: 1.906373\n","Train Epoch: 19 [8000/33600 (24%)]\tLoss: 3.031614\n","Train Epoch: 19 [8200/33600 (24%)]\tLoss: 3.122614\n","Train Epoch: 19 [8400/33600 (25%)]\tLoss: 1.663144\n","Train Epoch: 19 [8600/33600 (26%)]\tLoss: 1.704900\n","Train Epoch: 19 [8800/33600 (26%)]\tLoss: 1.640471\n","Train Epoch: 19 [9000/33600 (27%)]\tLoss: 1.884534\n","Train Epoch: 19 [9200/33600 (27%)]\tLoss: 2.561795\n","Train Epoch: 19 [9400/33600 (28%)]\tLoss: 2.632492\n","Train Epoch: 19 [9600/33600 (29%)]\tLoss: 2.467093\n","Train Epoch: 19 [9800/33600 (29%)]\tLoss: 1.947152\n","Train Epoch: 19 [10000/33600 (30%)]\tLoss: 1.677518\n","Train Epoch: 19 [10200/33600 (30%)]\tLoss: 2.329738\n","Train Epoch: 19 [10400/33600 (31%)]\tLoss: 1.700322\n","Train Epoch: 19 [10600/33600 (32%)]\tLoss: 2.425127\n","Train Epoch: 19 [10800/33600 (32%)]\tLoss: 2.060217\n","Train Epoch: 19 [11000/33600 (33%)]\tLoss: 2.199794\n","Train Epoch: 19 [11200/33600 (33%)]\tLoss: 2.453359\n","Train Epoch: 19 [11400/33600 (34%)]\tLoss: 2.193611\n","Train Epoch: 19 [11600/33600 (35%)]\tLoss: 2.310799\n","Train Epoch: 19 [11800/33600 (35%)]\tLoss: 2.192088\n","Train Epoch: 19 [12000/33600 (36%)]\tLoss: 2.239759\n","Train Epoch: 19 [12200/33600 (36%)]\tLoss: 1.968830\n","Train Epoch: 19 [12400/33600 (37%)]\tLoss: 1.888157\n","Train Epoch: 19 [12600/33600 (38%)]\tLoss: 1.733848\n","Train Epoch: 19 [12800/33600 (38%)]\tLoss: 2.610053\n","Train Epoch: 19 [13000/33600 (39%)]\tLoss: 2.243200\n","Train Epoch: 19 [13200/33600 (39%)]\tLoss: 1.653112\n","Train Epoch: 19 [13400/33600 (40%)]\tLoss: 2.281750\n","Train Epoch: 19 [13600/33600 (40%)]\tLoss: 2.011013\n","Train Epoch: 19 [13800/33600 (41%)]\tLoss: 2.240493\n","Train Epoch: 19 [14000/33600 (42%)]\tLoss: 2.631390\n","Train Epoch: 19 [14200/33600 (42%)]\tLoss: 2.263732\n","Train Epoch: 19 [14400/33600 (43%)]\tLoss: 2.537780\n","Train Epoch: 19 [14600/33600 (43%)]\tLoss: 1.725403\n","Train Epoch: 19 [14800/33600 (44%)]\tLoss: 3.477244\n","Train Epoch: 19 [15000/33600 (45%)]\tLoss: 1.954234\n","Train Epoch: 19 [15200/33600 (45%)]\tLoss: 2.123460\n","Train Epoch: 19 [15400/33600 (46%)]\tLoss: 1.841804\n","Train Epoch: 19 [15600/33600 (46%)]\tLoss: 2.267857\n","Train Epoch: 19 [15800/33600 (47%)]\tLoss: 2.331600\n","Train Epoch: 19 [16000/33600 (48%)]\tLoss: 1.716802\n","Train Epoch: 19 [16200/33600 (48%)]\tLoss: 1.775664\n","Train Epoch: 19 [16400/33600 (49%)]\tLoss: 2.513084\n","Train Epoch: 19 [16600/33600 (49%)]\tLoss: 1.931257\n","Train Epoch: 19 [16800/33600 (50%)]\tLoss: 2.458025\n","Train Epoch: 19 [17000/33600 (51%)]\tLoss: 3.419124\n","Train Epoch: 19 [17200/33600 (51%)]\tLoss: 1.726372\n","Train Epoch: 19 [17400/33600 (52%)]\tLoss: 2.472017\n","Train Epoch: 19 [17600/33600 (52%)]\tLoss: 2.385878\n","Train Epoch: 19 [17800/33600 (53%)]\tLoss: 2.555295\n","Train Epoch: 19 [18000/33600 (54%)]\tLoss: 2.790813\n","Train Epoch: 19 [18200/33600 (54%)]\tLoss: 2.071750\n","Train Epoch: 19 [18400/33600 (55%)]\tLoss: 1.864640\n","Train Epoch: 19 [18600/33600 (55%)]\tLoss: 2.110647\n","Train Epoch: 19 [18800/33600 (56%)]\tLoss: 2.529032\n","Train Epoch: 19 [19000/33600 (57%)]\tLoss: 2.442960\n","Train Epoch: 19 [19200/33600 (57%)]\tLoss: 2.675708\n","Train Epoch: 19 [19400/33600 (58%)]\tLoss: 2.018246\n","Train Epoch: 19 [19600/33600 (58%)]\tLoss: 1.766238\n","Train Epoch: 19 [19800/33600 (59%)]\tLoss: 2.814374\n","Train Epoch: 19 [20000/33600 (60%)]\tLoss: 2.053393\n","Train Epoch: 19 [20200/33600 (60%)]\tLoss: 1.791902\n","Train Epoch: 19 [20400/33600 (61%)]\tLoss: 1.903419\n","Train Epoch: 19 [20600/33600 (61%)]\tLoss: 2.115151\n","Train Epoch: 19 [20800/33600 (62%)]\tLoss: 2.131929\n","Train Epoch: 19 [21000/33600 (62%)]\tLoss: 2.572223\n","Train Epoch: 19 [21200/33600 (63%)]\tLoss: 2.146344\n","Train Epoch: 19 [21400/33600 (64%)]\tLoss: 2.088146\n","Train Epoch: 19 [21600/33600 (64%)]\tLoss: 1.897904\n","Train Epoch: 19 [21800/33600 (65%)]\tLoss: 1.658263\n","Train Epoch: 19 [22000/33600 (65%)]\tLoss: 1.985340\n","Train Epoch: 19 [22200/33600 (66%)]\tLoss: 1.812375\n","Train Epoch: 19 [22400/33600 (67%)]\tLoss: 2.106905\n","Train Epoch: 19 [22600/33600 (67%)]\tLoss: 2.094110\n","Train Epoch: 19 [22800/33600 (68%)]\tLoss: 2.228140\n","Train Epoch: 19 [23000/33600 (68%)]\tLoss: 1.925475\n","Train Epoch: 19 [23200/33600 (69%)]\tLoss: 2.139886\n","Train Epoch: 19 [23400/33600 (70%)]\tLoss: 1.942400\n","Train Epoch: 19 [23600/33600 (70%)]\tLoss: 2.430787\n","Train Epoch: 19 [23800/33600 (71%)]\tLoss: 2.860237\n","Train Epoch: 19 [24000/33600 (71%)]\tLoss: 2.442281\n","Train Epoch: 19 [24200/33600 (72%)]\tLoss: 2.068279\n","Train Epoch: 19 [24400/33600 (73%)]\tLoss: 2.246034\n","Train Epoch: 19 [24600/33600 (73%)]\tLoss: 1.722920\n","Train Epoch: 19 [24800/33600 (74%)]\tLoss: 2.457762\n","Train Epoch: 19 [25000/33600 (74%)]\tLoss: 2.545321\n","Train Epoch: 19 [25200/33600 (75%)]\tLoss: 1.941477\n","Train Epoch: 19 [25400/33600 (76%)]\tLoss: 2.478255\n","Train Epoch: 19 [25600/33600 (76%)]\tLoss: 1.991273\n","Train Epoch: 19 [25800/33600 (77%)]\tLoss: 2.665746\n","Train Epoch: 19 [26000/33600 (77%)]\tLoss: 2.082759\n","Train Epoch: 19 [26200/33600 (78%)]\tLoss: 1.768305\n","Train Epoch: 19 [26400/33600 (79%)]\tLoss: 2.330345\n","Train Epoch: 19 [26600/33600 (79%)]\tLoss: 2.380257\n","Train Epoch: 19 [26800/33600 (80%)]\tLoss: 1.747051\n","Train Epoch: 19 [27000/33600 (80%)]\tLoss: 2.211021\n","Train Epoch: 19 [27200/33600 (81%)]\tLoss: 1.838487\n","Train Epoch: 19 [27400/33600 (82%)]\tLoss: 3.351214\n","Train Epoch: 19 [27600/33600 (82%)]\tLoss: 1.508201\n","Train Epoch: 19 [27800/33600 (83%)]\tLoss: 2.104757\n","Train Epoch: 19 [28000/33600 (83%)]\tLoss: 2.006397\n","Train Epoch: 19 [28200/33600 (84%)]\tLoss: 1.629242\n","Train Epoch: 19 [28400/33600 (85%)]\tLoss: 2.371226\n","Train Epoch: 19 [28600/33600 (85%)]\tLoss: 2.465306\n","Train Epoch: 19 [28800/33600 (86%)]\tLoss: 2.053893\n","Train Epoch: 19 [29000/33600 (86%)]\tLoss: 1.597412\n","Train Epoch: 19 [29200/33600 (87%)]\tLoss: 1.463016\n","Train Epoch: 19 [29400/33600 (88%)]\tLoss: 2.341261\n","Train Epoch: 19 [29600/33600 (88%)]\tLoss: 1.473506\n","Train Epoch: 19 [29800/33600 (89%)]\tLoss: 1.456140\n","Train Epoch: 19 [30000/33600 (89%)]\tLoss: 2.153938\n","Train Epoch: 19 [30200/33600 (90%)]\tLoss: 2.500828\n","Train Epoch: 19 [30400/33600 (90%)]\tLoss: 2.577452\n","Train Epoch: 19 [30600/33600 (91%)]\tLoss: 1.555156\n","Train Epoch: 19 [30800/33600 (92%)]\tLoss: 2.684898\n","Train Epoch: 19 [31000/33600 (92%)]\tLoss: 1.513337\n","Train Epoch: 19 [31200/33600 (93%)]\tLoss: 2.361828\n","Train Epoch: 19 [31400/33600 (93%)]\tLoss: 1.797391\n","Train Epoch: 19 [31600/33600 (94%)]\tLoss: 1.755849\n","Train Epoch: 19 [31800/33600 (95%)]\tLoss: 2.045286\n","Train Epoch: 19 [32000/33600 (95%)]\tLoss: 2.128878\n","Train Epoch: 19 [32200/33600 (96%)]\tLoss: 1.853253\n","Train Epoch: 19 [32400/33600 (96%)]\tLoss: 1.992604\n","Train Epoch: 19 [32600/33600 (97%)]\tLoss: 2.192145\n","Train Epoch: 19 [32800/33600 (98%)]\tLoss: 1.825331\n","Train Epoch: 19 [33000/33600 (98%)]\tLoss: 1.966910\n","Train Epoch: 19 [33200/33600 (99%)]\tLoss: 2.535199\n","Train Epoch: 19 [33400/33600 (99%)]\tLoss: 1.469862\n","Train Epoch: 19 [33600/33600 (100%)]\tLoss: 2.085803\n","\n","Validation - Average Loss: 2.0428, Accuracy: 33.750%\n","\n","Train Epoch: 20 [200/33600 (1%)]\tLoss: 2.907674\n","Train Epoch: 20 [400/33600 (1%)]\tLoss: 2.526163\n","Train Epoch: 20 [600/33600 (2%)]\tLoss: 2.643253\n","Train Epoch: 20 [800/33600 (2%)]\tLoss: 2.408355\n","Train Epoch: 20 [1000/33600 (3%)]\tLoss: 2.088500\n","Train Epoch: 20 [1200/33600 (4%)]\tLoss: 2.973759\n","Train Epoch: 20 [1400/33600 (4%)]\tLoss: 1.802097\n","Train Epoch: 20 [1600/33600 (5%)]\tLoss: 1.979716\n","Train Epoch: 20 [1800/33600 (5%)]\tLoss: 2.136564\n","Train Epoch: 20 [2000/33600 (6%)]\tLoss: 1.676926\n","Train Epoch: 20 [2200/33600 (7%)]\tLoss: 1.898871\n","Train Epoch: 20 [2400/33600 (7%)]\tLoss: 2.464763\n","Train Epoch: 20 [2600/33600 (8%)]\tLoss: 2.814057\n","Train Epoch: 20 [2800/33600 (8%)]\tLoss: 2.998536\n","Train Epoch: 20 [3000/33600 (9%)]\tLoss: 2.267786\n","Train Epoch: 20 [3200/33600 (10%)]\tLoss: 2.131437\n","Train Epoch: 20 [3400/33600 (10%)]\tLoss: 1.934337\n","Train Epoch: 20 [3600/33600 (11%)]\tLoss: 2.503991\n","Train Epoch: 20 [3800/33600 (11%)]\tLoss: 2.381051\n","Train Epoch: 20 [4000/33600 (12%)]\tLoss: 1.348107\n","Train Epoch: 20 [4200/33600 (12%)]\tLoss: 1.733788\n","Train Epoch: 20 [4400/33600 (13%)]\tLoss: 2.175760\n","Train Epoch: 20 [4600/33600 (14%)]\tLoss: 1.915072\n","Train Epoch: 20 [4800/33600 (14%)]\tLoss: 2.189138\n","Train Epoch: 20 [5000/33600 (15%)]\tLoss: 2.533103\n","Train Epoch: 20 [5200/33600 (15%)]\tLoss: 2.385849\n","Train Epoch: 20 [5400/33600 (16%)]\tLoss: 1.364668\n","Train Epoch: 20 [5600/33600 (17%)]\tLoss: 3.026571\n","Train Epoch: 20 [5800/33600 (17%)]\tLoss: 1.762491\n","Train Epoch: 20 [6000/33600 (18%)]\tLoss: 1.744726\n","Train Epoch: 20 [6200/33600 (18%)]\tLoss: 2.557532\n","Train Epoch: 20 [6400/33600 (19%)]\tLoss: 1.877576\n","Train Epoch: 20 [6600/33600 (20%)]\tLoss: 2.493149\n","Train Epoch: 20 [6800/33600 (20%)]\tLoss: 2.154771\n","Train Epoch: 20 [7000/33600 (21%)]\tLoss: 2.528544\n","Train Epoch: 20 [7200/33600 (21%)]\tLoss: 1.814228\n","Train Epoch: 20 [7400/33600 (22%)]\tLoss: 2.462394\n","Train Epoch: 20 [7600/33600 (23%)]\tLoss: 2.577838\n","Train Epoch: 20 [7800/33600 (23%)]\tLoss: 1.688769\n","Train Epoch: 20 [8000/33600 (24%)]\tLoss: 2.850160\n","Train Epoch: 20 [8200/33600 (24%)]\tLoss: 2.185178\n","Train Epoch: 20 [8400/33600 (25%)]\tLoss: 1.955305\n","Train Epoch: 20 [8600/33600 (26%)]\tLoss: 1.895251\n","Train Epoch: 20 [8800/33600 (26%)]\tLoss: 2.282632\n","Train Epoch: 20 [9000/33600 (27%)]\tLoss: 1.891840\n","Train Epoch: 20 [9200/33600 (27%)]\tLoss: 2.200158\n","Train Epoch: 20 [9400/33600 (28%)]\tLoss: 2.087131\n","Train Epoch: 20 [9600/33600 (29%)]\tLoss: 1.935650\n","Train Epoch: 20 [9800/33600 (29%)]\tLoss: 1.852315\n","Train Epoch: 20 [10000/33600 (30%)]\tLoss: 1.721798\n","Train Epoch: 20 [10200/33600 (30%)]\tLoss: 2.443523\n","Train Epoch: 20 [10400/33600 (31%)]\tLoss: 1.969866\n","Train Epoch: 20 [10600/33600 (32%)]\tLoss: 1.875320\n","Train Epoch: 20 [10800/33600 (32%)]\tLoss: 1.844738\n","Train Epoch: 20 [11000/33600 (33%)]\tLoss: 1.898383\n","Train Epoch: 20 [11200/33600 (33%)]\tLoss: 2.551499\n","Train Epoch: 20 [11400/33600 (34%)]\tLoss: 1.948965\n","Train Epoch: 20 [11600/33600 (35%)]\tLoss: 1.847158\n","Train Epoch: 20 [11800/33600 (35%)]\tLoss: 2.047803\n","Train Epoch: 20 [12000/33600 (36%)]\tLoss: 1.542976\n","Train Epoch: 20 [12200/33600 (36%)]\tLoss: 2.005822\n","Train Epoch: 20 [12400/33600 (37%)]\tLoss: 2.694129\n","Train Epoch: 20 [12600/33600 (38%)]\tLoss: 1.827321\n","Train Epoch: 20 [12800/33600 (38%)]\tLoss: 2.092984\n","Train Epoch: 20 [13000/33600 (39%)]\tLoss: 2.289958\n","Train Epoch: 20 [13200/33600 (39%)]\tLoss: 1.674578\n","Train Epoch: 20 [13400/33600 (40%)]\tLoss: 1.848504\n","Train Epoch: 20 [13600/33600 (40%)]\tLoss: 1.895974\n","Train Epoch: 20 [13800/33600 (41%)]\tLoss: 2.088693\n","Train Epoch: 20 [14000/33600 (42%)]\tLoss: 2.048755\n","Train Epoch: 20 [14200/33600 (42%)]\tLoss: 1.903594\n","Train Epoch: 20 [14400/33600 (43%)]\tLoss: 2.980998\n","Train Epoch: 20 [14600/33600 (43%)]\tLoss: 3.103937\n","Train Epoch: 20 [14800/33600 (44%)]\tLoss: 1.730577\n","Train Epoch: 20 [15000/33600 (45%)]\tLoss: 1.927939\n","Train Epoch: 20 [15200/33600 (45%)]\tLoss: 1.995422\n","Train Epoch: 20 [15400/33600 (46%)]\tLoss: 1.567781\n","Train Epoch: 20 [15600/33600 (46%)]\tLoss: 2.263602\n","Train Epoch: 20 [15800/33600 (47%)]\tLoss: 2.470635\n","Train Epoch: 20 [16000/33600 (48%)]\tLoss: 1.871738\n","Train Epoch: 20 [16200/33600 (48%)]\tLoss: 1.810822\n","Train Epoch: 20 [16400/33600 (49%)]\tLoss: 1.859817\n","Train Epoch: 20 [16600/33600 (49%)]\tLoss: 2.277600\n","Train Epoch: 20 [16800/33600 (50%)]\tLoss: 2.249618\n","Train Epoch: 20 [17000/33600 (51%)]\tLoss: 2.826843\n","Train Epoch: 20 [17200/33600 (51%)]\tLoss: 2.179433\n","Train Epoch: 20 [17400/33600 (52%)]\tLoss: 2.316823\n","Train Epoch: 20 [17600/33600 (52%)]\tLoss: 2.084120\n","Train Epoch: 20 [17800/33600 (53%)]\tLoss: 2.190386\n","Train Epoch: 20 [18000/33600 (54%)]\tLoss: 1.948116\n","Train Epoch: 20 [18200/33600 (54%)]\tLoss: 2.298598\n","Train Epoch: 20 [18400/33600 (55%)]\tLoss: 1.940615\n","Train Epoch: 20 [18600/33600 (55%)]\tLoss: 2.088751\n","Train Epoch: 20 [18800/33600 (56%)]\tLoss: 1.689784\n","Train Epoch: 20 [19000/33600 (57%)]\tLoss: 1.975005\n","Train Epoch: 20 [19200/33600 (57%)]\tLoss: 2.253696\n","Train Epoch: 20 [19400/33600 (58%)]\tLoss: 2.377530\n","Train Epoch: 20 [19600/33600 (58%)]\tLoss: 1.925695\n","Train Epoch: 20 [19800/33600 (59%)]\tLoss: 3.056024\n","Train Epoch: 20 [20000/33600 (60%)]\tLoss: 2.779648\n","Train Epoch: 20 [20200/33600 (60%)]\tLoss: 1.920426\n","Train Epoch: 20 [20400/33600 (61%)]\tLoss: 2.290051\n","Train Epoch: 20 [20600/33600 (61%)]\tLoss: 2.045578\n","Train Epoch: 20 [20800/33600 (62%)]\tLoss: 2.425096\n","Train Epoch: 20 [21000/33600 (62%)]\tLoss: 1.309716\n","Train Epoch: 20 [21200/33600 (63%)]\tLoss: 2.339418\n","Train Epoch: 20 [21400/33600 (64%)]\tLoss: 2.547299\n","Train Epoch: 20 [21600/33600 (64%)]\tLoss: 2.036360\n","Train Epoch: 20 [21800/33600 (65%)]\tLoss: 2.341221\n","Train Epoch: 20 [22000/33600 (65%)]\tLoss: 2.361830\n","Train Epoch: 20 [22200/33600 (66%)]\tLoss: 2.172311\n","Train Epoch: 20 [22400/33600 (67%)]\tLoss: 1.664508\n","Train Epoch: 20 [22600/33600 (67%)]\tLoss: 2.828069\n","Train Epoch: 20 [22800/33600 (68%)]\tLoss: 2.303564\n","Train Epoch: 20 [23000/33600 (68%)]\tLoss: 1.792697\n","Train Epoch: 20 [23200/33600 (69%)]\tLoss: 2.252498\n","Train Epoch: 20 [23400/33600 (70%)]\tLoss: 1.395249\n","Train Epoch: 20 [23600/33600 (70%)]\tLoss: 1.694336\n","Train Epoch: 20 [23800/33600 (71%)]\tLoss: 2.138039\n","Train Epoch: 20 [24000/33600 (71%)]\tLoss: 1.781132\n","Train Epoch: 20 [24200/33600 (72%)]\tLoss: 2.093270\n","Train Epoch: 20 [24400/33600 (73%)]\tLoss: 2.149816\n","Train Epoch: 20 [24600/33600 (73%)]\tLoss: 2.098793\n","Train Epoch: 20 [24800/33600 (74%)]\tLoss: 2.614381\n","Train Epoch: 20 [25000/33600 (74%)]\tLoss: 1.916378\n","Train Epoch: 20 [25200/33600 (75%)]\tLoss: 1.635496\n","Train Epoch: 20 [25400/33600 (76%)]\tLoss: 2.604619\n","Train Epoch: 20 [25600/33600 (76%)]\tLoss: 2.218133\n","Train Epoch: 20 [25800/33600 (77%)]\tLoss: 1.950081\n","Train Epoch: 20 [26000/33600 (77%)]\tLoss: 2.251853\n","Train Epoch: 20 [26200/33600 (78%)]\tLoss: 1.947414\n","Train Epoch: 20 [26400/33600 (79%)]\tLoss: 1.353175\n","Train Epoch: 20 [26600/33600 (79%)]\tLoss: 1.655976\n","Train Epoch: 20 [26800/33600 (80%)]\tLoss: 1.643236\n","Train Epoch: 20 [27000/33600 (80%)]\tLoss: 2.831343\n","Train Epoch: 20 [27200/33600 (81%)]\tLoss: 1.787374\n","Train Epoch: 20 [27400/33600 (82%)]\tLoss: 1.800234\n","Train Epoch: 20 [27600/33600 (82%)]\tLoss: 1.264533\n","Train Epoch: 20 [27800/33600 (83%)]\tLoss: 2.583573\n","Train Epoch: 20 [28000/33600 (83%)]\tLoss: 2.491893\n","Train Epoch: 20 [28200/33600 (84%)]\tLoss: 2.410007\n","Train Epoch: 20 [28400/33600 (85%)]\tLoss: 2.750199\n","Train Epoch: 20 [28600/33600 (85%)]\tLoss: 2.002433\n","Train Epoch: 20 [28800/33600 (86%)]\tLoss: 2.768753\n","Train Epoch: 20 [29000/33600 (86%)]\tLoss: 2.085017\n","Train Epoch: 20 [29200/33600 (87%)]\tLoss: 1.650637\n","Train Epoch: 20 [29400/33600 (88%)]\tLoss: 1.729416\n","Train Epoch: 20 [29600/33600 (88%)]\tLoss: 2.028057\n","Train Epoch: 20 [29800/33600 (89%)]\tLoss: 1.533274\n","Train Epoch: 20 [30000/33600 (89%)]\tLoss: 2.608859\n","Train Epoch: 20 [30200/33600 (90%)]\tLoss: 2.400175\n","Train Epoch: 20 [30400/33600 (90%)]\tLoss: 2.699981\n","Train Epoch: 20 [30600/33600 (91%)]\tLoss: 2.451299\n","Train Epoch: 20 [30800/33600 (92%)]\tLoss: 2.327564\n","Train Epoch: 20 [31000/33600 (92%)]\tLoss: 2.063869\n","Train Epoch: 20 [31200/33600 (93%)]\tLoss: 2.429316\n","Train Epoch: 20 [31400/33600 (93%)]\tLoss: 1.963438\n","Train Epoch: 20 [31600/33600 (94%)]\tLoss: 2.170943\n","Train Epoch: 20 [31800/33600 (95%)]\tLoss: 2.664472\n","Train Epoch: 20 [32000/33600 (95%)]\tLoss: 1.990390\n","Train Epoch: 20 [32200/33600 (96%)]\tLoss: 2.557072\n","Train Epoch: 20 [32400/33600 (96%)]\tLoss: 2.972633\n","Train Epoch: 20 [32600/33600 (97%)]\tLoss: 2.079895\n","Train Epoch: 20 [32800/33600 (98%)]\tLoss: 2.078772\n","Train Epoch: 20 [33000/33600 (98%)]\tLoss: 2.060915\n","Train Epoch: 20 [33200/33600 (99%)]\tLoss: 2.625510\n","Train Epoch: 20 [33400/33600 (99%)]\tLoss: 2.780259\n","Train Epoch: 20 [33600/33600 (100%)]\tLoss: 1.177450\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[199], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      4\u001b[0m     train_model(n)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Plot the metrics after training\u001b[39;00m\n\u001b[1;32m      8\u001b[0m plot_metrics()\n","Cell \u001b[0;32mIn[198], line 60\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(data_loader)\u001b[0m\n\u001b[1;32m     57\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     58\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 60\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mconv_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n\u001b[1;32m     62\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","Cell \u001b[0;32mIn[196], line 33\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 33\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     35\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_block(x)\n","File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["num_epochs = 40\n","\n","for n in range(num_epochs):\n","    train_model(n)\n","    evaluate(val_loader)\n","\n","# Plot the metrics after training\n","plot_metrics()"]},{"cell_type":"markdown","metadata":{},"source":["### Saving the full CNN model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the full model\n","torch.save(conv_model, 'cnn_full_model.pth')"]},{"cell_type":"markdown","metadata":{},"source":["### Loading the full CNN model"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["Net(\n","  (conv_block): Sequential(\n","    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace)\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (9): ReLU(inplace)\n","    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (linear_block): Sequential(\n","    (0): Dropout(p=0.5)\n","    (1): Linear(in_features=6272, out_features=128, bias=True)\n","    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): ReLU(inplace)\n","    (4): Dropout(p=0.5)\n","    (5): Linear(in_features=128, out_features=64, bias=True)\n","    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): ReLU(inplace)\n","    (8): Dropout(p=0.5)\n","    (9): Linear(in_features=64, out_features=10, bias=True)\n","  )\n",")"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# To load the full model after the JN has timed out:\n","conv_model = torch.load('cnn_full_model.pth')\n","if torch.cuda.is_available():\n","    conv_model = conv_model.cuda()\n","conv_model.eval()  # Setting the model to evaluation mode"]},{"cell_type":"markdown","metadata":{"_uuid":"ba3507e41b548d5a7f6005a6eeb9219f246dea7c"},"source":["#### Make predictions on the test set (just the CNN)"]},{"cell_type":"code","execution_count":31,"metadata":{"_uuid":"4fedc4c69ff64bf3108a291926643fffce1c864e","trusted":true},"outputs":[],"source":["def make_predictions(data_loader):\n","    conv_model.eval()\n","    test_preds = torch.LongTensor()\n","    \n","    for i, data in enumerate(data_loader):\n","        data = data.unsqueeze(1)\n","        \n","        if torch.cuda.is_available():\n","            data = data.cuda()\n","            \n","        output = conv_model(data)\n","        \n","        preds = output.cpu().data.max(1, keepdim=True)[1]\n","        test_preds = torch.cat((test_preds, preds), dim=0)\n","        \n","    return test_preds\n","\n","#Run the inference\n","test_set_preds = make_predictions(test_loader)"]},{"cell_type":"markdown","metadata":{"_uuid":"80fae08d574b70975df07189687853b606389d74"},"source":["#### Prepare Submissions"]},{"cell_type":"code","execution_count":28,"metadata":{"_uuid":"d9aa65de4472cdc45de649cc55b95bf4e9435cdb","trusted":true},"outputs":[],"source":["submission_df = pd.read_csv(\"../Data/sample_submission.csv\")"]},{"cell_type":"code","execution_count":29,"metadata":{"_uuid":"6e6ca4d2373511e3d6bed6054a54464267ee0f14","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ImageId</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ImageId  Label\n","0        1      2\n","1        2      0\n","2        3      9\n","3        4      9\n","4        5      3"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["submission_df['Label'] = test_set_preds.numpy().squeeze()\n","submission_df.head()"]},{"cell_type":"code","execution_count":30,"metadata":{"_uuid":"bb7b97c22c0e1a94796e3868834bf8ac0f213562","trusted":true},"outputs":[],"source":["submission_df.to_csv('submission.csv', index=False)"]},{"cell_type":"markdown","metadata":{},"source":["### Puppeteer MLP"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["PuppeteerNet(\n","  (mlp): Sequential(\n","    (0): Linear(in_features=10, out_features=512, bias=True)\n","    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace)\n","    (3): Dropout(p=0.3)\n","    (4): Linear(in_features=512, out_features=1024, bias=True)\n","    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (6): ReLU(inplace)\n","    (7): Dropout(p=0.3)\n","    (8): Linear(in_features=1024, out_features=2048, bias=True)\n","    (9): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (10): ReLU(inplace)\n","    (11): Dropout(p=0.3)\n","    (12): Linear(in_features=2048, out_features=1024, bias=True)\n","    (13): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (14): ReLU(inplace)\n","    (15): Dropout(p=0.3)\n","    (16): Linear(in_features=1024, out_features=512, bias=True)\n","    (17): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (18): ReLU(inplace)\n","    (19): Dropout(p=0.3)\n","    (20): Linear(in_features=512, out_features=6272, bias=True)\n","    (21): Tanh()\n","  )\n",")"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["class PuppeteerNet(nn.Module):\n","    def __init__(self):\n","        super(PuppeteerNet, self).__init__()\n","        \n","        # Input: 10 neurons (one-hot encoded digit to inhibit)\n","        # Output: 6272 (to match CNN's 128*7*7 feature map)\n","        \n","        self.mlp = nn.Sequential(\n","            # First layer\n","            nn.Linear(10, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.3),\n","            \n","            # Second layer\n","            nn.Linear(512, 1024),\n","            nn.BatchNorm1d(1024),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.3),\n","            \n","            # Third layer\n","            nn.Linear(1024, 2048),\n","            nn.BatchNorm1d(2048),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.3),\n","            \n","            # Fourth layer\n","            nn.Linear(2048, 1024),\n","            nn.BatchNorm1d(1024),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.3),\n","            \n","            # Fifth layer\n","            nn.Linear(1024, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(0.3),\n","            \n","            # Output layer\n","            nn.Linear(512, 128*7*7),  # 6272 outputs to match CNN's feature map\n","            nn.Tanh()  # Allow for positive and negative manipulation\n","        )\n","        \n","    def forward(self, x):\n","        return self.mlp(x)\n","    \n","puppeteer_net=PuppeteerNet()\n","puppeteer_net"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([8, 1, 28, 28])\n"]}],"source":["print(images.shape)\n"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/10], Step [100/4200], Loss: 1.1831\n","Epoch [1/10], Step [200/4200], Loss: 0.0205\n","Epoch [1/10], Step [300/4200], Loss: 0.0114\n","Epoch [1/10], Step [400/4200], Loss: 0.0135\n","Epoch [1/10], Step [500/4200], Loss: 0.0226\n","Epoch [1/10], Step [600/4200], Loss: 0.0107\n","Epoch [1/10], Step [700/4200], Loss: 0.0117\n","Epoch [1/10], Step [800/4200], Loss: 0.0049\n","Epoch [1/10], Step [900/4200], Loss: 0.0062\n","Epoch [1/10], Step [1000/4200], Loss: 0.0048\n","Epoch [1/10], Step [1100/4200], Loss: 0.0081\n","Epoch [1/10], Step [1200/4200], Loss: 0.0058\n","Epoch [1/10], Step [1300/4200], Loss: 0.0052\n","Epoch [1/10], Step [1400/4200], Loss: 0.0027\n","Epoch [1/10], Step [1500/4200], Loss: 0.0028\n","Epoch [1/10], Step [1600/4200], Loss: 0.0033\n","Epoch [1/10], Step [1700/4200], Loss: 0.0055\n","Epoch [1/10], Step [1800/4200], Loss: 0.0033\n","Epoch [1/10], Step [1900/4200], Loss: 0.0009\n","Epoch [1/10], Step [2000/4200], Loss: 0.0027\n","Epoch [1/10], Step [2100/4200], Loss: 0.0035\n","Epoch [1/10], Step [2200/4200], Loss: 0.0059\n","Epoch [1/10], Step [2300/4200], Loss: 0.0013\n","Epoch [1/10], Step [2400/4200], Loss: 0.0015\n","Epoch [1/10], Step [2500/4200], Loss: 0.0037\n","Epoch [1/10], Step [2600/4200], Loss: 0.0017\n","Epoch [1/10], Step [2700/4200], Loss: 0.0015\n","Epoch [1/10], Step [2800/4200], Loss: 0.0005\n","Epoch [1/10], Step [2900/4200], Loss: 0.0161\n","Epoch [1/10], Step [3000/4200], Loss: 0.0026\n","Epoch [1/10], Step [3100/4200], Loss: 0.0019\n","Epoch [1/10], Step [3200/4200], Loss: 0.0020\n","Epoch [1/10], Step [3300/4200], Loss: 0.0020\n","Epoch [1/10], Step [3400/4200], Loss: 0.0103\n","Epoch [1/10], Step [3500/4200], Loss: 0.0024\n","Epoch [1/10], Step [3600/4200], Loss: 0.0047\n","Epoch [1/10], Step [3700/4200], Loss: 0.0054\n","Epoch [1/10], Step [3800/4200], Loss: 0.0051\n","Epoch [1/10], Step [3900/4200], Loss: 0.0072\n","Epoch [1/10], Step [4000/4200], Loss: 0.0087\n","Epoch [1/10], Step [4100/4200], Loss: 0.0012\n","Epoch [1/10], Step [4200/4200], Loss: 0.0006\n","Epoch [2/10], Step [100/4200], Loss: 0.0020\n","Epoch [2/10], Step [200/4200], Loss: 0.0021\n","Epoch [2/10], Step [300/4200], Loss: 0.0015\n","Epoch [2/10], Step [400/4200], Loss: 0.0084\n","Epoch [2/10], Step [500/4200], Loss: 0.0013\n","Epoch [2/10], Step [600/4200], Loss: 0.0018\n","Epoch [2/10], Step [700/4200], Loss: 0.0006\n","Epoch [2/10], Step [800/4200], Loss: 0.0007\n","Epoch [2/10], Step [900/4200], Loss: 0.0087\n","Epoch [2/10], Step [1000/4200], Loss: 0.0037\n","Epoch [2/10], Step [1100/4200], Loss: 0.0068\n","Epoch [2/10], Step [1200/4200], Loss: 0.0026\n","Epoch [2/10], Step [1300/4200], Loss: 0.0030\n","Epoch [2/10], Step [1400/4200], Loss: 0.0015\n","Epoch [2/10], Step [1500/4200], Loss: 0.0013\n","Epoch [2/10], Step [1600/4200], Loss: 0.0009\n","Epoch [2/10], Step [1700/4200], Loss: 0.0018\n","Epoch [2/10], Step [1800/4200], Loss: 0.0047\n","Epoch [2/10], Step [1900/4200], Loss: 0.0011\n","Epoch [2/10], Step [2000/4200], Loss: 0.0016\n","Epoch [2/10], Step [2100/4200], Loss: 0.0011\n","Epoch [2/10], Step [2200/4200], Loss: 0.0014\n","Epoch [2/10], Step [2300/4200], Loss: 0.0010\n","Epoch [2/10], Step [2400/4200], Loss: 0.0006\n","Epoch [2/10], Step [2500/4200], Loss: 0.0019\n","Epoch [2/10], Step [2600/4200], Loss: 0.0008\n","Epoch [2/10], Step [2700/4200], Loss: 0.0020\n","Epoch [2/10], Step [2800/4200], Loss: 0.0020\n","Epoch [2/10], Step [2900/4200], Loss: 0.0007\n","Epoch [2/10], Step [3000/4200], Loss: 0.0004\n","Epoch [2/10], Step [3100/4200], Loss: 0.0003\n","Epoch [2/10], Step [3200/4200], Loss: 0.0011\n","Epoch [2/10], Step [3300/4200], Loss: 0.0017\n","Epoch [2/10], Step [3400/4200], Loss: 0.0002\n","Epoch [2/10], Step [3500/4200], Loss: 0.0014\n","Epoch [2/10], Step [3600/4200], Loss: 0.0037\n","Epoch [2/10], Step [3700/4200], Loss: 0.0050\n","Epoch [2/10], Step [3800/4200], Loss: 0.0025\n","Epoch [2/10], Step [3900/4200], Loss: 0.0016\n","Epoch [2/10], Step [4000/4200], Loss: 0.0068\n","Epoch [2/10], Step [4100/4200], Loss: 0.0052\n","Epoch [2/10], Step [4200/4200], Loss: 0.0033\n","Epoch [3/10], Step [100/4200], Loss: 0.0015\n","Epoch [3/10], Step [200/4200], Loss: 0.0020\n","Epoch [3/10], Step [300/4200], Loss: 0.0061\n","Epoch [3/10], Step [400/4200], Loss: 0.0011\n","Epoch [3/10], Step [500/4200], Loss: 0.0006\n","Epoch [3/10], Step [600/4200], Loss: 0.0004\n","Epoch [3/10], Step [700/4200], Loss: 0.0005\n","Epoch [3/10], Step [800/4200], Loss: 0.0004\n","Epoch [3/10], Step [900/4200], Loss: 0.0138\n","Epoch [3/10], Step [1000/4200], Loss: 0.0027\n","Epoch [3/10], Step [1100/4200], Loss: 0.0038\n","Epoch [3/10], Step [1200/4200], Loss: 0.0021\n","Epoch [3/10], Step [1300/4200], Loss: 0.0009\n","Epoch [3/10], Step [1400/4200], Loss: 0.0020\n","Epoch [3/10], Step [1500/4200], Loss: 0.0054\n","Epoch [3/10], Step [1600/4200], Loss: 0.0035\n","Epoch [3/10], Step [1700/4200], Loss: 0.0017\n","Epoch [3/10], Step [1800/4200], Loss: 0.0020\n","Epoch [3/10], Step [1900/4200], Loss: 0.0039\n","Epoch [3/10], Step [2000/4200], Loss: 0.0017\n","Epoch [3/10], Step [2100/4200], Loss: 0.0010\n","Epoch [3/10], Step [2200/4200], Loss: 0.0009\n","Epoch [3/10], Step [2300/4200], Loss: 0.0006\n","Epoch [3/10], Step [2400/4200], Loss: 0.0005\n","Epoch [3/10], Step [2500/4200], Loss: 0.0022\n","Epoch [3/10], Step [2600/4200], Loss: 0.0007\n","Epoch [3/10], Step [2700/4200], Loss: 0.0040\n","Epoch [3/10], Step [2800/4200], Loss: 0.0005\n","Epoch [3/10], Step [2900/4200], Loss: 0.0004\n","Epoch [3/10], Step [3000/4200], Loss: 0.0006\n","Epoch [3/10], Step [3100/4200], Loss: 0.0007\n","Epoch [3/10], Step [3200/4200], Loss: 0.0002\n","Epoch [3/10], Step [3300/4200], Loss: 0.0008\n","Epoch [3/10], Step [3400/4200], Loss: 0.0007\n","Epoch [3/10], Step [3500/4200], Loss: 0.0003\n","Epoch [3/10], Step [3600/4200], Loss: 0.0007\n","Epoch [3/10], Step [3700/4200], Loss: 0.0004\n","Epoch [3/10], Step [3800/4200], Loss: 0.0039\n","Epoch [3/10], Step [3900/4200], Loss: 0.0106\n","Epoch [3/10], Step [4000/4200], Loss: 0.0060\n","Epoch [3/10], Step [4100/4200], Loss: 0.0015\n","Epoch [3/10], Step [4200/4200], Loss: 0.0007\n","Epoch [4/10], Step [100/4200], Loss: 0.0010\n","Epoch [4/10], Step [200/4200], Loss: 0.0006\n","Epoch [4/10], Step [300/4200], Loss: 0.0019\n","Epoch [4/10], Step [400/4200], Loss: 0.0010\n","Epoch [4/10], Step [500/4200], Loss: 0.0061\n","Epoch [4/10], Step [600/4200], Loss: 0.0011\n","Epoch [4/10], Step [700/4200], Loss: 0.0045\n","Epoch [4/10], Step [800/4200], Loss: 0.0024\n","Epoch [4/10], Step [900/4200], Loss: 0.0009\n","Epoch [4/10], Step [1000/4200], Loss: 0.0016\n","Epoch [4/10], Step [1100/4200], Loss: 0.0011\n","Epoch [4/10], Step [1200/4200], Loss: 0.0013\n","Epoch [4/10], Step [1300/4200], Loss: 0.0004\n","Epoch [4/10], Step [1400/4200], Loss: 0.0008\n","Epoch [4/10], Step [1500/4200], Loss: 0.0007\n","Epoch [4/10], Step [1600/4200], Loss: 0.0004\n","Epoch [4/10], Step [1700/4200], Loss: 0.0009\n","Epoch [4/10], Step [1800/4200], Loss: 0.0007\n","Epoch [4/10], Step [1900/4200], Loss: 0.0009\n","Epoch [4/10], Step [2000/4200], Loss: 0.0022\n","Epoch [4/10], Step [2100/4200], Loss: 0.0014\n","Epoch [4/10], Step [2200/4200], Loss: 0.0011\n","Epoch [4/10], Step [2300/4200], Loss: 0.0019\n","Epoch [4/10], Step [2400/4200], Loss: 0.0013\n","Epoch [4/10], Step [2500/4200], Loss: 0.0023\n","Epoch [4/10], Step [2600/4200], Loss: 0.0007\n","Epoch [4/10], Step [2700/4200], Loss: 0.0013\n","Epoch [4/10], Step [2800/4200], Loss: 0.0005\n","Epoch [4/10], Step [2900/4200], Loss: 0.0003\n","Epoch [4/10], Step [3000/4200], Loss: 0.0006\n","Epoch [4/10], Step [3100/4200], Loss: 0.0005\n","Epoch [4/10], Step [3200/4200], Loss: 0.0004\n","Epoch [4/10], Step [3300/4200], Loss: 0.0005\n","Epoch [4/10], Step [3400/4200], Loss: 0.0014\n","Epoch [4/10], Step [3500/4200], Loss: 0.0005\n","Epoch [4/10], Step [3600/4200], Loss: 0.0008\n","Epoch [4/10], Step [3700/4200], Loss: 0.0005\n","Epoch [4/10], Step [3800/4200], Loss: 0.0036\n","Epoch [4/10], Step [3900/4200], Loss: 0.0035\n","Epoch [4/10], Step [4000/4200], Loss: 0.0030\n","Epoch [4/10], Step [4100/4200], Loss: 0.0034\n","Epoch [4/10], Step [4200/4200], Loss: 0.0014\n","Epoch [5/10], Step [100/4200], Loss: 0.0013\n","Epoch [5/10], Step [200/4200], Loss: 0.0005\n","Epoch [5/10], Step [300/4200], Loss: 0.0005\n","Epoch [5/10], Step [400/4200], Loss: 0.0005\n","Epoch [5/10], Step [500/4200], Loss: 0.0009\n","Epoch [5/10], Step [600/4200], Loss: 0.0037\n","Epoch [5/10], Step [700/4200], Loss: 0.0074\n","Epoch [5/10], Step [800/4200], Loss: 0.0013\n","Epoch [5/10], Step [900/4200], Loss: 0.0012\n","Epoch [5/10], Step [1000/4200], Loss: 0.0005\n","Epoch [5/10], Step [1100/4200], Loss: 0.0005\n","Epoch [5/10], Step [1200/4200], Loss: 0.0004\n","Epoch [5/10], Step [1300/4200], Loss: 0.0004\n","Epoch [5/10], Step [1400/4200], Loss: 0.0005\n","Epoch [5/10], Step [1500/4200], Loss: 0.0007\n","Epoch [5/10], Step [1600/4200], Loss: 0.0011\n","Epoch [5/10], Step [1700/4200], Loss: 0.0004\n","Epoch [5/10], Step [1800/4200], Loss: 0.0005\n","Epoch [5/10], Step [1900/4200], Loss: 0.0002\n","Epoch [5/10], Step [2000/4200], Loss: 0.0009\n","Epoch [5/10], Step [2100/4200], Loss: 0.0002\n","Epoch [5/10], Step [2200/4200], Loss: 0.0006\n","Epoch [5/10], Step [2300/4200], Loss: 0.0004\n","Epoch [5/10], Step [2400/4200], Loss: 0.0028\n","Epoch [5/10], Step [2500/4200], Loss: 0.0009\n","Epoch [5/10], Step [2600/4200], Loss: 0.0011\n","Epoch [5/10], Step [2700/4200], Loss: 0.0007\n","Epoch [5/10], Step [2800/4200], Loss: 0.0011\n","Epoch [5/10], Step [2900/4200], Loss: 0.0003\n","Epoch [5/10], Step [3000/4200], Loss: 0.0002\n","Epoch [5/10], Step [3100/4200], Loss: 0.0016\n","Epoch [5/10], Step [3200/4200], Loss: 0.0013\n","Epoch [5/10], Step [3300/4200], Loss: 0.0006\n","Epoch [5/10], Step [3400/4200], Loss: 0.0012\n","Epoch [5/10], Step [3500/4200], Loss: 0.0003\n","Epoch [5/10], Step [3600/4200], Loss: 0.0002\n","Epoch [5/10], Step [3700/4200], Loss: 0.0009\n","Epoch [5/10], Step [3800/4200], Loss: 0.0001\n","Epoch [5/10], Step [3900/4200], Loss: 0.0004\n","Epoch [5/10], Step [4000/4200], Loss: 0.0004\n","Epoch [5/10], Step [4100/4200], Loss: 0.0021\n","Epoch [5/10], Step [4200/4200], Loss: 0.0002\n","Epoch [6/10], Step [100/4200], Loss: 0.0012\n","Epoch [6/10], Step [200/4200], Loss: 0.0005\n","Epoch [6/10], Step [300/4200], Loss: 0.0010\n","Epoch [6/10], Step [400/4200], Loss: 0.0012\n","Epoch [6/10], Step [500/4200], Loss: 0.0012\n","Epoch [6/10], Step [600/4200], Loss: 0.0012\n","Epoch [6/10], Step [700/4200], Loss: 0.0004\n","Epoch [6/10], Step [800/4200], Loss: 0.0003\n","Epoch [6/10], Step [900/4200], Loss: 0.0004\n","Epoch [6/10], Step [1000/4200], Loss: 0.0003\n","Epoch [6/10], Step [1100/4200], Loss: 0.0004\n","Epoch [6/10], Step [1200/4200], Loss: 0.0003\n","Epoch [6/10], Step [1300/4200], Loss: 0.0129\n","Epoch [6/10], Step [1400/4200], Loss: 0.0020\n","Epoch [6/10], Step [1500/4200], Loss: 0.0005\n","Epoch [6/10], Step [1600/4200], Loss: 0.0005\n","Epoch [6/10], Step [1700/4200], Loss: 0.0012\n","Epoch [6/10], Step [1800/4200], Loss: 0.0005\n","Epoch [6/10], Step [1900/4200], Loss: 0.0006\n","Epoch [6/10], Step [2000/4200], Loss: 0.0003\n","Epoch [6/10], Step [2100/4200], Loss: 0.0009\n","Epoch [6/10], Step [2200/4200], Loss: 0.0015\n","Epoch [6/10], Step [2300/4200], Loss: 0.0017\n","Epoch [6/10], Step [2400/4200], Loss: 0.0007\n","Epoch [6/10], Step [2500/4200], Loss: 0.0047\n","Epoch [6/10], Step [2600/4200], Loss: 0.0015\n","Epoch [6/10], Step [2700/4200], Loss: 0.0007\n","Epoch [6/10], Step [2800/4200], Loss: 0.0004\n","Epoch [6/10], Step [2900/4200], Loss: 0.0005\n","Epoch [6/10], Step [3000/4200], Loss: 0.0002\n","Epoch [6/10], Step [3100/4200], Loss: 0.0006\n","Epoch [6/10], Step [3200/4200], Loss: 0.0004\n","Epoch [6/10], Step [3300/4200], Loss: 0.0016\n","Epoch [6/10], Step [3400/4200], Loss: 0.0003\n","Epoch [6/10], Step [3500/4200], Loss: 0.0005\n","Epoch [6/10], Step [3600/4200], Loss: 0.0006\n","Epoch [6/10], Step [3700/4200], Loss: 0.0003\n","Epoch [6/10], Step [3800/4200], Loss: 0.0014\n","Epoch [6/10], Step [3900/4200], Loss: 0.0004\n","Epoch [6/10], Step [4000/4200], Loss: 0.0003\n","Epoch [6/10], Step [4100/4200], Loss: 0.0005\n","Epoch [6/10], Step [4200/4200], Loss: 0.0003\n","Epoch [7/10], Step [100/4200], Loss: 0.0008\n","Epoch [7/10], Step [200/4200], Loss: 0.0001\n","Epoch [7/10], Step [300/4200], Loss: 0.0003\n","Epoch [7/10], Step [400/4200], Loss: 0.0002\n","Epoch [7/10], Step [500/4200], Loss: 0.0008\n","Epoch [7/10], Step [600/4200], Loss: 0.0002\n","Epoch [7/10], Step [700/4200], Loss: 0.0009\n","Epoch [7/10], Step [800/4200], Loss: 0.0003\n","Epoch [7/10], Step [900/4200], Loss: 0.0003\n","Epoch [7/10], Step [1000/4200], Loss: 0.0001\n","Epoch [7/10], Step [1100/4200], Loss: 0.0022\n","Epoch [7/10], Step [1200/4200], Loss: 0.0006\n","Epoch [7/10], Step [1300/4200], Loss: 0.0010\n","Epoch [7/10], Step [1400/4200], Loss: 0.0011\n","Epoch [7/10], Step [1500/4200], Loss: 0.0033\n","Epoch [7/10], Step [1600/4200], Loss: 0.0005\n","Epoch [7/10], Step [1700/4200], Loss: 0.0015\n","Epoch [7/10], Step [1800/4200], Loss: 0.0005\n","Epoch [7/10], Step [1900/4200], Loss: 0.0081\n","Epoch [7/10], Step [2000/4200], Loss: 0.0015\n","Epoch [7/10], Step [2100/4200], Loss: 0.0007\n","Epoch [7/10], Step [2200/4200], Loss: 0.0020\n","Epoch [7/10], Step [2300/4200], Loss: 0.0008\n","Epoch [7/10], Step [2400/4200], Loss: 0.0005\n","Epoch [7/10], Step [2500/4200], Loss: 0.0046\n","Epoch [7/10], Step [2600/4200], Loss: 0.0008\n","Epoch [7/10], Step [2700/4200], Loss: 0.0008\n","Epoch [7/10], Step [2800/4200], Loss: 0.0027\n","Epoch [7/10], Step [2900/4200], Loss: 0.0025\n","Epoch [7/10], Step [3000/4200], Loss: 0.0007\n","Epoch [7/10], Step [3100/4200], Loss: 0.0006\n","Epoch [7/10], Step [3200/4200], Loss: 0.0018\n","Epoch [7/10], Step [3300/4200], Loss: 0.0004\n","Epoch [7/10], Step [3400/4200], Loss: 0.0018\n","Epoch [7/10], Step [3500/4200], Loss: 0.0006\n","Epoch [7/10], Step [3600/4200], Loss: 0.0010\n","Epoch [7/10], Step [3700/4200], Loss: 0.0003\n","Epoch [7/10], Step [3800/4200], Loss: 0.0004\n","Epoch [7/10], Step [3900/4200], Loss: 0.0003\n","Epoch [7/10], Step [4000/4200], Loss: 0.0001\n","Epoch [7/10], Step [4100/4200], Loss: 0.0002\n","Epoch [7/10], Step [4200/4200], Loss: 0.0006\n","Epoch [8/10], Step [100/4200], Loss: 0.0011\n","Epoch [8/10], Step [200/4200], Loss: 0.0018\n","Epoch [8/10], Step [300/4200], Loss: 0.0024\n","Epoch [8/10], Step [400/4200], Loss: 0.0004\n","Epoch [8/10], Step [500/4200], Loss: 0.0003\n","Epoch [8/10], Step [600/4200], Loss: 0.0006\n","Epoch [8/10], Step [700/4200], Loss: 0.0002\n","Epoch [8/10], Step [800/4200], Loss: 0.0010\n","Epoch [8/10], Step [900/4200], Loss: 0.0003\n","Epoch [8/10], Step [1000/4200], Loss: 0.0003\n","Epoch [8/10], Step [1100/4200], Loss: 0.0002\n","Epoch [8/10], Step [1200/4200], Loss: 0.0002\n","Epoch [8/10], Step [1300/4200], Loss: 0.0009\n","Epoch [8/10], Step [1400/4200], Loss: 0.0004\n","Epoch [8/10], Step [1500/4200], Loss: 0.0003\n","Epoch [8/10], Step [1600/4200], Loss: 0.0002\n","Epoch [8/10], Step [1700/4200], Loss: 0.0003\n","Epoch [8/10], Step [1800/4200], Loss: 0.0001\n","Epoch [8/10], Step [1900/4200], Loss: 0.0003\n","Epoch [8/10], Step [2000/4200], Loss: 0.0016\n","Epoch [8/10], Step [2100/4200], Loss: 0.0004\n","Epoch [8/10], Step [2200/4200], Loss: 0.0003\n","Epoch [8/10], Step [2300/4200], Loss: 0.0005\n","Epoch [8/10], Step [2400/4200], Loss: 0.0002\n","Epoch [8/10], Step [2500/4200], Loss: 0.0001\n","Epoch [8/10], Step [2600/4200], Loss: 0.0019\n","Epoch [8/10], Step [2700/4200], Loss: 0.0077\n","Epoch [8/10], Step [2800/4200], Loss: 0.0007\n","Epoch [8/10], Step [2900/4200], Loss: 0.0010\n","Epoch [8/10], Step [3000/4200], Loss: 0.0022\n","Epoch [8/10], Step [3100/4200], Loss: 0.0005\n","Epoch [8/10], Step [3200/4200], Loss: 0.0006\n","Epoch [8/10], Step [3300/4200], Loss: 0.0004\n","Epoch [8/10], Step [3400/4200], Loss: 0.0004\n","Epoch [8/10], Step [3500/4200], Loss: 0.0015\n","Epoch [8/10], Step [3600/4200], Loss: 0.0004\n","Epoch [8/10], Step [3700/4200], Loss: 0.0001\n","Epoch [8/10], Step [3800/4200], Loss: 0.0002\n","Epoch [8/10], Step [3900/4200], Loss: 0.0002\n","Epoch [8/10], Step [4000/4200], Loss: 0.0002\n","Epoch [8/10], Step [4100/4200], Loss: 0.0003\n","Epoch [8/10], Step [4200/4200], Loss: 0.0005\n","Epoch [9/10], Step [100/4200], Loss: 0.0003\n","Epoch [9/10], Step [200/4200], Loss: 0.0008\n","Epoch [9/10], Step [300/4200], Loss: 0.0004\n","Epoch [9/10], Step [400/4200], Loss: 0.0002\n","Epoch [9/10], Step [500/4200], Loss: 0.0005\n","Epoch [9/10], Step [600/4200], Loss: 0.0005\n","Epoch [9/10], Step [700/4200], Loss: 0.0003\n","Epoch [9/10], Step [800/4200], Loss: 0.0008\n","Epoch [9/10], Step [900/4200], Loss: 0.0005\n","Epoch [9/10], Step [1000/4200], Loss: 0.0001\n","Epoch [9/10], Step [1100/4200], Loss: 0.0013\n","Epoch [9/10], Step [1200/4200], Loss: 0.0002\n","Epoch [9/10], Step [1300/4200], Loss: 0.0033\n","Epoch [9/10], Step [1400/4200], Loss: 0.0011\n","Epoch [9/10], Step [1500/4200], Loss: 0.0013\n","Epoch [9/10], Step [1600/4200], Loss: 0.0003\n","Epoch [9/10], Step [1700/4200], Loss: 0.0028\n","Epoch [9/10], Step [1800/4200], Loss: 0.0008\n","Epoch [9/10], Step [1900/4200], Loss: 0.0014\n","Epoch [9/10], Step [2000/4200], Loss: 0.0002\n","Epoch [9/10], Step [2100/4200], Loss: 0.0011\n","Epoch [9/10], Step [2200/4200], Loss: 0.0009\n","Epoch [9/10], Step [2300/4200], Loss: 0.0001\n","Epoch [9/10], Step [2400/4200], Loss: 0.0009\n","Epoch [9/10], Step [2500/4200], Loss: 0.0003\n","Epoch [9/10], Step [2600/4200], Loss: 0.0001\n","Epoch [9/10], Step [2700/4200], Loss: 0.0001\n","Epoch [9/10], Step [2800/4200], Loss: 0.0001\n","Epoch [9/10], Step [2900/4200], Loss: 0.0001\n","Epoch [9/10], Step [3000/4200], Loss: 0.0008\n","Epoch [9/10], Step [3100/4200], Loss: 0.0019\n","Epoch [9/10], Step [3200/4200], Loss: 0.0004\n","Epoch [9/10], Step [3300/4200], Loss: 0.0006\n","Epoch [9/10], Step [3400/4200], Loss: 0.0004\n","Epoch [9/10], Step [3500/4200], Loss: 0.0002\n","Epoch [9/10], Step [3600/4200], Loss: 0.0012\n","Epoch [9/10], Step [3700/4200], Loss: 0.0027\n","Epoch [9/10], Step [3800/4200], Loss: 0.0008\n","Epoch [9/10], Step [3900/4200], Loss: 0.0021\n","Epoch [9/10], Step [4000/4200], Loss: 0.0004\n","Epoch [9/10], Step [4100/4200], Loss: 0.0004\n","Epoch [9/10], Step [4200/4200], Loss: 0.0003\n","Epoch [10/10], Step [100/4200], Loss: 0.0001\n","Epoch [10/10], Step [200/4200], Loss: 0.0017\n","Epoch [10/10], Step [300/4200], Loss: 0.0001\n","Epoch [10/10], Step [400/4200], Loss: 0.0004\n","Epoch [10/10], Step [500/4200], Loss: 0.0002\n","Epoch [10/10], Step [600/4200], Loss: 0.0016\n","Epoch [10/10], Step [700/4200], Loss: 0.0044\n","Epoch [10/10], Step [800/4200], Loss: 0.0012\n","Epoch [10/10], Step [900/4200], Loss: 0.0005\n","Epoch [10/10], Step [1000/4200], Loss: 0.0002\n","Epoch [10/10], Step [1100/4200], Loss: 0.0003\n","Epoch [10/10], Step [1200/4200], Loss: 0.0004\n","Epoch [10/10], Step [1300/4200], Loss: 0.0001\n","Epoch [10/10], Step [1400/4200], Loss: 0.0013\n","Epoch [10/10], Step [1500/4200], Loss: 0.0005\n","Epoch [10/10], Step [1600/4200], Loss: 0.0003\n","Epoch [10/10], Step [1700/4200], Loss: 0.0011\n","Epoch [10/10], Step [1800/4200], Loss: 0.0006\n","Epoch [10/10], Step [1900/4200], Loss: 0.0001\n","Epoch [10/10], Step [2000/4200], Loss: 0.0015\n","Epoch [10/10], Step [2100/4200], Loss: 0.0122\n","Epoch [10/10], Step [2200/4200], Loss: 0.0002\n","Epoch [10/10], Step [2300/4200], Loss: 0.0002\n","Epoch [10/10], Step [2400/4200], Loss: 0.0009\n","Epoch [10/10], Step [2500/4200], Loss: 0.0008\n","Epoch [10/10], Step [2600/4200], Loss: 0.0001\n","Epoch [10/10], Step [2700/4200], Loss: 0.0008\n","Epoch [10/10], Step [2800/4200], Loss: 0.0015\n","Epoch [10/10], Step [2900/4200], Loss: 0.0005\n","Epoch [10/10], Step [3000/4200], Loss: 0.0001\n","Epoch [10/10], Step [3100/4200], Loss: 0.0002\n","Epoch [10/10], Step [3200/4200], Loss: 0.0003\n","Epoch [10/10], Step [3300/4200], Loss: 0.0003\n","Epoch [10/10], Step [3400/4200], Loss: 0.0002\n","Epoch [10/10], Step [3500/4200], Loss: 0.0006\n","Epoch [10/10], Step [3600/4200], Loss: 0.0001\n","Epoch [10/10], Step [3700/4200], Loss: 0.0001\n","Epoch [10/10], Step [3800/4200], Loss: 0.0002\n","Epoch [10/10], Step [3900/4200], Loss: 0.0017\n","Epoch [10/10], Step [4000/4200], Loss: 0.0005\n","Epoch [10/10], Step [4100/4200], Loss: 0.0034\n","Epoch [10/10], Step [4200/4200], Loss: 0.0002\n"]}],"source":["# Freeze CNN parameters\n","for param in conv_model.parameters():\n","    param.requires_grad = False\n","\n","if torch.cuda.is_available():\n","    conv_model = conv_model.cuda()\n","    puppeteer_net = puppeteer_net.cuda()\n","\n","# Define optimizer for the Puppeteer MLP\n","optimizer = optim.Adam(puppeteer_net.parameters(), lr=0.001)\n","\n","# Training loop parameters\n","num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    puppeteer_net.train()\n","    running_loss = 0.0\n","\n","    for i, (images, labels) in enumerate(train_loader):\n","        images = images.unsqueeze(1)\n","        if torch.cuda.is_available():\n","            images = images.cuda()\n","            labels = labels.cuda()\n","        \n","        batch_size = images.size(0)\n","        \n","        # Select digits to inhibit (using true labels for simplicity)\n","        inhibited_digits = labels  # Alternatively, use random digits to inhibit\n","        \n","        # Convert inhibited digits to one-hot vectors\n","        inhibited_digits_one_hot = torch.zeros(batch_size, 10).to(images.device)\n","        inhibited_digits_one_hot.scatter_(1, inhibited_digits.view(-1, 1), 1)\n","        \n","        # Forward pass through conv_block of the CNN\n","        x = conv_model.conv_block(images)\n","        \n","        # Flatten the activations\n","        x = x.view(batch_size, -1)\n","        \n","        # Get adjustments from Puppeteer MLP\n","        adjustments = puppeteer_net(inhibited_digits_one_hot)\n","        \n","        # Adjust the activations\n","        x = x + adjustments  # You can experiment with other operations like multiplication\n","        \n","        # Pass adjusted activations through linear_block of the CNN\n","        output = conv_model.linear_block(x)\n","        \n","        # Compute softmax probabilities\n","        output_probs = F.softmax(output, dim=1)\n","        \n","        # Probability of predicting the inhibited digit\n","        p_inhibited = output_probs[range(batch_size), inhibited_digits]\n","        \n","        # Loss function to penalize high probability of inhibited digit\n","        epsilon = 1e-6  # Small value to prevent log(0)\n","        loss = -torch.log(1 - p_inhibited + epsilon)\n","        loss = torch.mean(loss)\n","        \n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","        running_loss += loss.item()\n","        \n","        # Print training progress\n","        if (i+1) % 100 == 0:\n","            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}')\n","            running_loss = 0.0\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.15"}},"nbformat":4,"nbformat_minor":1}
